{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why no regularization is better than L1/L2 regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case of MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are having a study group for Stockholm AI soon. During a discussion with my friend, Carl, I told him that it is common to use L2 regularization and L1 at the same time. We then continued the dicussion and I started to wonder: would it actually perform the performance of a simple MLP on a simple data like MNIST? But then I started a simple experiment: let's compare the performance of an MLP with no regularization with L1, L2 and a combination of L1 and L2 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before anything else, let's ensure reproducibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow\n",
    "\n",
    "numpy.random.seed(7)\n",
    "tensorflow.set_random_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I usually like to import everything first: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a broader perspective on the measures, I decided to add F1 score to the model as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='micro')\n",
    "        _val_recall = recall_score(val_targ, val_predict, average='micro')\n",
    "        _val_precision = precision_score(val_targ, val_predict, average='micro')\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print(\" — val_f1: %f — val_precision: %f — val_recall %f\" % (_val_f1, _val_precision, _val_recall))\n",
    "        \n",
    "        return\n",
    " \n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple MLP with no regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the simplest MLP one can find. The point with this MLP is not that it should be the state-of-the-art among MLPs, since the model is not going to change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2197 - acc: 0.9316 - val_loss: 0.1048 - val_acc: 0.9664\n",
      " — val_f1: 0.966747 — val_precision: 0.971235 — val_recall 0.962300\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0822 - acc: 0.9744 - val_loss: 0.1102 - val_acc: 0.9647\n",
      " — val_f1: 0.965106 — val_precision: 0.967726 — val_recall 0.962500\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0537 - acc: 0.9837 - val_loss: 0.0683 - val_acc: 0.9796\n",
      " — val_f1: 0.979676 — val_precision: 0.980854 — val_recall 0.978500\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0389 - acc: 0.9875 - val_loss: 0.0757 - val_acc: 0.9800\n",
      " — val_f1: 0.980325 — val_precision: 0.981554 — val_recall 0.979100\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0288 - acc: 0.9908 - val_loss: 0.0861 - val_acc: 0.9791\n",
      " — val_f1: 0.979437 — val_precision: 0.980074 — val_recall 0.978800\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0234 - acc: 0.9924 - val_loss: 0.0984 - val_acc: 0.9783\n",
      " — val_f1: 0.978683 — val_precision: 0.979467 — val_recall 0.977900\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0196 - acc: 0.9939 - val_loss: 0.0998 - val_acc: 0.9797\n",
      " — val_f1: 0.979992 — val_precision: 0.980384 — val_recall 0.979600\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0153 - acc: 0.9949 - val_loss: 0.0899 - val_acc: 0.9830\n",
      " — val_f1: 0.982991 — val_precision: 0.983483 — val_recall 0.982500\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0140 - acc: 0.9958 - val_loss: 0.1254 - val_acc: 0.9765\n",
      " — val_f1: 0.976395 — val_precision: 0.976591 — val_recall 0.976200\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.1082 - val_acc: 0.9822\n",
      " — val_f1: 0.982242 — val_precision: 0.982684 — val_recall 0.981800\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.1256 - val_acc: 0.9795\n",
      " — val_f1: 0.979647 — val_precision: 0.979794 — val_recall 0.979500\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0097 - acc: 0.9970 - val_loss: 0.1171 - val_acc: 0.9819\n",
      " — val_f1: 0.981898 — val_precision: 0.981996 — val_recall 0.981800\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0080 - acc: 0.9976 - val_loss: 0.1325 - val_acc: 0.9813\n",
      " — val_f1: 0.981445 — val_precision: 0.981691 — val_recall 0.981200\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.1158 - val_acc: 0.9826\n",
      " — val_f1: 0.982547 — val_precision: 0.982695 — val_recall 0.982400\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0056 - acc: 0.9982 - val_loss: 0.1207 - val_acc: 0.9826\n",
      " — val_f1: 0.982698 — val_precision: 0.982797 — val_recall 0.982600\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.1559 - val_acc: 0.9801\n",
      " — val_f1: 0.980100 — val_precision: 0.980100 — val_recall 0.980100\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.1235 - val_acc: 0.9838\n",
      " — val_f1: 0.983798 — val_precision: 0.983897 — val_recall 0.983700\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0062 - acc: 0.9984 - val_loss: 0.1602 - val_acc: 0.9800\n",
      " — val_f1: 0.980096 — val_precision: 0.980292 — val_recall 0.979900\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.1318 - val_acc: 0.9819\n",
      " — val_f1: 0.981998 — val_precision: 0.982096 — val_recall 0.981900\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.1417 - val_acc: 0.9811\n",
      " — val_f1: 0.981098 — val_precision: 0.981196 — val_recall 0.981000\n",
      "Test loss: 0.14170724155069364\n",
      "Test accuracy: 0.9811\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test), callbacks=[metrics])\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we all know that L2 regularization helps generalizatin of a neural network or any ML model, right? I thought so too. So I started checking the usual parameter for L2 regulariztion, namely 0.001:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.6426 - acc: 0.9225 - val_loss: 0.3232 - val_acc: 0.9572\n",
      " — val_f1: 0.955391 — val_precision: 0.966537 — val_recall 0.944500\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2627 - acc: 0.9612 - val_loss: 0.2343 - val_acc: 0.9591\n",
      " — val_f1: 0.959702 — val_precision: 0.965678 — val_recall 0.953800\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2043 - acc: 0.9675 - val_loss: 0.2097 - val_acc: 0.9602\n",
      " — val_f1: 0.960205 — val_precision: 0.966184 — val_recall 0.954300\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1769 - acc: 0.9721 - val_loss: 0.1808 - val_acc: 0.9682\n",
      " — val_f1: 0.968316 — val_precision: 0.973998 — val_recall 0.962700\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.1617 - acc: 0.9734 - val_loss: 0.1582 - val_acc: 0.9736\n",
      " — val_f1: 0.972889 — val_precision: 0.976911 — val_recall 0.968900\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1494 - acc: 0.9758 - val_loss: 0.1892 - val_acc: 0.9630\n",
      " — val_f1: 0.963097 — val_precision: 0.967127 — val_recall 0.959100\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1431 - acc: 0.9765 - val_loss: 0.1577 - val_acc: 0.9703\n",
      " — val_f1: 0.970743 — val_precision: 0.974312 — val_recall 0.967200\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1369 - acc: 0.9773 - val_loss: 0.1306 - val_acc: 0.9785\n",
      " — val_f1: 0.979289 — val_precision: 0.982195 — val_recall 0.976400\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1312 - acc: 0.9786 - val_loss: 0.1632 - val_acc: 0.9652\n",
      " — val_f1: 0.965870 — val_precision: 0.969569 — val_recall 0.962200\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1264 - acc: 0.9791 - val_loss: 0.1282 - val_acc: 0.9785\n",
      " — val_f1: 0.978832 — val_precision: 0.981985 — val_recall 0.975700\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1236 - acc: 0.9795 - val_loss: 0.2548 - val_acc: 0.9350\n",
      " — val_f1: 0.935471 — val_precision: 0.940291 — val_recall 0.930700\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1215 - acc: 0.9798 - val_loss: 0.1431 - val_acc: 0.9735\n",
      " — val_f1: 0.973575 — val_precision: 0.976365 — val_recall 0.970800\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1176 - acc: 0.9804 - val_loss: 0.1371 - val_acc: 0.9753\n",
      " — val_f1: 0.975463 — val_precision: 0.978951 — val_recall 0.972000\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1166 - acc: 0.9800 - val_loss: 0.1630 - val_acc: 0.9654\n",
      " — val_f1: 0.966206 — val_precision: 0.970348 — val_recall 0.962100\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1147 - acc: 0.9809 - val_loss: 0.1324 - val_acc: 0.9767\n",
      " — val_f1: 0.977327 — val_precision: 0.980475 — val_recall 0.974200\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1133 - acc: 0.9814 - val_loss: 0.1442 - val_acc: 0.9717\n",
      " — val_f1: 0.971609 — val_precision: 0.974738 — val_recall 0.968500\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1118 - acc: 0.9810 - val_loss: 0.1199 - val_acc: 0.9795\n",
      " — val_f1: 0.979743 — val_precision: 0.982502 — val_recall 0.977000\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1108 - acc: 0.9809 - val_loss: 0.1427 - val_acc: 0.9737\n",
      " — val_f1: 0.973783 — val_precision: 0.976279 — val_recall 0.971300\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.1114 - acc: 0.9816 - val_loss: 0.1272 - val_acc: 0.9769\n",
      " — val_f1: 0.977346 — val_precision: 0.979703 — val_recall 0.975000\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1084 - acc: 0.9816 - val_loss: 0.1285 - val_acc: 0.9764\n",
      " — val_f1: 0.976889 — val_precision: 0.979491 — val_recall 0.974300\n",
      "Test loss: 0.12848583143949507\n",
      "Test accuracy: 0.9764\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(512, activation='relu', input_shape=(784,), kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model_2.add(Dropout(0.2))\n",
    "model_2.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model_2.add(Dropout(0.2))\n",
    "model_2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model_2.summary()\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_2 = model_2.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test), callbacks=[metrics])\n",
    "score_2 = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score_2[0])\n",
    "print('Test accuracy:', score_2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was confused a bit. How can the network with L2 regularization perform worse than the one without it? Isn't one the promise of regularization is to help generalization? Could it be that the L2 coefficient needs more tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamter optimization of L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.8196639854552179\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 31.1118 - acc: 0.1522 - val_loss: 2.4363 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.4380 - acc: 0.1115 - val_loss: 2.4372 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4377 - acc: 0.1114 - val_loss: 2.4371 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.4376 - acc: 0.1122 - val_loss: 2.4374 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.4374 - acc: 0.1124 - val_loss: 2.4371 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4373 - acc: 0.1124 - val_loss: 2.4373 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.4373 - acc: 0.1124 - val_loss: 2.4373 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.4373 - acc: 0.1124 - val_loss: 2.4370 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4373 - acc: 0.1124 - val_loss: 2.4370 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4372 - acc: 0.1124 - val_loss: 2.4371 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4373 - acc: 0.1124 - val_loss: 2.4370 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4373 - acc: 0.1124 - val_loss: 2.4371 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4373 - acc: 0.1124 - val_loss: 2.4370 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4372 - acc: 0.1124 - val_loss: 2.4370 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4372 - acc: 0.1124 - val_loss: 2.4371 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4372 - acc: 0.1124 - val_loss: 2.4369 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4372 - acc: 0.1124 - val_loss: 2.4370 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4372 - acc: 0.1124 - val_loss: 2.4370 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4372 - acc: 0.1124 - val_loss: 2.4370 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4372 - acc: 0.1124 - val_loss: 2.4370 - val_acc: 0.1135\n",
      "Test loss: 2.4369561347961426\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 4.870195268861175\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 173.9154 - acc: 0.1347 - val_loss: 3.1091 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 3.1098 - acc: 0.1109 - val_loss: 3.1097 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 3.1095 - acc: 0.1123 - val_loss: 3.1096 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 3.1094 - acc: 0.1124 - val_loss: 3.1092 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 3.1093 - acc: 0.1124 - val_loss: 3.1089 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 3.1093 - acc: 0.1124 - val_loss: 3.1090 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 3.1092 - acc: 0.1124 - val_loss: 3.1090 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 3.1092 - acc: 0.1124 - val_loss: 3.1089 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 3.1092 - acc: 0.1124 - val_loss: 3.1089 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1092 - acc: 0.1124 - val_loss: 3.1089 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1092 - acc: 0.1124 - val_loss: 3.1089 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1092 - acc: 0.1124 - val_loss: 3.1089 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1092 - acc: 0.1124 - val_loss: 3.1089 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1092 - acc: 0.1124 - val_loss: 3.1089 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 3.1092 - acc: 0.1124 - val_loss: 3.1089 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1092 - acc: 0.1124 - val_loss: 3.1089 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1092 - acc: 0.1124 - val_loss: 3.1089 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1092 - acc: 0.1124 - val_loss: 3.1090 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1091 - acc: 0.1124 - val_loss: 3.1089 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1092 - acc: 0.1124 - val_loss: 3.1088 - val_acc: 0.1135\n",
      "Test loss: 3.1088435592651367\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 1.568332024397552\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 57.4077 - acc: 0.1461 - val_loss: 2.5616 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.5620 - acc: 0.1107 - val_loss: 2.5612 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5615 - acc: 0.1117 - val_loss: 2.5614 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.5616 - acc: 0.1123 - val_loss: 2.5614 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5615 - acc: 0.1121 - val_loss: 2.5611 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5615 - acc: 0.1124 - val_loss: 2.5612 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.5615 - acc: 0.1124 - val_loss: 2.5613 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.5615 - acc: 0.1124 - val_loss: 2.5612 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.5615 - acc: 0.1124 - val_loss: 2.5611 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5614 - acc: 0.1124 - val_loss: 2.5611 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5614 - acc: 0.1124 - val_loss: 2.5612 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.5615 - acc: 0.1124 - val_loss: 2.5612 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.5614 - acc: 0.1124 - val_loss: 2.5612 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.5614 - acc: 0.1124 - val_loss: 2.5611 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.5614 - acc: 0.1124 - val_loss: 2.5612 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.5614 - acc: 0.1124 - val_loss: 2.5611 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.5614 - acc: 0.1124 - val_loss: 2.5612 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.5614 - acc: 0.1124 - val_loss: 2.5612 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.5614 - acc: 0.1124 - val_loss: 2.5612 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.5614 - acc: 0.1124 - val_loss: 2.5612 - val_acc: 0.1135\n",
      "Test loss: 2.561189179611206\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 3.0020740138267867\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 108.1053 - acc: 0.1366 - val_loss: 2.7998 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7999 - acc: 0.1105 - val_loss: 2.7991 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7997 - acc: 0.1117 - val_loss: 2.7995 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7994 - acc: 0.1122 - val_loss: 2.7993 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7994 - acc: 0.1124 - val_loss: 2.7991 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7993 - acc: 0.1124 - val_loss: 2.7991 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7993 - acc: 0.1124 - val_loss: 2.7992 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7993 - acc: 0.1124 - val_loss: 2.7990 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7993 - acc: 0.1124 - val_loss: 2.7991 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7993 - acc: 0.1124 - val_loss: 2.7991 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7993 - acc: 0.1124 - val_loss: 2.7989 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7993 - acc: 0.1124 - val_loss: 2.7991 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7993 - acc: 0.1124 - val_loss: 2.7991 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7993 - acc: 0.1124 - val_loss: 2.7990 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7993 - acc: 0.1124 - val_loss: 2.7990 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7993 - acc: 0.1124 - val_loss: 2.7990 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7992 - acc: 0.1124 - val_loss: 2.7991 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7992 - acc: 0.1124 - val_loss: 2.7989 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7993 - acc: 0.1124 - val_loss: 2.7991 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7992 - acc: 0.1124 - val_loss: 2.7990 - val_acc: 0.1135\n",
      "Test loss: 2.798963117599487\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 2.239395435785369\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 81.1331 - acc: 0.1394 - val_loss: 2.6733 - val_acc: 0.1032\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6734 - acc: 0.1117 - val_loss: 2.6727 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6732 - acc: 0.1117 - val_loss: 2.6727 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6731 - acc: 0.1122 - val_loss: 2.6727 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6728 - acc: 0.1124 - val_loss: 2.6725 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6728 - acc: 0.1124 - val_loss: 2.6726 - val_acc: 0.1135\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6728 - acc: 0.1124 - val_loss: 2.6725 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6728 - acc: 0.1124 - val_loss: 2.6725 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6728 - acc: 0.1124 - val_loss: 2.6724 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6728 - acc: 0.1124 - val_loss: 2.6725 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6727 - acc: 0.1124 - val_loss: 2.6726 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6728 - acc: 0.1124 - val_loss: 2.6725 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6728 - acc: 0.1124 - val_loss: 2.6725 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6727 - acc: 0.1124 - val_loss: 2.6726 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6727 - acc: 0.1124 - val_loss: 2.6725 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6727 - acc: 0.1124 - val_loss: 2.6725 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6727 - acc: 0.1124 - val_loss: 2.6725 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6727 - acc: 0.1124 - val_loss: 2.6725 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6727 - acc: 0.1124 - val_loss: 2.6726 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6727 - acc: 0.1124 - val_loss: 2.6724 - val_acc: 0.1135\n",
      "Test loss: 2.6724311557769775\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 2.3910667980148466\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 86.2794 - acc: 0.1390 - val_loss: 2.6976 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6984 - acc: 0.1120 - val_loss: 2.6978 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6983 - acc: 0.1122 - val_loss: 2.6981 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6981 - acc: 0.1124 - val_loss: 2.6978 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6981 - acc: 0.1124 - val_loss: 2.6977 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6980 - acc: 0.1124 - val_loss: 2.6977 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6980 - acc: 0.1124 - val_loss: 2.6977 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6979 - acc: 0.1124 - val_loss: 2.6976 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6979 - acc: 0.1124 - val_loss: 2.6977 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6979 - acc: 0.1124 - val_loss: 2.6977 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6979 - acc: 0.1124 - val_loss: 2.6977 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6979 - acc: 0.1124 - val_loss: 2.6977 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6979 - acc: 0.1124 - val_loss: 2.6977 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6979 - acc: 0.1124 - val_loss: 2.6976 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6979 - acc: 0.1124 - val_loss: 2.6977 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6979 - acc: 0.1124 - val_loss: 2.6977 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6979 - acc: 0.1124 - val_loss: 2.6977 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6979 - acc: 0.1124 - val_loss: 2.6976 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6979 - acc: 0.1124 - val_loss: 2.6977 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6979 - acc: 0.1124 - val_loss: 2.6976 - val_acc: 0.1135\n",
      "Test loss: 2.6976188411712645\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 3.2222401447095304\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 115.6325 - acc: 0.1427 - val_loss: 2.8363 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8364 - acc: 0.1112 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8362 - acc: 0.1121 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8360 - acc: 0.1124 - val_loss: 2.8355 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8359 - acc: 0.1124 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8358 - acc: 0.1124 - val_loss: 2.8355 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8359 - acc: 0.1124 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8358 - acc: 0.1124 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8359 - acc: 0.1124 - val_loss: 2.8355 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8358 - acc: 0.1124 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8358 - acc: 0.1124 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8358 - acc: 0.1124 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8358 - acc: 0.1124 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8358 - acc: 0.1124 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8358 - acc: 0.1124 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8358 - acc: 0.1124 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8358 - acc: 0.1124 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8358 - acc: 0.1124 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8358 - acc: 0.1124 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.8358 - acc: 0.1124 - val_loss: 2.8356 - val_acc: 0.1135\n",
      "Test loss: 2.8355579471588133\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 1.1728433812216947\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 43.4966 - acc: 0.1572 - val_loss: 2.4965 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4965 - acc: 0.1107 - val_loss: 2.4962 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4963 - acc: 0.1119 - val_loss: 2.4958 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4960 - acc: 0.1124 - val_loss: 2.4957 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4960 - acc: 0.1124 - val_loss: 2.4956 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4959 - acc: 0.1124 - val_loss: 2.4956 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4958 - acc: 0.1124 - val_loss: 2.4957 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4959 - acc: 0.1124 - val_loss: 2.4955 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4958 - acc: 0.1124 - val_loss: 2.4955 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4958 - acc: 0.1124 - val_loss: 2.4956 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4958 - acc: 0.1124 - val_loss: 2.4956 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4958 - acc: 0.1124 - val_loss: 2.4956 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4958 - acc: 0.1124 - val_loss: 2.4957 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4958 - acc: 0.1124 - val_loss: 2.4955 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4958 - acc: 0.1124 - val_loss: 2.4955 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4958 - acc: 0.1124 - val_loss: 2.4956 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4958 - acc: 0.1124 - val_loss: 2.4956 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4958 - acc: 0.1124 - val_loss: 2.4956 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4958 - acc: 0.1124 - val_loss: 2.4955 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4958 - acc: 0.1124 - val_loss: 2.4956 - val_acc: 0.1135\n",
      "Test loss: 2.4956221797943114\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 2.521603946419071\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 91.0593 - acc: 0.1369 - val_loss: 2.7211 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7202 - acc: 0.1118 - val_loss: 2.7202 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7199 - acc: 0.1118 - val_loss: 2.7196 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7198 - acc: 0.1124 - val_loss: 2.7194 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7197 - acc: 0.1124 - val_loss: 2.7195 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7196 - acc: 0.1124 - val_loss: 2.7194 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7196 - acc: 0.1124 - val_loss: 2.7195 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7196 - acc: 0.1124 - val_loss: 2.7194 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7196 - acc: 0.1124 - val_loss: 2.7193 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7196 - acc: 0.1124 - val_loss: 2.7193 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7196 - acc: 0.1124 - val_loss: 2.7193 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7196 - acc: 0.1124 - val_loss: 2.7194 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7196 - acc: 0.1124 - val_loss: 2.7193 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7195 - acc: 0.1124 - val_loss: 2.7193 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7195 - acc: 0.1124 - val_loss: 2.7193 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7196 - acc: 0.1124 - val_loss: 2.7192 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7195 - acc: 0.1124 - val_loss: 2.7193 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7195 - acc: 0.1124 - val_loss: 2.7193 - val_acc: 0.1135\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7195 - acc: 0.1124 - val_loss: 2.7194 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7195 - acc: 0.1124 - val_loss: 2.7193 - val_acc: 0.1135\n",
      "Test loss: 2.719317379760742\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.8278994807864386\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 31.4524 - acc: 0.1563 - val_loss: 2.4396 - val_acc: 0.1028\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.4393 - acc: 0.1109 - val_loss: 2.4389 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.4391 - acc: 0.1118 - val_loss: 2.4388 - val_acc: 0.1028\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.4389 - acc: 0.1116 - val_loss: 2.4386 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.4388 - acc: 0.1124 - val_loss: 2.4386 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.4387 - acc: 0.1124 - val_loss: 2.4386 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4387 - acc: 0.1124 - val_loss: 2.4385 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.4387 - acc: 0.1124 - val_loss: 2.4384 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.4387 - acc: 0.1124 - val_loss: 2.4383 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4387 - acc: 0.1124 - val_loss: 2.4383 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.4386 - acc: 0.1124 - val_loss: 2.4382 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.4386 - acc: 0.1124 - val_loss: 2.4383 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4386 - acc: 0.1124 - val_loss: 2.4383 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4386 - acc: 0.1124 - val_loss: 2.4383 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.4386 - acc: 0.1124 - val_loss: 2.4384 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4386 - acc: 0.1124 - val_loss: 2.4383 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4386 - acc: 0.1124 - val_loss: 2.4383 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 2.4386 - acc: 0.1124 - val_loss: 2.4383 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.4386 - acc: 0.1124 - val_loss: 2.4384 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4386 - acc: 0.1124 - val_loss: 2.4384 - val_acc: 0.1135\n",
      "Test loss: 2.4384285163879396\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 2.3869331606777835\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 86.3813 - acc: 0.1373 - val_loss: 2.6974 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6977 - acc: 0.1112 - val_loss: 2.6972 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6975 - acc: 0.1120 - val_loss: 2.6972 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.6974 - acc: 0.1120 - val_loss: 2.6973 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.6973 - acc: 0.1124 - val_loss: 2.6969 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.6973 - acc: 0.1124 - val_loss: 2.6971 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6972 - acc: 0.1124 - val_loss: 2.6970 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6973 - acc: 0.1124 - val_loss: 2.6970 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6972 - acc: 0.1124 - val_loss: 2.6970 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6972 - acc: 0.1124 - val_loss: 2.6969 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6973 - acc: 0.1124 - val_loss: 2.6970 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6973 - acc: 0.1124 - val_loss: 2.6970 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6972 - acc: 0.1124 - val_loss: 2.6970 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6972 - acc: 0.1124 - val_loss: 2.6970 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6972 - acc: 0.1124 - val_loss: 2.6970 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6972 - acc: 0.1124 - val_loss: 2.6969 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6972 - acc: 0.1124 - val_loss: 2.6970 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6972 - acc: 0.1124 - val_loss: 2.6970 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6972 - acc: 0.1124 - val_loss: 2.6970 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6972 - acc: 0.1124 - val_loss: 2.6970 - val_acc: 0.1135\n",
      "Test loss: 2.6970286102294923\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 3.011440928342537\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 21us/step - loss: 108.2448 - acc: 0.1365 - val_loss: 2.8009 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8012 - acc: 0.1107 - val_loss: 2.8017 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8011 - acc: 0.1119 - val_loss: 2.8011 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8011 - acc: 0.1124 - val_loss: 2.8005 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8009 - acc: 0.1123 - val_loss: 2.8008 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.8009 - acc: 0.1124 - val_loss: 2.8008 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8009 - acc: 0.1124 - val_loss: 2.8005 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8009 - acc: 0.1124 - val_loss: 2.8005 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.8009 - acc: 0.1124 - val_loss: 2.8007 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8009 - acc: 0.1124 - val_loss: 2.8007 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8008 - acc: 0.1124 - val_loss: 2.8006 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8008 - acc: 0.1124 - val_loss: 2.8005 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8008 - acc: 0.1124 - val_loss: 2.8006 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8009 - acc: 0.1124 - val_loss: 2.8006 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8008 - acc: 0.1124 - val_loss: 2.8006 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8008 - acc: 0.1124 - val_loss: 2.8006 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8008 - acc: 0.1124 - val_loss: 2.8006 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8008 - acc: 0.1124 - val_loss: 2.8006 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8008 - acc: 0.1124 - val_loss: 2.8006 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.8008 - acc: 0.1124 - val_loss: 2.8005 - val_acc: 0.1135\n",
      "Test loss: 2.800538907241821\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 2.950320423009912\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 106.2385 - acc: 0.1422 - val_loss: 2.7916 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7913 - acc: 0.1120 - val_loss: 2.7905 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7909 - acc: 0.1122 - val_loss: 2.7910 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7909 - acc: 0.1120 - val_loss: 2.7905 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7908 - acc: 0.1124 - val_loss: 2.7904 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7908 - acc: 0.1124 - val_loss: 2.7905 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.7907 - acc: 0.1124 - val_loss: 2.7904 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7907 - acc: 0.1124 - val_loss: 2.7904 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7907 - acc: 0.1124 - val_loss: 2.7905 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.7907 - acc: 0.1124 - val_loss: 2.7906 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.7907 - acc: 0.1124 - val_loss: 2.7904 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7907 - acc: 0.1124 - val_loss: 2.7904 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.7907 - acc: 0.1124 - val_loss: 2.7905 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7907 - acc: 0.1124 - val_loss: 2.7904 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7907 - acc: 0.1124 - val_loss: 2.7904 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7907 - acc: 0.1124 - val_loss: 2.7904 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7907 - acc: 0.1124 - val_loss: 2.7904 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7907 - acc: 0.1124 - val_loss: 2.7904 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7907 - acc: 0.1124 - val_loss: 2.7903 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7907 - acc: 0.1124 - val_loss: 2.7904 - val_acc: 0.1135\n",
      "Test loss: 2.7903843845367433\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.33990602186109353\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 13.8791 - acc: 0.5504 - val_loss: 1.6138 - val_acc: 0.6498\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.5338 - acc: 0.6744 - val_loss: 1.4141 - val_acc: 0.7109\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.3880 - acc: 0.7188 - val_loss: 1.3125 - val_acc: 0.7444\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.2965 - acc: 0.7474 - val_loss: 1.2134 - val_acc: 0.7805\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.2318 - acc: 0.7646 - val_loss: 1.1819 - val_acc: 0.7797\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.1892 - acc: 0.7711 - val_loss: 1.1254 - val_acc: 0.7944\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.1531 - acc: 0.7734 - val_loss: 1.1044 - val_acc: 0.7923\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.1257 - acc: 0.7784 - val_loss: 1.1461 - val_acc: 0.7683\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.1067 - acc: 0.7802 - val_loss: 1.0703 - val_acc: 0.7877\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.0886 - acc: 0.7842 - val_loss: 1.0392 - val_acc: 0.8005\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.0747 - acc: 0.7837 - val_loss: 1.0359 - val_acc: 0.7931\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.0616 - acc: 0.7851 - val_loss: 1.0467 - val_acc: 0.7932\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.0534 - acc: 0.7844 - val_loss: 1.0289 - val_acc: 0.7996\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.0427 - acc: 0.7846 - val_loss: 1.0198 - val_acc: 0.7967\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.0330 - acc: 0.7880 - val_loss: 1.0448 - val_acc: 0.7682\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.0270 - acc: 0.7866 - val_loss: 1.0540 - val_acc: 0.7635\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.0171 - acc: 0.7886 - val_loss: 0.9820 - val_acc: 0.8009\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.0116 - acc: 0.7900 - val_loss: 0.9947 - val_acc: 0.7993\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.0079 - acc: 0.7886 - val_loss: 1.0335 - val_acc: 0.7749\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.0031 - acc: 0.7896 - val_loss: 1.0286 - val_acc: 0.7734\n",
      "Test loss: 1.0285612456321716\n",
      "Test accuracy: 0.7734\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.8537929100946587\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 32.3499 - acc: 0.1531 - val_loss: 2.4435 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4436 - acc: 0.1114 - val_loss: 2.4429 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4434 - acc: 0.1119 - val_loss: 2.4428 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4431 - acc: 0.1122 - val_loss: 2.4429 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4431 - acc: 0.1123 - val_loss: 2.4426 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4430 - acc: 0.1124 - val_loss: 2.4427 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4429 - acc: 0.1124 - val_loss: 2.4428 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4429 - acc: 0.1124 - val_loss: 2.4426 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4429 - acc: 0.1124 - val_loss: 2.4427 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4429 - acc: 0.1124 - val_loss: 2.4426 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4429 - acc: 0.1124 - val_loss: 2.4427 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4429 - acc: 0.1124 - val_loss: 2.4427 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4429 - acc: 0.1124 - val_loss: 2.4426 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4429 - acc: 0.1124 - val_loss: 2.4427 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4429 - acc: 0.1124 - val_loss: 2.4426 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4429 - acc: 0.1124 - val_loss: 2.4427 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4429 - acc: 0.1124 - val_loss: 2.4427 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4429 - acc: 0.1124 - val_loss: 2.4427 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4429 - acc: 0.1124 - val_loss: 2.4426 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4429 - acc: 0.1124 - val_loss: 2.4427 - val_acc: 0.1135\n",
      "Test loss: 2.442653723526001\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 4.97800401940925\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 177.9061 - acc: 0.1417 - val_loss: 3.1283 - val_acc: 0.1010\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 3.1277 - acc: 0.1099 - val_loss: 3.1274 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 3.1274 - acc: 0.1123 - val_loss: 3.1272 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 3.1273 - acc: 0.1124 - val_loss: 3.1268 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 3.1272 - acc: 0.1124 - val_loss: 3.1269 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 3.1271 - acc: 0.1124 - val_loss: 3.1268 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 3.1271 - acc: 0.1124 - val_loss: 3.1268 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 3.1271 - acc: 0.1124 - val_loss: 3.1268 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1271 - acc: 0.1124 - val_loss: 3.1269 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1271 - acc: 0.1124 - val_loss: 3.1268 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1271 - acc: 0.1124 - val_loss: 3.1267 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1271 - acc: 0.1124 - val_loss: 3.1268 - val_acc: 0.1135\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1271 - acc: 0.1124 - val_loss: 3.1269 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1271 - acc: 0.1124 - val_loss: 3.1268 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1270 - acc: 0.1124 - val_loss: 3.1268 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1270 - acc: 0.1124 - val_loss: 3.1269 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1270 - acc: 0.1124 - val_loss: 3.1267 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1271 - acc: 0.1124 - val_loss: 3.1268 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1270 - acc: 0.1124 - val_loss: 3.1268 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1270 - acc: 0.1124 - val_loss: 3.1268 - val_acc: 0.1135\n",
      "Test loss: 3.126763243865967\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 2.460148669527674\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 88.8347 - acc: 0.1453 - val_loss: 2.7097 - val_acc: 0.1010\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7101 - acc: 0.1108 - val_loss: 2.7093 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7098 - acc: 0.1116 - val_loss: 2.7094 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7096 - acc: 0.1124 - val_loss: 2.7092 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7095 - acc: 0.1124 - val_loss: 2.7092 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7094 - acc: 0.1124 - val_loss: 2.7092 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7094 - acc: 0.1124 - val_loss: 2.7091 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7094 - acc: 0.1124 - val_loss: 2.7091 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7094 - acc: 0.1124 - val_loss: 2.7091 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7094 - acc: 0.1124 - val_loss: 2.7092 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7094 - acc: 0.1124 - val_loss: 2.7092 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7094 - acc: 0.1124 - val_loss: 2.7091 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7094 - acc: 0.1124 - val_loss: 2.7091 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7094 - acc: 0.1124 - val_loss: 2.7092 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7094 - acc: 0.1124 - val_loss: 2.7091 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.7093 - acc: 0.1124 - val_loss: 2.7091 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.7094 - acc: 0.1124 - val_loss: 2.7091 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7094 - acc: 0.1124 - val_loss: 2.7091 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7094 - acc: 0.1124 - val_loss: 2.7091 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7094 - acc: 0.1124 - val_loss: 2.7091 - val_acc: 0.1135\n",
      "Test loss: 2.7091391510009766\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 1.9979528533548736\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 72.5370 - acc: 0.1440 - val_loss: 2.6328 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6332 - acc: 0.1115 - val_loss: 2.6328 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6331 - acc: 0.1114 - val_loss: 2.6327 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6329 - acc: 0.1124 - val_loss: 2.6325 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6328 - acc: 0.1124 - val_loss: 2.6326 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6328 - acc: 0.1124 - val_loss: 2.6326 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6328 - acc: 0.1124 - val_loss: 2.6326 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.6328 - acc: 0.1124 - val_loss: 2.6325 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.6327 - acc: 0.1124 - val_loss: 2.6324 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6328 - acc: 0.1124 - val_loss: 2.6324 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6327 - acc: 0.1124 - val_loss: 2.6324 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6327 - acc: 0.1124 - val_loss: 2.6325 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6327 - acc: 0.1124 - val_loss: 2.6325 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6327 - acc: 0.1124 - val_loss: 2.6325 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6327 - acc: 0.1124 - val_loss: 2.6325 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.6327 - acc: 0.1124 - val_loss: 2.6325 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6327 - acc: 0.1124 - val_loss: 2.6325 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.6327 - acc: 0.1124 - val_loss: 2.6324 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6327 - acc: 0.1124 - val_loss: 2.6324 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6327 - acc: 0.1124 - val_loss: 2.6324 - val_acc: 0.1135\n",
      "Test loss: 2.632441757965088\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 2.841034152763692\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 102.2991 - acc: 0.1408 - val_loss: 2.7727 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7731 - acc: 0.1113 - val_loss: 2.7733 - val_acc: 0.1028\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7729 - acc: 0.1113 - val_loss: 2.7727 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7728 - acc: 0.1123 - val_loss: 2.7725 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7727 - acc: 0.1124 - val_loss: 2.7724 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7727 - acc: 0.1124 - val_loss: 2.7724 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7726 - acc: 0.1124 - val_loss: 2.7723 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7726 - acc: 0.1124 - val_loss: 2.7724 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7726 - acc: 0.1124 - val_loss: 2.7726 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7726 - acc: 0.1124 - val_loss: 2.7723 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7726 - acc: 0.1124 - val_loss: 2.7723 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7726 - acc: 0.1124 - val_loss: 2.7723 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7726 - acc: 0.1124 - val_loss: 2.7724 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7726 - acc: 0.1124 - val_loss: 2.7723 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7726 - acc: 0.1124 - val_loss: 2.7724 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7726 - acc: 0.1124 - val_loss: 2.7723 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7725 - acc: 0.1124 - val_loss: 2.7724 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7726 - acc: 0.1124 - val_loss: 2.7723 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.7725 - acc: 0.1124 - val_loss: 2.7723 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7725 - acc: 0.1124 - val_loss: 2.7723 - val_acc: 0.1135\n",
      "Test loss: 2.772285889053345\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.391171839036517\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 15.7376 - acc: 0.5211 - val_loss: 1.6973 - val_acc: 0.6521\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.5971 - acc: 0.6596 - val_loss: 1.5056 - val_acc: 0.6871\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.4561 - acc: 0.6908 - val_loss: 1.3734 - val_acc: 0.7106\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.3652 - acc: 0.7176 - val_loss: 1.3032 - val_acc: 0.7400\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.3034 - acc: 0.7396 - val_loss: 1.2956 - val_acc: 0.7337\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.2506 - acc: 0.7593 - val_loss: 1.1913 - val_acc: 0.7812\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.2095 - acc: 0.7703 - val_loss: 1.1820 - val_acc: 0.7631\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.1818 - acc: 0.7715 - val_loss: 1.2046 - val_acc: 0.7465\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.1566 - acc: 0.7742 - val_loss: 1.0993 - val_acc: 0.7980\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.1396 - acc: 0.7757 - val_loss: 1.0710 - val_acc: 0.8071\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.1227 - acc: 0.7766 - val_loss: 1.1657 - val_acc: 0.7395\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.1090 - acc: 0.7806 - val_loss: 1.0887 - val_acc: 0.7811\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.0993 - acc: 0.7790 - val_loss: 1.0596 - val_acc: 0.7930\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.0869 - acc: 0.7812 - val_loss: 1.0950 - val_acc: 0.7704\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.0783 - acc: 0.7810 - val_loss: 1.1378 - val_acc: 0.7401\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.0725 - acc: 0.7822 - val_loss: 1.0468 - val_acc: 0.7834\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.0646 - acc: 0.7809 - val_loss: 1.0356 - val_acc: 0.7994\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.0532 - acc: 0.7848 - val_loss: 1.0958 - val_acc: 0.7618\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.0502 - acc: 0.7841 - val_loss: 1.1032 - val_acc: 0.7494\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.0419 - acc: 0.7857 - val_loss: 0.9953 - val_acc: 0.8036\n",
      "Test loss: 0.9953286781311035\n",
      "Test accuracy: 0.8036\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.07339817919732688\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 22us/step - loss: 3.9693 - acc: 0.7766 - val_loss: 1.1037 - val_acc: 0.7551\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.9106 - acc: 0.8509 - val_loss: 0.7897 - val_acc: 0.8831\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.7905 - acc: 0.8690 - val_loss: 0.7194 - val_acc: 0.8869\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.7318 - acc: 0.8763 - val_loss: 0.6674 - val_acc: 0.8930\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.6902 - acc: 0.8843 - val_loss: 0.6529 - val_acc: 0.9013\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.6630 - acc: 0.8886 - val_loss: 0.6714 - val_acc: 0.8766\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.6395 - acc: 0.8918 - val_loss: 0.5981 - val_acc: 0.9034\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.6230 - acc: 0.8957 - val_loss: 0.5794 - val_acc: 0.9073\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.6089 - acc: 0.8991 - val_loss: 0.5818 - val_acc: 0.9026\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5946 - acc: 0.9009 - val_loss: 0.6392 - val_acc: 0.8831\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5853 - acc: 0.9025 - val_loss: 0.5427 - val_acc: 0.9102\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5716 - acc: 0.9048 - val_loss: 0.5395 - val_acc: 0.9117\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5618 - acc: 0.9060 - val_loss: 0.5769 - val_acc: 0.8906\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5567 - acc: 0.9058 - val_loss: 0.5283 - val_acc: 0.9163\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5482 - acc: 0.9079 - val_loss: 0.5762 - val_acc: 0.8984\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5426 - acc: 0.9080 - val_loss: 0.5229 - val_acc: 0.9126\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5346 - acc: 0.9104 - val_loss: 0.4914 - val_acc: 0.9200\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5322 - acc: 0.9086 - val_loss: 0.5990 - val_acc: 0.8751\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5252 - acc: 0.9115 - val_loss: 0.5878 - val_acc: 0.8753\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5212 - acc: 0.9102 - val_loss: 0.6151 - val_acc: 0.8780\n",
      "Test loss: 0.615082698726654\n",
      "Test accuracy: 0.878\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.00035046016383383227\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.4439 - acc: 0.9285 - val_loss: 0.2491 - val_acc: 0.9659\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2147 - acc: 0.9676 - val_loss: 0.1979 - val_acc: 0.9683\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1622 - acc: 0.9743 - val_loss: 0.1534 - val_acc: 0.9738\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1379 - acc: 0.9788 - val_loss: 0.1422 - val_acc: 0.9747\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1223 - acc: 0.9802 - val_loss: 0.1319 - val_acc: 0.9763\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1124 - acc: 0.9817 - val_loss: 0.1134 - val_acc: 0.9805\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.1049 - acc: 0.9832 - val_loss: 0.1243 - val_acc: 0.9761\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0995 - acc: 0.9840 - val_loss: 0.1380 - val_acc: 0.9710\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0952 - acc: 0.9842 - val_loss: 0.1223 - val_acc: 0.9767\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0907 - acc: 0.9851 - val_loss: 0.1105 - val_acc: 0.9811\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0889 - acc: 0.9852 - val_loss: 0.1229 - val_acc: 0.9751\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0855 - acc: 0.9863 - val_loss: 0.1042 - val_acc: 0.9814\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0832 - acc: 0.9867 - val_loss: 0.1187 - val_acc: 0.9771\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0824 - acc: 0.9862 - val_loss: 0.1117 - val_acc: 0.9783\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0808 - acc: 0.9862 - val_loss: 0.1102 - val_acc: 0.9785\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0797 - acc: 0.9871 - val_loss: 0.1174 - val_acc: 0.9763\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0781 - acc: 0.9871 - val_loss: 0.1280 - val_acc: 0.9755\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0754 - acc: 0.9878 - val_loss: 0.1074 - val_acc: 0.9804\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0743 - acc: 0.9885 - val_loss: 0.1007 - val_acc: 0.9819\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0745 - acc: 0.9880 - val_loss: 0.0965 - val_acc: 0.9832\n",
      "Test loss: 0.09648782815933228\n",
      "Test accuracy: 0.9832\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 3.7139345918144686\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 133.0276 - acc: 0.1462 - val_loss: 2.9175 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9181 - acc: 0.1109 - val_loss: 2.9174 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9177 - acc: 0.1122 - val_loss: 2.9176 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9176 - acc: 0.1124 - val_loss: 2.9173 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9175 - acc: 0.1124 - val_loss: 2.9174 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9175 - acc: 0.1124 - val_loss: 2.9171 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9174 - acc: 0.1124 - val_loss: 2.9171 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9174 - acc: 0.1124 - val_loss: 2.9172 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9174 - acc: 0.1124 - val_loss: 2.9171 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9174 - acc: 0.1124 - val_loss: 2.9171 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9174 - acc: 0.1124 - val_loss: 2.9172 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9174 - acc: 0.1124 - val_loss: 2.9171 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9174 - acc: 0.1124 - val_loss: 2.9171 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9174 - acc: 0.1124 - val_loss: 2.9171 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9174 - acc: 0.1124 - val_loss: 2.9171 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9174 - acc: 0.1124 - val_loss: 2.9171 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9173 - acc: 0.1124 - val_loss: 2.9172 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9174 - acc: 0.1124 - val_loss: 2.9171 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9174 - acc: 0.1124 - val_loss: 2.9171 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.9173 - acc: 0.1124 - val_loss: 2.9171 - val_acc: 0.1135\n",
      "Test loss: 2.9171157333374023\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.008318658725945277\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1.3064 - acc: 0.8803 - val_loss: 0.4902 - val_acc: 0.9272\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4607 - acc: 0.9269 - val_loss: 0.3747 - val_acc: 0.9482\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3813 - acc: 0.9392 - val_loss: 0.3693 - val_acc: 0.9416\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3370 - acc: 0.9471 - val_loss: 0.3228 - val_acc: 0.9467\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3106 - acc: 0.9509 - val_loss: 0.2817 - val_acc: 0.9610\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2933 - acc: 0.9539 - val_loss: 0.2961 - val_acc: 0.9522\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2809 - acc: 0.9558 - val_loss: 0.2585 - val_acc: 0.9598\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2727 - acc: 0.9566 - val_loss: 0.2559 - val_acc: 0.9571\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2661 - acc: 0.9579 - val_loss: 0.2697 - val_acc: 0.9589\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2588 - acc: 0.9585 - val_loss: 0.2461 - val_acc: 0.9620\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2548 - acc: 0.9587 - val_loss: 0.2516 - val_acc: 0.9591\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2505 - acc: 0.9599 - val_loss: 0.2417 - val_acc: 0.9621\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2465 - acc: 0.9598 - val_loss: 0.2503 - val_acc: 0.9574\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2445 - acc: 0.9599 - val_loss: 0.2533 - val_acc: 0.9560\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2398 - acc: 0.9619 - val_loss: 0.3009 - val_acc: 0.9393\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2390 - acc: 0.9602 - val_loss: 0.2227 - val_acc: 0.9646\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2351 - acc: 0.9617 - val_loss: 0.2282 - val_acc: 0.9615\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2332 - acc: 0.9613 - val_loss: 0.2403 - val_acc: 0.9580\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2319 - acc: 0.9614 - val_loss: 0.2791 - val_acc: 0.9447\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2291 - acc: 0.9623 - val_loss: 0.3224 - val_acc: 0.9290\n",
      "Test loss: 0.32244079258441927\n",
      "Test accuracy: 0.929\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_79 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.01947631609968073\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 1.8585 - acc: 0.8510 - val_loss: 0.6680 - val_acc: 0.8936\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.6022 - acc: 0.9029 - val_loss: 0.5232 - val_acc: 0.9118\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.5063 - acc: 0.9178 - val_loss: 0.4370 - val_acc: 0.9321\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4571 - acc: 0.9269 - val_loss: 0.4453 - val_acc: 0.9236\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4255 - acc: 0.9325 - val_loss: 0.3776 - val_acc: 0.9447\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4033 - acc: 0.9362 - val_loss: 0.4115 - val_acc: 0.9304\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3881 - acc: 0.9389 - val_loss: 0.3921 - val_acc: 0.9354\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3741 - acc: 0.9404 - val_loss: 0.3467 - val_acc: 0.9529\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3642 - acc: 0.9417 - val_loss: 0.3455 - val_acc: 0.9450\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3567 - acc: 0.9436 - val_loss: 0.3392 - val_acc: 0.9443\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3483 - acc: 0.9444 - val_loss: 0.3419 - val_acc: 0.9477\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3424 - acc: 0.9451 - val_loss: 0.3119 - val_acc: 0.9524\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3373 - acc: 0.9465 - val_loss: 0.3234 - val_acc: 0.9477\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3310 - acc: 0.9472 - val_loss: 0.3368 - val_acc: 0.9398\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3294 - acc: 0.9466 - val_loss: 0.3163 - val_acc: 0.9539\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3244 - acc: 0.9469 - val_loss: 0.3012 - val_acc: 0.9538\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3191 - acc: 0.9483 - val_loss: 0.2971 - val_acc: 0.9565\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3155 - acc: 0.9486 - val_loss: 0.2983 - val_acc: 0.9523\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3131 - acc: 0.9492 - val_loss: 0.3187 - val_acc: 0.9466\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3125 - acc: 0.9487 - val_loss: 0.2843 - val_acc: 0.9585\n",
      "Test loss: 0.2842605022668839\n",
      "Test accuracy: 0.9585\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_82 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 4.283136641258872\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 153.0968 - acc: 0.1453 - val_loss: 3.0124 - val_acc: 0.1028\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.0124 - acc: 0.1117 - val_loss: 3.0120 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.0121 - acc: 0.1123 - val_loss: 3.0118 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.0120 - acc: 0.1120 - val_loss: 3.0115 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.0119 - acc: 0.1124 - val_loss: 3.0116 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.0119 - acc: 0.1124 - val_loss: 3.0116 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.0119 - acc: 0.1124 - val_loss: 3.0115 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.0118 - acc: 0.1124 - val_loss: 3.0116 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.0118 - acc: 0.1124 - val_loss: 3.0115 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.0118 - acc: 0.1124 - val_loss: 3.0115 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 3.0118 - acc: 0.1124 - val_loss: 3.0116 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 3.0118 - acc: 0.1124 - val_loss: 3.0115 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 3.0118 - acc: 0.1124 - val_loss: 3.0115 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 3.0118 - acc: 0.1124 - val_loss: 3.0116 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 3.0118 - acc: 0.1124 - val_loss: 3.0116 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 3.0118 - acc: 0.1124 - val_loss: 3.0115 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 3.0118 - acc: 0.1124 - val_loss: 3.0116 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 3.0118 - acc: 0.1124 - val_loss: 3.0115 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 3.0118 - acc: 0.1124 - val_loss: 3.0115 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 3.0118 - acc: 0.1124 - val_loss: 3.0116 - val_acc: 0.1135\n",
      "Test loss: 3.011554498291016\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 1.7552187984075087\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 63.9976 - acc: 0.1473 - val_loss: 2.5928 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.5930 - acc: 0.1109 - val_loss: 2.5923 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.5928 - acc: 0.1111 - val_loss: 2.5926 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.5926 - acc: 0.1123 - val_loss: 2.5923 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5926 - acc: 0.1124 - val_loss: 2.5923 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5925 - acc: 0.1124 - val_loss: 2.5923 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.5925 - acc: 0.1124 - val_loss: 2.5921 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.5925 - acc: 0.1124 - val_loss: 2.5922 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5925 - acc: 0.1124 - val_loss: 2.5922 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5925 - acc: 0.1124 - val_loss: 2.5921 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5924 - acc: 0.1124 - val_loss: 2.5923 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5925 - acc: 0.1124 - val_loss: 2.5922 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.5924 - acc: 0.1124 - val_loss: 2.5922 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5924 - acc: 0.1124 - val_loss: 2.5923 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5924 - acc: 0.1124 - val_loss: 2.5922 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5924 - acc: 0.1124 - val_loss: 2.5922 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5924 - acc: 0.1124 - val_loss: 2.5922 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5924 - acc: 0.1124 - val_loss: 2.5922 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5924 - acc: 0.1124 - val_loss: 2.5922 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.5924 - acc: 0.1124 - val_loss: 2.5922 - val_acc: 0.1135\n",
      "Test loss: 2.59221547203064\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 1.4215246973663331\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 52.4269 - acc: 0.1415 - val_loss: 2.5389 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.5380 - acc: 0.1111 - val_loss: 2.5372 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.5375 - acc: 0.1109 - val_loss: 2.5370 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.5374 - acc: 0.1124 - val_loss: 2.5373 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.5372 - acc: 0.1124 - val_loss: 2.5369 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.5372 - acc: 0.1124 - val_loss: 2.5368 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.5372 - acc: 0.1124 - val_loss: 2.5369 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.5371 - acc: 0.1124 - val_loss: 2.5369 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.5371 - acc: 0.1124 - val_loss: 2.5369 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.5371 - acc: 0.1124 - val_loss: 2.5369 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.5371 - acc: 0.1124 - val_loss: 2.5369 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.5371 - acc: 0.1124 - val_loss: 2.5368 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.5371 - acc: 0.1124 - val_loss: 2.5368 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.5371 - acc: 0.1124 - val_loss: 2.5369 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.5371 - acc: 0.1124 - val_loss: 2.5368 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.5371 - acc: 0.1124 - val_loss: 2.5369 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.5371 - acc: 0.1124 - val_loss: 2.5368 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.5371 - acc: 0.1124 - val_loss: 2.5369 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.5371 - acc: 0.1124 - val_loss: 2.5368 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.5370 - acc: 0.1124 - val_loss: 2.5368 - val_acc: 0.1135\n",
      "Test loss: 2.5368324352264406\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.45880775848752586\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 18.1901 - acc: 0.3861 - val_loss: 1.8719 - val_acc: 0.4731\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.8178 - acc: 0.4754 - val_loss: 1.7047 - val_acc: 0.5258\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.7043 - acc: 0.5189 - val_loss: 1.6161 - val_acc: 0.5653\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.6407 - acc: 0.5452 - val_loss: 1.6770 - val_acc: 0.4845\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.5838 - acc: 0.5738 - val_loss: 1.5219 - val_acc: 0.5983\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.5138 - acc: 0.6341 - val_loss: 1.4121 - val_acc: 0.6837\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.4102 - acc: 0.6888 - val_loss: 1.4085 - val_acc: 0.6581\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.3521 - acc: 0.7023 - val_loss: 1.2883 - val_acc: 0.7373\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.3111 - acc: 0.7118 - val_loss: 1.2873 - val_acc: 0.7165\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2823 - acc: 0.7161 - val_loss: 1.2146 - val_acc: 0.7530\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2597 - acc: 0.7206 - val_loss: 1.2776 - val_acc: 0.7160\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.2437 - acc: 0.7246 - val_loss: 1.3041 - val_acc: 0.6712\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2282 - acc: 0.7271 - val_loss: 1.2202 - val_acc: 0.7199\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.2142 - acc: 0.7294 - val_loss: 1.1686 - val_acc: 0.7472\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.2005 - acc: 0.7334 - val_loss: 1.1611 - val_acc: 0.7560\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1865 - acc: 0.7345 - val_loss: 1.2314 - val_acc: 0.7181\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1833 - acc: 0.7353 - val_loss: 1.2896 - val_acc: 0.6911\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.1731 - acc: 0.7346 - val_loss: 1.1037 - val_acc: 0.7727\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1647 - acc: 0.7368 - val_loss: 1.1513 - val_acc: 0.7550\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1562 - acc: 0.7376 - val_loss: 1.1393 - val_acc: 0.7453\n",
      "Test loss: 1.1393246723175048\n",
      "Test accuracy: 0.7453\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_94 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 1.1628826443141567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 43.1862 - acc: 0.1497 - val_loss: 2.4947 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4947 - acc: 0.1110 - val_loss: 2.4954 - val_acc: 0.1009\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4946 - acc: 0.1112 - val_loss: 2.4943 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4944 - acc: 0.1121 - val_loss: 2.4941 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4943 - acc: 0.1124 - val_loss: 2.4941 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4943 - acc: 0.1124 - val_loss: 2.4941 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4942 - acc: 0.1124 - val_loss: 2.4940 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4942 - acc: 0.1124 - val_loss: 2.4940 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4942 - acc: 0.1124 - val_loss: 2.4940 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4942 - acc: 0.1124 - val_loss: 2.4939 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4942 - acc: 0.1124 - val_loss: 2.4939 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4942 - acc: 0.1124 - val_loss: 2.4939 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4942 - acc: 0.1124 - val_loss: 2.4939 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4942 - acc: 0.1124 - val_loss: 2.4939 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4942 - acc: 0.1124 - val_loss: 2.4939 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4942 - acc: 0.1124 - val_loss: 2.4939 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4942 - acc: 0.1124 - val_loss: 2.4939 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4942 - acc: 0.1124 - val_loss: 2.4939 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4942 - acc: 0.1124 - val_loss: 2.4939 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4941 - acc: 0.1124 - val_loss: 2.4939 - val_acc: 0.1135\n",
      "Test loss: 2.493887739562988\n",
      "Test accuracy: 0.1135\n",
      "{'l2': 0.00035046016383383227}\n",
      "{'spec': None, 'exp_key': None, 'refresh_time': datetime.datetime(2018, 9, 1, 9, 9, 42, 690000), 'result': {'loss': -0.9832, 'status': 'ok'}, 'book_time': datetime.datetime(2018, 9, 1, 9, 9, 24, 148000), 'owner': None, 'misc': {'vals': {'l2': [0.00035046016383383227]}, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'tid': 21, 'idxs': {'l2': [21]}, 'workdir': None}, 'state': 2, 'tid': 21, 'version': 0}\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    model_2 = Sequential()\n",
    "    model_2.add(Dense(512, activation='relu', input_shape=(784,), kernel_regularizer=regularizers.l2(params['l2'])))\n",
    "    # model_2.add(Dropout(0.2))\n",
    "    model_2.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(params['l2'])))\n",
    "    # model_2.add(Dropout(0.2))\n",
    "    model_2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_2.summary()\n",
    "    \n",
    "    print('training with L2 regularization parameter', params['l2'])\n",
    "    \n",
    "    model_2.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history_2 = model_2.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score_2 = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    print('Test loss:', score_2[0])\n",
    "    print('Test accuracy:', score_2[1])\n",
    "\n",
    "    return {'loss': - score_2[1], 'status': STATUS_OK} \n",
    "\n",
    "space = {\n",
    "    'l2': hp.uniform('l2', 0.0001, 5)\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(objective, space, algo=tpe.suggest, trials=trials, max_evals = 30)\n",
    "print (best)\n",
    "print (trials.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqIAAAGPCAYAAACH27KGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAHBpJREFUeJzt3V9wlPX96PHPk4Bo0N+RELROlyQVgrQWBSVKtNpyemxnvIHR0sw5BXQUsM6Ujide2Ite9MJa5+gvZ6xcVKlQkTlM2uI4jDrTKtP+tDOcIlPRqh0Rj5s/R1AhSAeiFpI9F0zToyRhg5v9ZsPrNZOZpvu4z+d5drd9++xmv1mhUCgEAACUWVXqAQAAODMJUQAAkhCiAAAkIUQBAEhCiAIAkIQQBQAgCSEKAEASQhQAgCSEKAAASQhRAACSmJR6gNGYMmVKzJgxI/UYAAAM44MPPohPPvmkqG0rKkRnzJgRPT09qccAAGAYuVyu6G29NQ8AQBJCFACAJIQoAABJCFEAAJIQogAAJCFEAQBIQogCAJCEEAUAIAkhCgBAEkIUAIAkhCgAAEkIUQAAkhCiAAAkMSn1ABARUSgU4qV8b/zxzQ8iIuLrc+oiy7LoPNgXjXVTY2HDtMiybFzM9o1LZkRzY+2YzlMoFGJX56HIHzh62sdfivsox32Oh32VYn/FPE9G2ke5j/dURjvPcNuX4/Uz3s5dKU3kYyuWc3BCqV6T401WKBQKqYcoVi6Xi56entRjUGI9h/riv67/39Hd+9FJt50zuSqODxRiZm1NbLrtqshNqyn7bP9t/Z+jq7fvU//9zNpzYsvqRWMyT8+hvli5YWd09/bF5OqqONY/MOrjL8V9lOM+x8O+SrG/Yp4nI+0jIsp6vMUcz2jmGW77/3HzZfHff737pNd2fW1N/K/VV5fk2Mr9XCmniXxsxXIOTijVa7Jc5200vSZESapQKMR//vc/xjsH+kbcrroqi8bpNfF829fL9m90hUIhvvnv/xH/58DRIW+/uK4mtt/9jZJf2flm+39E58G+6B/410tzNMdfivsox32Oh32VYn/FPE+eb/t6/Jf/+cKw+xgoFKKr96OyHO+pjPZ8jLR9VRZxrH/o/4uZNWPq5z62cj9XymkiH1uxnIMTSvmaLNd5G02v+YwoSe3qPDTkldDP6h8oRFdvX+zqPFSGqU7Y1XnopCtc/7/OMZhnV+eh6PlMkESM7vhLcR/luM/xsK9S7K+Y58nmP3cNu4/Og33RXcbjPZXRno+Rth8uQiMiOg9+/mMr93OlnCbysRXLOTihlK/J8XjehChJ5Q8cjaoi/8VscnVV5Ie56jQWTsw2/HDVWVbyefIHjsak6qH3Wezxl+I+ynGf42FfpdhfMc+T1/7v4WH3UZVlw74Gyv2cjxj9+Rhp+5FUleD1U+7nSjlN5GMrlnNwQilfk+PxvAlRkmqsmxr9RX465Fj/QDTWTR3jif6lsW5qDIwwW3+hUPJ5GuumxrH+gSFvK/b4S3Ef5bjP8bCvUuyvmOfJV7/4n4bdx0ChMOxroNzP+YjRn4+Rth/JQAleP+V+rpTTRD62YjkHJ5TyNTkez5sQJamFDdOivvbUH5yursqivrYmFjZMK8NUJ5xqtoYxmGdhw7SYWVsT1Z+5RDaa4y/FfZTjPsfDvkqxv2KeJ8uvrh92Hw3Ta6K+jMd7KqM9HyNtP3mEK6UN0z//sZX7uVJOE/nYiuUcnFDK1+R4PG9ClKSyLIsnbr86ZtaeM+Tt50yujsnVJz5gven2q8v6wfQsy2LT7VcNGRn1tefEE6sWlXyeLMti021XRcP0mphcnUXNWaM//lLcRznuczzsqxT7K+Z5UlVVNeI+nrj96rId76mM9nyMtP2WNYuGfG03lOjYyv1cKaeJfGzFcg5OKOVrcjyeN381z7jge0RP3qfvEfU9or5HdGxmrSQT+diK5RycUEnfI+rrmwAASMLXNwEAMO4JUQAAkhCiAAAkIUQBAEhCiAIAkIQQBQAgCSEKAEASQhQAgCSEKAAASQhRAACSEKIAACQhRAEASEKIAgCQhBAFACAJIQoAQBJCFACAJIQoAABJCFEAAJIQogAAJCFEAQBIQogCAJCEEAUAIAkhCgBAEiUJ0YGBgVi7dm3MmjUrZs+eHevWrRtyu48//jiWLl0ac+bMicsvvzxuuOGG2Lt3bylGAACgwpQkRDdv3hxvvPFG7NmzJ3bu3BkPPPBAvP7660Nuu2bNmnjzzTfjlVdeiSVLlsSqVatKMQIAABWmJCHa0dERq1evjurq6qitrY3W1tbYsmXLSdudffbZceONN0aWZRERsWjRosjn86UYAQCAClOSEO3q6oqGhobB3xsbG6Orq+uU/9xDDz0US5YsKcUIAABUmEnFbNTS0hJvvfXWkLe9/PLLp7Xj++67L/bu3Rvbt28fdpv29vZob28f/P3IkSOntS8AAMafokJ0x44dI95eX18fnZ2d0dLSEhER+Xw+6uvrh93+wQcfjCeffDKef/75qKmpGXa7tra2aGtrG/w9l8sVMy4AABWgJG/NL1u2LNavXx/9/f3R29sbHR0d0draOuS27e3tsWXLlnjuuefi/PPPL8XuAQCoQCUJ0RUrVsTcuXOjqakpmpubo62tLebNmxcREdu2bRv8y/ienp64++6748MPP4zFixfH/Pnz4+qrry7FCAAAVJisUCgUUg9RrFwuFz09PanHAABgGKPpNSsrAQCQhBAFACAJIQoAQBJCFACAJIQoAABJCFEAAJIQogAAJCFEAQBIQogCAJCEEAUAIAkhCgBAEkIUAIAkhCgAAEkIUQAAkhCiAAAkIUQBAEhCiAIAkIQQBQAgCSEKAEASQhQAgCSEKAAASQhRAACSEKIAACQhRAEASEKIAgCQhBAFACAJIQoAQBJCFACAJIQoAABJCFEAAJIQogAAJCFEAQBIQogCAJCEEAUAIAkhCgBAEkIUAIAkhCgAAEkIUQAAkhCiAAAkIUQBAEhCiAIAkIQQBQAgCSEKAEASQhQAgCSEKAAASQhRAACSEKIAACQhRAEASEKIAgCQhBAFACAJIQoAQBJCFACAJIQoAABJCFEAAJIQogAAJCFEAQBIQogCAJCEEAUAIAkhCgBAEkIUAIAkhCgAAEkIUQAAkhCiAAAkIUQBAEhCiAIAkIQQBQAgiZKE6MDAQKxduzZmzZoVs2fPjnXr1p3yn9m4cWNkWRZPPfVUKUYAAKDCTCrFnWzevDneeOON2LNnTxw+fDgWLFgQixcvjksvvXTI7fP5fKxfvz4WLVpUit0DAFCBSnJFtKOjI1avXh3V1dVRW1sbra2tsWXLliG3HRgYiFWrVsXDDz8cU6ZMKcXuAQCoQCUJ0a6urmhoaBj8vbGxMbq6uobctr29Pa699tq48sorT3m/7e3tkcvlBn+OHDlSinEBABgHinprvqWlJd56660hb3v55ZeL3tlrr70WW7dujRdeeKGo7dva2qKtrW3w91wuV/S+AAAY34oK0R07dox4e319fXR2dkZLS0tEnPgMaH19/Unbvfjii5HP56OpqSkiIvbv3x9r1qyJffv2xZ133jna2QEAqGBZoVAofN47+dWvfhVPPPFE/P73vx/8Y6Wnn3465s2bN+I/941vfCPuuuuuWLp0aVH7yeVy0dPT83nHBQBgjIym10ryGdEVK1bE3Llzo6mpKZqbm6OtrW0wQrdt2xarVq0qxW4AAJhASnJFtFxcEQUAGN/KfkUUAABGS4gCAJCEEAUAIAkhCgBAEkIUAIAkhCgAAEkIUQAAkhCiAAAkIUQBAEhCiAIAkIQQBQAgCSEKAEASQhQAgCSEKAAASQhRAACSEKIAACQhRAEASEKIAgCQhBAFACAJIQoAQBJCFACAJIQoAABJCFEAAJIQogAAJCFEAQBIQogCAJCEEAUAIAkhCgBAEkIUAIAkhCgAAEkIUQAAkhCiAAAkIUQBAEhCiAIAkIQQBQAgCSEKAEASQhQAgCSEKAAASQhRAACSEKIAACQhRAEASEKIAgCQhBAFACAJIQoAQBJCFACAJIQoAABJCFEAAJIQogAAJCFEAQBIQogCAJCEEAUAIAkhCgBAEkIUAIAkhCgAAEkIUQAAkhCiAAAkIUQBAEhCiAIAkIQQBQAgCSEKAEASQhQAgCSEKAAASQhRAACSEKIAACQhRAEASKIkITowMBBr166NWbNmxezZs2PdunXDbvvJJ5/ED37wg2hqaop58+bF8uXLSzECAAAVZlIp7mTz5s3xxhtvxJ49e+Lw4cOxYMGCWLx4cVx66aUnbfujH/0osiyLPXv2RJZlsX///lKMAABAhSnJFdGOjo5YvXp1VFdXR21tbbS2tsaWLVtO2u7o0aPx2GOPxU9/+tPIsiwiIr7whS+UYgQAACpMSUK0q6srGhoaBn9vbGyMrq6uk7Z7++23o7a2Nu67775YuHBhXHfddbF9+/Zh77e9vT1yudzgz5EjR0oxLgAA40BRIdrS0hJ1dXVD/nR3dxe9s+PHj0dnZ2d85StfiV27dsXPf/7zaG1tjffee2/I7dva2qKnp2fw59xzzy16XwAAjG9FfUZ0x44dI95eX18fnZ2d0dLSEhER+Xw+6uvrh9yuqqoqvve970VExIIFC+JLX/pS/PWvf40LL7xwtLMDAFDBSvLW/LJly2L9+vXR398fvb290dHREa2trSdtV1dXF9/85jfjd7/7XUREvPPOO/HOO+/El7/85VKMAQBABSlJiK5YsSLmzp0bTU1N0dzcHG1tbTFv3ryIiNi2bVusWrVqcNtf/OIX8cADD8S8efNi6dKl8cgjj8QXv/jFUowBAEAFyQqFQiH1EMXK5XLR09OTegwAAIYxml6zshIAAEkIUQAAkhCiAAAkIUQBAEhCiAIAkIQQBQAgCSEKAEASQhQAgCSEKAAASQhRAACSEKIAACQhRAEASEKIAgCQhBAFACAJIQoAQBJCFACAJIQoAABJCFEAAJIQogAAJCFEAQBIQogCAJCEEAUAIAkhCgBAEkIUAIAkhCgAAEkIUQAAkhCiAAAkIUQBAEhCiAIAkIQQBQAgCSEKAEASQhQAgCSEKAAASQhRAACSEKIAACQhRAEASEKIAgCQhBAFACAJIQoAQBJCFACAJIQoAABJCFEAAJIQogAAJCFEAQBIYlLqARh7hUIhdnUeivyBo9FYNzUWNkyLLMtSjwUAnOGE6ATXc6gvVm7YGd29fTG5uiqO9Q/EzNqa2HTbVZGbVpN6PADgDOat+QmsUCjEyg07o/NgXxzrL0TfP/rjWH8hOg/2xS0bdkahUEg9IgBwBhOiE9iuzkPR0/tR9A98Ojj7BwrR1dsXuzoPJZoMAECITmj5A0djUvXQnwWdXF0V+QNHyzwRAMC/CNEJrLFuahzrHxjytmP9A9FYN7XMEwEA/IsQncAWNkyLmbU1UV316aui1VVZ1NfWxMKGaYkmAwAQohNalmWx6baromF6TUyuzqLmrOqYXJ1F4/Sa2HT71b7CCQBIytc3TXC5aTWxve3rvkcUABh3hOgZIMuyaG6sjebG2tSjAAAM8tY8AABJuCJaYSzXCQBMFEK0gliuEwCYSLw1XyEs1wkATDRCtEJYrhMAmGiEaIWwXCcAMNEI0QphuU4AYKIRohXCcp0AwEQjRCuE5ToBgInG1zdVEMt1AgATiRCtMJbrBAAmipK8NT8wMBBr166NWbNmxezZs2PdunXDbvvss8/GFVdcEfPnz4+vfvWr8fjjj5diBAAAKkxJrohu3rw53njjjdizZ08cPnw4FixYEIsXL45LL730U9sVCoVYvnx5/PGPf4zLLrss8vl8zJ07N2666aY477zzSjHKGcvSnwBApSlJiHZ0dMTq1aujuro6amtro7W1NbZs2RL33nvvSdtmWRYffvhhRET8/e9/j+nTp8eUKVNKMcYZy9KfAEAlKslb811dXdHQ0DD4e2NjY3R1dZ20XZZl0dHRETfddFM0NDTE1772tXj88cfjrLPOKsUYZyRLfwIAlaqoEG1paYm6urohf7q7u4ve2fHjx+Pee++NJ598Mjo7O2P79u2xYsWKOHDgwJDbt7e3Ry6XG/w5cuRI0fs6U1j6EwCoVEWF6I4dO+LAgQND/sycOTPq6+ujs7NzcPt8Ph/19fUn3c/u3bvj3Xffjeuvvz4iIpqbmyOXy8XLL7885H7b2tqip6dn8Ofcc889nWOc0Cz9CQBUqpK8Nb9s2bJYv3599Pf3R29vb3R0dERra+tJ282cOTP27dsXf/vb3yIiYu/evfH222/HJZdcUooxzkiW/gQAKlVJ/lhpxYoV8dJLL0VTU1NkWRZtbW0xb968iIjYtm1bbNu2LX75y1/GhRdeGI8++mh897vfjaqqqhgYGIh169YNefWU4vxz6c/Og32fenve0p8AwHiXFSror1lyuVz09PSkHmPcGeqv5utrTyz9+cXzz0k9HgBwBhlNr1lZaQKw9CcAUImE6ARh6U8AoNKU5I+VAABgtIQoAABJCFEAAJIQogAAJCFEAQBIQogCAJCEEAUAIAkhCgBAEkIUAIAkhCgAAEkIUQAAkhCiAAAkIUQBAEhCiAIAkIQQBQAgCSEKAEASQhQAgCSEKAAASUxKPUClKhQKsavzUOQPHI3GuqmxsGFaZFmWeiwAgIohRE9Dz6G+WLlhZ3T39sXk6qo41j8QM2trYtNtV0VuWk3q8QAAKoK35kepUCjEyg07o/NgXxzrL0TfP/rjWH8hOg/2xS0bdkahUEg9IgBARRCio7Sr81D09H4U/QOfDs7+gUJ09fbFrs5DiSYDAKgsQnSU8geOxqTqoT8LOrm6KvIHjpZ5IgCAyiRER6mxbmoc6x8Y8rZj/QPRWDe1zBMBAFQmITpKCxumxczamqiu+vRV0eqqLOpra2Jhw7REkwEAVBYhOkpZlsWm266Khuk1Mbk6i5qzqmNydRaN02ti0+1X+wonAIAi+fqm05CbVhPb277ue0QBAD4HIXqasiyL5sbaaG6sTT0KAEBF8tY8AABJCFEAAJIQogAAJCFEAQBIQogCAJCEEAUAIAkhCgBAEkIUAIAkhCgAAElYWWkEhULBMp4AAGNEiA6j51BfrNywM7p7+2JydVUc6x+ImbU1sem2qyI3rSb1eAAAFc9b80MoFAqxcsPO6DzYF8f6C9H3j/441l+IzoN9ccuGnVEoFFKPCABQ8YToEHZ1Hoqe3o+if+DTwdk/UIiu3r7Y1Xko0WQAABOHEB1C/sDRmFQ99GdBJ1dXRf7A0TJPBAAw8QjRITTWTY1j/QND3nasfyAa66aWeSIAgIlHiA5hYcO0mFlbE9VVn74qWl2VRX1tTSxsmJZoMgCAiUOIDiHLsth021XRML0mJldnUXNWdUyuzqJxek1suv1qX+EEAFACvr5pGLlpNbG97eu+RxQAYIwI0RFkWRbNjbXR3FibehQAgAlHiJ6C1ZUAAMaGEB2B1ZUAAMaOP1YahtWVAADGlhAdhtWVAADGlhAdhtWVAADGlhAdhtWVAADGlhAdhtWVAADGlhAdhtWVAADGlq9vGoHVlQAAxo4QPQWrKwEAjA0hOgwrKgEAjC0hOgQrKgEAjD1/rPQZVlQCACgPIfoZVlQCACgPIfoZVlQCACgPIfoZVlQCACgPIfoZVlQCACiPkoToM888E1deeWVMmTIl7rrrrhG3feutt+Kaa66JOXPmRHNzc7z++uulGKFkrKgEAFAeJfn6pqamptiwYUP85je/iSNHjoy47R133BFr1qyJW2+9NX7729/GrbfeGi+99FIpxigZKyoBAIy9klwRnTNnTlx++eUxadLIXfv+++/Hrl27Yvny5RERcfPNN0d3d3fs3bu3FGOU1D9XVFq2cGY0N9aKUACAEivrZ0S7u7vjoosuGgzWLMuivr4+urq6hty+vb09crnc4M+prrYCAFA5igrRlpaWqKurG/Knu7t7zIZra2uLnp6ewZ9zzz13zPYFAEB5FfUZ0R07dpRkZzNnzox9+/bF8ePHY9KkSVEoFKKrqyvq6+tLcv8AAFSOsr41f8EFF8QVV1wRmzdvjoiIrVu3Ri6Xi9mzZ5dzDAAAxoGShOj27dsjl8tFe3t7PPbYY5HL5WLbtm0REbFt27ZYtWrV4LaPPPJIPPLIIzFnzpy4//77Y+PGjaUYAQCACpMVCoXCqTcbH3K5XPT09KQeAwCAYYym16ysBABAEkIUAIAkhCgAAEkIUQAAkhCiAAAkIUQBAEhCiAIAkERFfY/olClTYsaMGWXd55EjR6xxX+E8hpXPY1j5PIaVz2NY+cr1GH7wwQfxySefFLVtRYVoCr5Ev/J5DCufx7DyeQwrn8ew8o3Hx9Bb8wAAJCFEAQBIovonP/nJT1IPMd61tLSkHoHPyWNY+TyGlc9jWPk8hpVvvD2GPiMKAEAS3poHACAJIQoAQBJCFACAJIToMN5666245pprYs6cOdHc3Byvv/566pEYhR/+8IfR2NgYWZbF7t27U4/Dafj4449j6dKlMWfOnLj88svjhhtuiL1796Yei1H61re+FZdddlnMnz8/rrvuunj55ZdTj8Rp2rhxY2RZFk899VTqURilxsbGuOSSS2L+/Pkxf/786OjoSD3SICE6jDvuuCPWrFkTe/bsiXvuuSduvfXW1CMxCt/5znfiT3/6UzQ0NKQehc9hzZo18eabb8Yrr7wSS5YsiVWrVqUeiVH69a9/Ha+++mrs3r072tra/G9phcrn87F+/fpYtGhR6lE4TR0dHbF79+7YvXt3tLa2ph5nkBAdwvvvvx+7du2K5cuXR0TEzTffHN3d3a7GVJDrr78+crlc6jH4HM4+++y48cYbI8uyiIhYtGhR5PP5tEMxaueff/7gfz58+PDg40nlGBgYiFWrVsXDDz8cU6ZMST0OE8yk1AOMR93d3XHRRRfFpEknTk+WZVFfXx9dXV0xe/bsxNPBmemhhx6KJUuWpB6D07By5cr4wx/+EBERzz77bOJpGK329va49tpr48orr0w9Cp/DypUro1AoxFVXXRX3339/zJgxI/VIEeGKKFAB7rvvvti7d2/87Gc/Sz0Kp2HTpk3R3d0d9957b9xzzz2px2EUXnvttdi6dWv8+Mc/Tj0Kn8MLL7wQr776avzlL3+Jurq6uOWWW1KPNMgV0SHMnDkz9u3bF8ePH49JkyZFoVCIrq6uqK+vTz0anHEefPDBePLJJ+P555+Pmpqa1OPwOdxyyy3x/e9/Pw4ePBjTp09PPQ5FePHFFyOfz0dTU1NEROzfvz/WrFkT+/btizvvvDPxdBTrn/0yefLkuOuuu2LOnDmJJ/oXV0SHcMEFF8QVV1wRmzdvjoiIrVu3Ri6X87Y8lFl7e3ts2bIlnnvuuU991pDK8OGHH8a77747+PtTTz0V06dPj9ra2oRTMRp33nln7Nu3L/L5fOTz+Vi0aFE8+uijIrSCHD16ND788MPB37ds2RILFixIONGnuSI6jEceeSRuvfXWuO++++Lf/u3fYuPGjalHYhTuuOOOeOaZZ2L//v3x7W9/O8477zx/bFZhenp64u67746LL744Fi9eHBERU6ZMiT//+c+JJ6NYhw8fjmXLlsVHH30UVVVVMWPGjHj66af9wRKU0XvvvRc333xz9Pf3R6FQiIsvvjg2bdqUeqxB1poHACAJb80DAJCEEAUAIAkhCgBAEkIUAIAkhCgAAEkIUQAAkhCiAAAkIUQBAEji/wFXsrROwoNuKgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 800x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure(num=None, figsize=(10, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "t = trials.trials\n",
    "\n",
    "y = []\n",
    "x = []\n",
    "for tr in t: \n",
    "    y.append((tr['result']['loss']))\n",
    "    x.append(tr['misc']['vals']['l2'])\n",
    "    \n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be sure, let's run another trial with values between 0 and 1 only: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_232 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.04295182815892902\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 2.7877 - acc: 0.8176 - val_loss: 0.8089 - val_acc: 0.8785\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7735 - acc: 0.8726 - val_loss: 0.6624 - val_acc: 0.8965\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6674 - acc: 0.8910 - val_loss: 0.5815 - val_acc: 0.9137\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6041 - acc: 0.9033 - val_loss: 0.5659 - val_acc: 0.9121\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.5655 - acc: 0.9088 - val_loss: 0.5428 - val_acc: 0.9138\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.5412 - acc: 0.9114 - val_loss: 0.4950 - val_acc: 0.9256\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5206 - acc: 0.9152 - val_loss: 0.5178 - val_acc: 0.9091\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5063 - acc: 0.9172 - val_loss: 0.4693 - val_acc: 0.9316\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4931 - acc: 0.9198 - val_loss: 0.5276 - val_acc: 0.9077\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4818 - acc: 0.9221 - val_loss: 0.5361 - val_acc: 0.8953\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4720 - acc: 0.9232 - val_loss: 0.5037 - val_acc: 0.9118\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4635 - acc: 0.9250 - val_loss: 0.4325 - val_acc: 0.9315\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4589 - acc: 0.9251 - val_loss: 0.4915 - val_acc: 0.9086\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4489 - acc: 0.9276 - val_loss: 0.5189 - val_acc: 0.8937\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.4450 - acc: 0.9279 - val_loss: 0.4260 - val_acc: 0.9360\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4407 - acc: 0.9271 - val_loss: 0.4028 - val_acc: 0.9379\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4378 - acc: 0.9270 - val_loss: 0.4280 - val_acc: 0.9281\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4334 - acc: 0.9278 - val_loss: 0.4122 - val_acc: 0.9325\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.4282 - acc: 0.9294 - val_loss: 0.4473 - val_acc: 0.9148\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.4274 - acc: 0.9272 - val_loss: 0.3774 - val_acc: 0.9428\n",
      "Test loss: 0.37739884507656096\n",
      "Test accuracy: 0.9428\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_235 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.22659074343359872\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 9.7391 - acc: 0.6095 - val_loss: 1.4665 - val_acc: 0.7032\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.3632 - acc: 0.7362 - val_loss: 1.2188 - val_acc: 0.7859\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2053 - acc: 0.7816 - val_loss: 1.1105 - val_acc: 0.8193\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0935 - acc: 0.8175 - val_loss: 1.0252 - val_acc: 0.8315\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0218 - acc: 0.8313 - val_loss: 0.9784 - val_acc: 0.8379\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9781 - acc: 0.8350 - val_loss: 0.9318 - val_acc: 0.8483\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9474 - acc: 0.8375 - val_loss: 0.9063 - val_acc: 0.8439\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9184 - acc: 0.8437 - val_loss: 0.9029 - val_acc: 0.8418\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9028 - acc: 0.8404 - val_loss: 0.8674 - val_acc: 0.8550\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8834 - acc: 0.8441 - val_loss: 0.8628 - val_acc: 0.8434\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8719 - acc: 0.8435 - val_loss: 0.8439 - val_acc: 0.8545\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8605 - acc: 0.8440 - val_loss: 0.8759 - val_acc: 0.8356\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8490 - acc: 0.8444 - val_loss: 0.8871 - val_acc: 0.8380\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8404 - acc: 0.8451 - val_loss: 0.8685 - val_acc: 0.8363\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8316 - acc: 0.8444 - val_loss: 0.7961 - val_acc: 0.8627\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8225 - acc: 0.8468 - val_loss: 0.8724 - val_acc: 0.8309\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8192 - acc: 0.8446 - val_loss: 0.7861 - val_acc: 0.8545\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8130 - acc: 0.8476 - val_loss: 0.7757 - val_acc: 0.8578\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8093 - acc: 0.8451 - val_loss: 0.8141 - val_acc: 0.8431\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8031 - acc: 0.8454 - val_loss: 0.8565 - val_acc: 0.8255\n",
      "Test loss: 0.8564510998725892\n",
      "Test accuracy: 0.8255\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_238 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.16152514649256067\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 7.3102 - acc: 0.6952 - val_loss: 1.3083 - val_acc: 0.7563\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.1589 - acc: 0.8091 - val_loss: 1.0566 - val_acc: 0.8283\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0198 - acc: 0.8308 - val_loss: 0.9513 - val_acc: 0.8539\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9473 - acc: 0.8375 - val_loss: 0.9095 - val_acc: 0.8399\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8989 - acc: 0.8460 - val_loss: 0.8419 - val_acc: 0.8618\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8666 - acc: 0.8479 - val_loss: 0.8971 - val_acc: 0.8163\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8434 - acc: 0.8489 - val_loss: 0.8818 - val_acc: 0.8193\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8258 - acc: 0.8512 - val_loss: 0.7916 - val_acc: 0.8617\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8075 - acc: 0.8552 - val_loss: 0.8585 - val_acc: 0.8194\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7956 - acc: 0.8561 - val_loss: 0.7733 - val_acc: 0.8676\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7847 - acc: 0.8589 - val_loss: 0.7682 - val_acc: 0.8642\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7746 - acc: 0.8583 - val_loss: 0.7201 - val_acc: 0.8791\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7662 - acc: 0.8593 - val_loss: 0.7724 - val_acc: 0.8536\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7560 - acc: 0.8617 - val_loss: 0.7532 - val_acc: 0.8710\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7492 - acc: 0.8609 - val_loss: 0.7289 - val_acc: 0.8680\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7397 - acc: 0.8634 - val_loss: 0.8354 - val_acc: 0.8200\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7379 - acc: 0.8628 - val_loss: 0.7371 - val_acc: 0.8683\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7291 - acc: 0.8644 - val_loss: 0.7242 - val_acc: 0.8756\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7209 - acc: 0.8657 - val_loss: 0.7262 - val_acc: 0.8591\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7194 - acc: 0.8652 - val_loss: 0.7385 - val_acc: 0.8640\n",
      "Test loss: 0.7384949163436889\n",
      "Test accuracy: 0.864\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_241 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.03083468735919477\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 2.3191 - acc: 0.8300 - val_loss: 0.7548 - val_acc: 0.8826\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7036 - acc: 0.8851 - val_loss: 0.6587 - val_acc: 0.8912\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.5962 - acc: 0.9031 - val_loss: 0.5638 - val_acc: 0.9013\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.5424 - acc: 0.9120 - val_loss: 0.5196 - val_acc: 0.9112\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.5071 - acc: 0.9174 - val_loss: 0.4842 - val_acc: 0.9209\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4837 - acc: 0.9218 - val_loss: 0.4816 - val_acc: 0.9185\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4620 - acc: 0.9259 - val_loss: 0.4190 - val_acc: 0.9378\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4474 - acc: 0.9271 - val_loss: 0.5162 - val_acc: 0.8982\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4358 - acc: 0.9298 - val_loss: 0.4228 - val_acc: 0.9282\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4272 - acc: 0.9319 - val_loss: 0.4285 - val_acc: 0.9278\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4203 - acc: 0.9323 - val_loss: 0.4208 - val_acc: 0.9269\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4125 - acc: 0.9331 - val_loss: 0.3980 - val_acc: 0.9358\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4070 - acc: 0.9332 - val_loss: 0.4335 - val_acc: 0.9223\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4008 - acc: 0.9349 - val_loss: 0.4904 - val_acc: 0.9026\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3942 - acc: 0.9358 - val_loss: 0.4022 - val_acc: 0.9280\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3910 - acc: 0.9359 - val_loss: 0.3690 - val_acc: 0.9428\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3880 - acc: 0.9355 - val_loss: 0.3755 - val_acc: 0.9364\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3827 - acc: 0.9365 - val_loss: 0.3409 - val_acc: 0.9487\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3791 - acc: 0.9373 - val_loss: 0.3850 - val_acc: 0.9321\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3755 - acc: 0.9376 - val_loss: 0.3554 - val_acc: 0.9402\n",
      "Test loss: 0.3554223667144775\n",
      "Test accuracy: 0.9402\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_244 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.20603590316494322\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 8.9904 - acc: 0.6383 - val_loss: 1.3801 - val_acc: 0.7722\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.2644 - acc: 0.7920 - val_loss: 1.1071 - val_acc: 0.8446\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0987 - acc: 0.8248 - val_loss: 1.0473 - val_acc: 0.8314\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0211 - acc: 0.8311 - val_loss: 1.0093 - val_acc: 0.8142\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9710 - acc: 0.8352 - val_loss: 0.9140 - val_acc: 0.8570\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9324 - acc: 0.8393 - val_loss: 0.8705 - val_acc: 0.8625\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9057 - acc: 0.8416 - val_loss: 0.8664 - val_acc: 0.8494\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8855 - acc: 0.8418 - val_loss: 0.8950 - val_acc: 0.8287\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8683 - acc: 0.8433 - val_loss: 0.8502 - val_acc: 0.8511\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8547 - acc: 0.8440 - val_loss: 0.9425 - val_acc: 0.7835\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8431 - acc: 0.8450 - val_loss: 0.8017 - val_acc: 0.8592\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8307 - acc: 0.8449 - val_loss: 0.8089 - val_acc: 0.8489\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8240 - acc: 0.8447 - val_loss: 0.8422 - val_acc: 0.8311\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8162 - acc: 0.8449 - val_loss: 0.7464 - val_acc: 0.8708\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8090 - acc: 0.8450 - val_loss: 0.7785 - val_acc: 0.8636\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8010 - acc: 0.8460 - val_loss: 0.7837 - val_acc: 0.8494\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7967 - acc: 0.8454 - val_loss: 0.7643 - val_acc: 0.8666\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7919 - acc: 0.8460 - val_loss: 0.7359 - val_acc: 0.8770\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7836 - acc: 0.8478 - val_loss: 0.7661 - val_acc: 0.8484\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7808 - acc: 0.8480 - val_loss: 0.7060 - val_acc: 0.8763\n",
      "Test loss: 0.705960833644867\n",
      "Test accuracy: 0.8763\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_247 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.27771069103868207\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 11.6196 - acc: 0.5720 - val_loss: 1.5116 - val_acc: 0.6947\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.4437 - acc: 0.7045 - val_loss: 1.4144 - val_acc: 0.6953\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.2906 - acc: 0.7505 - val_loss: 1.3226 - val_acc: 0.6902\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.1993 - acc: 0.7698 - val_loss: 1.1895 - val_acc: 0.7581\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.1390 - acc: 0.7782 - val_loss: 1.0934 - val_acc: 0.7891\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.1053 - acc: 0.7815 - val_loss: 1.1294 - val_acc: 0.7464\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0760 - acc: 0.7869 - val_loss: 1.1239 - val_acc: 0.7748\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0545 - acc: 0.7867 - val_loss: 1.0120 - val_acc: 0.8060\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0361 - acc: 0.7906 - val_loss: 0.9817 - val_acc: 0.8129\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0251 - acc: 0.7895 - val_loss: 1.0579 - val_acc: 0.7892\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0108 - acc: 0.7926 - val_loss: 1.0366 - val_acc: 0.7796\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9989 - acc: 0.7933 - val_loss: 1.0244 - val_acc: 0.7812\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9875 - acc: 0.7939 - val_loss: 0.9907 - val_acc: 0.7906\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9816 - acc: 0.7941 - val_loss: 0.9479 - val_acc: 0.8113\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9735 - acc: 0.7939 - val_loss: 0.9900 - val_acc: 0.8003\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9684 - acc: 0.7944 - val_loss: 1.0867 - val_acc: 0.7234\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9590 - acc: 0.7970 - val_loss: 0.9769 - val_acc: 0.7969\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9531 - acc: 0.7965 - val_loss: 0.9903 - val_acc: 0.7871\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9466 - acc: 0.7978 - val_loss: 1.0389 - val_acc: 0.7589\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9450 - acc: 0.7982 - val_loss: 0.9223 - val_acc: 0.8069\n",
      "Test loss: 0.9222776588439942\n",
      "Test accuracy: 0.8069\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_250 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.6058315926349815\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 23.6134 - acc: 0.1553 - val_loss: 2.3998 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4025 - acc: 0.1110 - val_loss: 2.4007 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4022 - acc: 0.1110 - val_loss: 2.4015 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4021 - acc: 0.1122 - val_loss: 2.4019 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4019 - acc: 0.1124 - val_loss: 2.4020 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4019 - acc: 0.1124 - val_loss: 2.4015 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4018 - acc: 0.1124 - val_loss: 2.4017 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4018 - acc: 0.1124 - val_loss: 2.4015 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4019 - acc: 0.1124 - val_loss: 2.4016 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4018 - acc: 0.1124 - val_loss: 2.4016 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4018 - acc: 0.1124 - val_loss: 2.4016 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4018 - acc: 0.1124 - val_loss: 2.4015 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4017 - acc: 0.1124 - val_loss: 2.4016 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4018 - acc: 0.1124 - val_loss: 2.4015 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4018 - acc: 0.1124 - val_loss: 2.4015 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4018 - acc: 0.1124 - val_loss: 2.4015 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4018 - acc: 0.1124 - val_loss: 2.4015 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4017 - acc: 0.1124 - val_loss: 2.4015 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4017 - acc: 0.1124 - val_loss: 2.4015 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4017 - acc: 0.1124 - val_loss: 2.4016 - val_acc: 0.1135\n",
      "Test loss: 2.4015879039764405\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_253 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.6685584059883968\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 25.8545 - acc: 0.1579 - val_loss: 2.4139 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4130 - acc: 0.1098 - val_loss: 2.4125 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4126 - acc: 0.1113 - val_loss: 2.4126 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4125 - acc: 0.1120 - val_loss: 2.4121 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4124 - acc: 0.1124 - val_loss: 2.4122 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4123 - acc: 0.1124 - val_loss: 2.4119 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4122 - acc: 0.1124 - val_loss: 2.4120 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4122 - acc: 0.1124 - val_loss: 2.4120 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4122 - acc: 0.1124 - val_loss: 2.4120 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4122 - acc: 0.1124 - val_loss: 2.4119 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4122 - acc: 0.1124 - val_loss: 2.4120 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4122 - acc: 0.1124 - val_loss: 2.4121 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4122 - acc: 0.1124 - val_loss: 2.4119 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4121 - acc: 0.1124 - val_loss: 2.4119 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4122 - acc: 0.1124 - val_loss: 2.4119 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4121 - acc: 0.1124 - val_loss: 2.4119 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4122 - acc: 0.1124 - val_loss: 2.4119 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4122 - acc: 0.1124 - val_loss: 2.4120 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4121 - acc: 0.1124 - val_loss: 2.4119 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4121 - acc: 0.1124 - val_loss: 2.4119 - val_acc: 0.1135\n",
      "Test loss: 2.4119388145446776\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_256 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.528701428652475\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 20.7001 - acc: 0.3630 - val_loss: 1.9559 - val_acc: 0.4503\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.8832 - acc: 0.4685 - val_loss: 1.8097 - val_acc: 0.4643\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.7522 - acc: 0.5200 - val_loss: 1.6972 - val_acc: 0.5456\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.6796 - acc: 0.5454 - val_loss: 1.6287 - val_acc: 0.5809\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.6289 - acc: 0.5618 - val_loss: 1.5916 - val_acc: 0.5782\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.5929 - acc: 0.5706 - val_loss: 1.5185 - val_acc: 0.6003\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.5622 - acc: 0.5760 - val_loss: 1.5407 - val_acc: 0.5949\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.5441 - acc: 0.5771 - val_loss: 1.4728 - val_acc: 0.6124\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.5234 - acc: 0.5856 - val_loss: 1.4719 - val_acc: 0.6042\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.4849 - acc: 0.6247 - val_loss: 1.5109 - val_acc: 0.6297\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.4255 - acc: 0.6718 - val_loss: 1.3841 - val_acc: 0.6956\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.3697 - acc: 0.6959 - val_loss: 1.2921 - val_acc: 0.7252\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.3268 - acc: 0.7075 - val_loss: 1.4821 - val_acc: 0.6363\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.3008 - acc: 0.7125 - val_loss: 1.2440 - val_acc: 0.7269\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.2759 - acc: 0.7196 - val_loss: 1.2307 - val_acc: 0.7349\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.2596 - acc: 0.7212 - val_loss: 1.1918 - val_acc: 0.7506\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.2456 - acc: 0.7217 - val_loss: 1.2329 - val_acc: 0.7231\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.2365 - acc: 0.7233 - val_loss: 1.1873 - val_acc: 0.7443\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.2237 - acc: 0.7238 - val_loss: 1.1897 - val_acc: 0.7399\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.2163 - acc: 0.7255 - val_loss: 1.2006 - val_acc: 0.7295\n",
      "Test loss: 1.20057587890625\n",
      "Test accuracy: 0.7295\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_259 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.950098770062801\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 35.6952 - acc: 0.1520 - val_loss: 2.4583 - val_acc: 0.1010\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4596 - acc: 0.1108 - val_loss: 2.4593 - val_acc: 0.1028\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4593 - acc: 0.1119 - val_loss: 2.4589 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4591 - acc: 0.1115 - val_loss: 2.4590 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4591 - acc: 0.1124 - val_loss: 2.4587 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4590 - acc: 0.1124 - val_loss: 2.4587 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4590 - acc: 0.1124 - val_loss: 2.4586 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4589 - acc: 0.1124 - val_loss: 2.4587 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4589 - acc: 0.1124 - val_loss: 2.4587 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4589 - acc: 0.1124 - val_loss: 2.4587 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4589 - acc: 0.1124 - val_loss: 2.4588 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4589 - acc: 0.1124 - val_loss: 2.4585 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4589 - acc: 0.1124 - val_loss: 2.4586 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4589 - acc: 0.1124 - val_loss: 2.4586 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4589 - acc: 0.1124 - val_loss: 2.4586 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4589 - acc: 0.1124 - val_loss: 2.4586 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4589 - acc: 0.1124 - val_loss: 2.4586 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4589 - acc: 0.1124 - val_loss: 2.4586 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4589 - acc: 0.1124 - val_loss: 2.4586 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4589 - acc: 0.1124 - val_loss: 2.4586 - val_acc: 0.1135\n",
      "Test loss: 2.4586157478332518\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_262 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_264 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.17496924301563518\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 7.8282 - acc: 0.6847 - val_loss: 1.3515 - val_acc: 0.7595\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.1980 - acc: 0.8043 - val_loss: 1.0672 - val_acc: 0.8317\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0473 - acc: 0.8274 - val_loss: 0.9599 - val_acc: 0.8459\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9715 - acc: 0.8355 - val_loss: 0.9156 - val_acc: 0.8528\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9216 - acc: 0.8423 - val_loss: 0.9743 - val_acc: 0.8020\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8877 - acc: 0.8462 - val_loss: 0.8383 - val_acc: 0.8522\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8631 - acc: 0.8453 - val_loss: 0.8148 - val_acc: 0.8514\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8443 - acc: 0.8472 - val_loss: 0.8080 - val_acc: 0.8561\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8263 - acc: 0.8485 - val_loss: 0.7966 - val_acc: 0.8511\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8126 - acc: 0.8502 - val_loss: 0.7689 - val_acc: 0.8639\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8008 - acc: 0.8502 - val_loss: 0.7682 - val_acc: 0.8547\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7919 - acc: 0.8523 - val_loss: 0.7336 - val_acc: 0.8737\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7822 - acc: 0.8505 - val_loss: 0.8758 - val_acc: 0.8001\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7764 - acc: 0.8497 - val_loss: 0.7243 - val_acc: 0.8639\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7691 - acc: 0.8507 - val_loss: 0.7259 - val_acc: 0.8702\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7628 - acc: 0.8507 - val_loss: 0.7306 - val_acc: 0.8644\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7573 - acc: 0.8534 - val_loss: 0.7562 - val_acc: 0.8532\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7534 - acc: 0.8521 - val_loss: 0.7820 - val_acc: 0.8327\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7475 - acc: 0.8508 - val_loss: 0.6936 - val_acc: 0.8703\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7460 - acc: 0.8513 - val_loss: 0.8534 - val_acc: 0.7884\n",
      "Test loss: 0.8534186641693116\n",
      "Test accuracy: 0.7884\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_265 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.12730347484436022\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 42us/step - loss: 6.0323 - acc: 0.7285 - val_loss: 1.1261 - val_acc: 0.8412\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0731 - acc: 0.8323 - val_loss: 0.9448 - val_acc: 0.8541\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9334 - acc: 0.8500 - val_loss: 0.8543 - val_acc: 0.8687\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8679 - acc: 0.8580 - val_loss: 0.8951 - val_acc: 0.8301\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8291 - acc: 0.8612 - val_loss: 0.7900 - val_acc: 0.8675\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7937 - acc: 0.8674 - val_loss: 0.7420 - val_acc: 0.8864\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7705 - acc: 0.8701 - val_loss: 0.7627 - val_acc: 0.8652\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7514 - acc: 0.8706 - val_loss: 0.7182 - val_acc: 0.8786\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7376 - acc: 0.8712 - val_loss: 0.7489 - val_acc: 0.8638\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7253 - acc: 0.8706 - val_loss: 0.6836 - val_acc: 0.8871\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7153 - acc: 0.8729 - val_loss: 0.7513 - val_acc: 0.8486\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7055 - acc: 0.8728 - val_loss: 0.7478 - val_acc: 0.8521\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6982 - acc: 0.8734 - val_loss: 0.6905 - val_acc: 0.8749\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6895 - acc: 0.8754 - val_loss: 0.6909 - val_acc: 0.8727\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6831 - acc: 0.8757 - val_loss: 0.9038 - val_acc: 0.7796\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6767 - acc: 0.8752 - val_loss: 0.6360 - val_acc: 0.8846\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6702 - acc: 0.8758 - val_loss: 0.6409 - val_acc: 0.8859\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6644 - acc: 0.8786 - val_loss: 0.6396 - val_acc: 0.8823\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6612 - acc: 0.8772 - val_loss: 0.6071 - val_acc: 0.9000\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6543 - acc: 0.8779 - val_loss: 0.7324 - val_acc: 0.8535\n",
      "Test loss: 0.7323877964019775\n",
      "Test accuracy: 0.8535\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_268 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_270 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.7172188129444295\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 27.5422 - acc: 0.1514 - val_loss: 2.4207 - val_acc: 0.1028\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4209 - acc: 0.1106 - val_loss: 2.4225 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4208 - acc: 0.1116 - val_loss: 2.4203 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4206 - acc: 0.1118 - val_loss: 2.4200 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4204 - acc: 0.1124 - val_loss: 2.4204 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4204 - acc: 0.1124 - val_loss: 2.4199 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4203 - acc: 0.1124 - val_loss: 2.4200 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4203 - acc: 0.1124 - val_loss: 2.4200 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4203 - acc: 0.1124 - val_loss: 2.4200 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4203 - acc: 0.1124 - val_loss: 2.4201 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4202 - acc: 0.1124 - val_loss: 2.4200 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4202 - acc: 0.1124 - val_loss: 2.4200 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4203 - acc: 0.1124 - val_loss: 2.4200 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4202 - acc: 0.1124 - val_loss: 2.4199 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4202 - acc: 0.1124 - val_loss: 2.4200 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4203 - acc: 0.1124 - val_loss: 2.4200 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4202 - acc: 0.1124 - val_loss: 2.4201 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4202 - acc: 0.1124 - val_loss: 2.4199 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4202 - acc: 0.1124 - val_loss: 2.4200 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4202 - acc: 0.1124 - val_loss: 2.4208 - val_acc: 0.1135\n",
      "Test loss: 2.420843745803833\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_271 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_273 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.1333346550123517\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 6.2591 - acc: 0.7252 - val_loss: 1.2757 - val_acc: 0.7337\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0925 - acc: 0.8260 - val_loss: 1.0402 - val_acc: 0.8294\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9569 - acc: 0.8458 - val_loss: 0.8667 - val_acc: 0.8763\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8835 - acc: 0.8555 - val_loss: 0.8525 - val_acc: 0.8625\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8384 - acc: 0.8615 - val_loss: 0.8054 - val_acc: 0.8589\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8038 - acc: 0.8646 - val_loss: 0.8005 - val_acc: 0.8582\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7778 - acc: 0.8683 - val_loss: 0.7566 - val_acc: 0.8714\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7595 - acc: 0.8690 - val_loss: 0.7242 - val_acc: 0.8767\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7438 - acc: 0.8701 - val_loss: 0.7755 - val_acc: 0.8399\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7297 - acc: 0.8704 - val_loss: 0.6901 - val_acc: 0.8891\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7225 - acc: 0.8709 - val_loss: 0.7195 - val_acc: 0.8647\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7124 - acc: 0.8730 - val_loss: 0.6685 - val_acc: 0.8889\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7024 - acc: 0.8736 - val_loss: 0.7690 - val_acc: 0.8467\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6952 - acc: 0.8753 - val_loss: 0.7279 - val_acc: 0.8654\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6897 - acc: 0.8745 - val_loss: 0.7234 - val_acc: 0.8521\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6826 - acc: 0.8758 - val_loss: 0.6628 - val_acc: 0.8809\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6795 - acc: 0.8750 - val_loss: 0.6889 - val_acc: 0.8691\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6714 - acc: 0.8748 - val_loss: 0.6473 - val_acc: 0.8821\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6694 - acc: 0.8763 - val_loss: 0.6474 - val_acc: 0.8793\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.6632 - acc: 0.8779 - val_loss: 0.6134 - val_acc: 0.8941\n",
      "Test loss: 0.6133964624881745\n",
      "Test accuracy: 0.8941\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_274 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_276 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.32541473904763174\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 13.3211 - acc: 0.5575 - val_loss: 1.7038 - val_acc: 0.6171\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.5032 - acc: 0.6895 - val_loss: 1.4553 - val_acc: 0.6745\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.3605 - acc: 0.7317 - val_loss: 1.3258 - val_acc: 0.7233\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2730 - acc: 0.7540 - val_loss: 1.1972 - val_acc: 0.7848\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2055 - acc: 0.7672 - val_loss: 1.1495 - val_acc: 0.7849\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.1607 - acc: 0.7749 - val_loss: 1.2029 - val_acc: 0.7358\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1322 - acc: 0.7774 - val_loss: 1.0823 - val_acc: 0.7980\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1063 - acc: 0.7809 - val_loss: 1.1548 - val_acc: 0.7421\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0897 - acc: 0.7810 - val_loss: 1.0474 - val_acc: 0.7964\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0731 - acc: 0.7829 - val_loss: 1.0455 - val_acc: 0.7999\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0592 - acc: 0.7841 - val_loss: 1.0067 - val_acc: 0.8065\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0487 - acc: 0.7858 - val_loss: 1.0376 - val_acc: 0.7894\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0377 - acc: 0.7869 - val_loss: 1.0723 - val_acc: 0.7661\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0269 - acc: 0.7876 - val_loss: 1.0272 - val_acc: 0.7921\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0193 - acc: 0.7874 - val_loss: 0.9719 - val_acc: 0.8063\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0109 - acc: 0.7883 - val_loss: 1.1292 - val_acc: 0.7215\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0045 - acc: 0.7899 - val_loss: 0.9650 - val_acc: 0.8095\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9997 - acc: 0.7877 - val_loss: 0.9571 - val_acc: 0.8054\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9910 - acc: 0.7920 - val_loss: 0.9596 - val_acc: 0.8048\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9859 - acc: 0.7909 - val_loss: 1.0544 - val_acc: 0.7659\n",
      "Test loss: 1.05438123254776\n",
      "Test accuracy: 0.7659\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_277 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_279 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.7753139820518375\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 29.5363 - acc: 0.1528 - val_loss: 2.4285 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4305 - acc: 0.1114 - val_loss: 2.4298 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4305 - acc: 0.1118 - val_loss: 2.4298 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4301 - acc: 0.1121 - val_loss: 2.4297 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4301 - acc: 0.1123 - val_loss: 2.4297 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4300 - acc: 0.1124 - val_loss: 2.4297 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4300 - acc: 0.1124 - val_loss: 2.4297 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4299 - acc: 0.1124 - val_loss: 2.4297 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4299 - acc: 0.1124 - val_loss: 2.4298 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4299 - acc: 0.1124 - val_loss: 2.4296 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4299 - acc: 0.1124 - val_loss: 2.4297 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4299 - acc: 0.1124 - val_loss: 2.4297 - val_acc: 0.1135\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4299 - acc: 0.1124 - val_loss: 2.4298 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4299 - acc: 0.1124 - val_loss: 2.4296 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4299 - acc: 0.1124 - val_loss: 2.4296 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4299 - acc: 0.1124 - val_loss: 2.4297 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4299 - acc: 0.1124 - val_loss: 2.4296 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4298 - acc: 0.1124 - val_loss: 2.4296 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4298 - acc: 0.1124 - val_loss: 2.4297 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4299 - acc: 0.1124 - val_loss: 2.4296 - val_acc: 0.1135\n",
      "Test loss: 2.4296255348205564\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_280 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.8084252271171599\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 30.7385 - acc: 0.1498 - val_loss: 2.4350 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4360 - acc: 0.1099 - val_loss: 2.4361 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4358 - acc: 0.1103 - val_loss: 2.4353 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4355 - acc: 0.1120 - val_loss: 2.4352 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4355 - acc: 0.1124 - val_loss: 2.4352 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4354 - acc: 0.1124 - val_loss: 2.4354 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4354 - acc: 0.1124 - val_loss: 2.4351 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4354 - acc: 0.1124 - val_loss: 2.4350 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4354 - acc: 0.1124 - val_loss: 2.4352 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4354 - acc: 0.1124 - val_loss: 2.4354 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4354 - acc: 0.1124 - val_loss: 2.4351 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4354 - acc: 0.1124 - val_loss: 2.4351 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4354 - acc: 0.1124 - val_loss: 2.4351 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4354 - acc: 0.1124 - val_loss: 2.4351 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4354 - acc: 0.1124 - val_loss: 2.4351 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4354 - acc: 0.1124 - val_loss: 2.4351 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4354 - acc: 0.1124 - val_loss: 2.4351 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4354 - acc: 0.1124 - val_loss: 2.4351 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4354 - acc: 0.1124 - val_loss: 2.4351 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4353 - acc: 0.1124 - val_loss: 2.4351 - val_acc: 0.1135\n",
      "Test loss: 2.4351265327453615\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_283 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_285 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.6499431382460084\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 25.2244 - acc: 0.1604 - val_loss: 2.4114 - val_acc: 0.1006\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4099 - acc: 0.1097 - val_loss: 2.4091 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4097 - acc: 0.1115 - val_loss: 2.4091 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4094 - acc: 0.1118 - val_loss: 2.4092 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4093 - acc: 0.1121 - val_loss: 2.4088 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4092 - acc: 0.1124 - val_loss: 2.4089 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4092 - acc: 0.1124 - val_loss: 2.4089 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4092 - acc: 0.1124 - val_loss: 2.4090 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4091 - acc: 0.1124 - val_loss: 2.4088 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4091 - acc: 0.1124 - val_loss: 2.4088 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4091 - acc: 0.1124 - val_loss: 2.4088 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4091 - acc: 0.1124 - val_loss: 2.4088 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4091 - acc: 0.1124 - val_loss: 2.4088 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4091 - acc: 0.1124 - val_loss: 2.4088 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4091 - acc: 0.1124 - val_loss: 2.4088 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4091 - acc: 0.1124 - val_loss: 2.4088 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4091 - acc: 0.1124 - val_loss: 2.4088 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4091 - acc: 0.1124 - val_loss: 2.4088 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4091 - acc: 0.1124 - val_loss: 2.4088 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.4091 - acc: 0.1124 - val_loss: 2.4089 - val_acc: 0.1135\n",
      "Test loss: 2.4088610332489013\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_286 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_288 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.21760271932090053\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 9.4230 - acc: 0.6226 - val_loss: 1.4264 - val_acc: 0.7519\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.3110 - acc: 0.7822 - val_loss: 1.2082 - val_acc: 0.7909\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.1415 - acc: 0.8152 - val_loss: 1.0522 - val_acc: 0.8398\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0553 - acc: 0.8279 - val_loss: 1.0152 - val_acc: 0.8183\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9961 - acc: 0.8346 - val_loss: 0.9576 - val_acc: 0.8409\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9521 - acc: 0.8405 - val_loss: 0.9181 - val_acc: 0.8373\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9231 - acc: 0.8400 - val_loss: 0.8515 - val_acc: 0.8668\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9003 - acc: 0.8425 - val_loss: 0.8433 - val_acc: 0.8647\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8851 - acc: 0.8437 - val_loss: 0.8215 - val_acc: 0.8660\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8715 - acc: 0.8432 - val_loss: 0.8955 - val_acc: 0.8202\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8576 - acc: 0.8446 - val_loss: 0.8147 - val_acc: 0.8594\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8459 - acc: 0.8455 - val_loss: 0.8004 - val_acc: 0.8627\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8379 - acc: 0.8457 - val_loss: 0.8305 - val_acc: 0.8294\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8289 - acc: 0.8454 - val_loss: 0.8876 - val_acc: 0.8060\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8201 - acc: 0.8457 - val_loss: 0.8625 - val_acc: 0.8166\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8117 - acc: 0.8475 - val_loss: 0.7662 - val_acc: 0.8594\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8053 - acc: 0.8467 - val_loss: 0.8353 - val_acc: 0.8318\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8018 - acc: 0.8461 - val_loss: 0.7650 - val_acc: 0.8561\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7963 - acc: 0.8455 - val_loss: 0.7698 - val_acc: 0.8491\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7896 - acc: 0.8474 - val_loss: 1.0349 - val_acc: 0.7329\n",
      "Test loss: 1.034912970352173\n",
      "Test accuracy: 0.7329\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_289 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_291 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.2254688084711408\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 9.6895 - acc: 0.6177 - val_loss: 1.4775 - val_acc: 0.7069\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.3380 - acc: 0.7534 - val_loss: 1.2500 - val_acc: 0.7856\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.1767 - acc: 0.8042 - val_loss: 1.0726 - val_acc: 0.8425\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0762 - acc: 0.8264 - val_loss: 0.9996 - val_acc: 0.8483\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0161 - acc: 0.8318 - val_loss: 1.0066 - val_acc: 0.8030\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9740 - acc: 0.8356 - val_loss: 0.9427 - val_acc: 0.8481\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9450 - acc: 0.8380 - val_loss: 0.9294 - val_acc: 0.8473\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9227 - acc: 0.8396 - val_loss: 0.9139 - val_acc: 0.8499\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.9048 - acc: 0.8408 - val_loss: 0.9284 - val_acc: 0.8099\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8908 - acc: 0.8403 - val_loss: 0.8727 - val_acc: 0.8467\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8739 - acc: 0.8419 - val_loss: 0.8746 - val_acc: 0.8402\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8621 - acc: 0.8437 - val_loss: 0.8376 - val_acc: 0.8471\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8526 - acc: 0.8433 - val_loss: 0.9033 - val_acc: 0.8218\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8416 - acc: 0.8461 - val_loss: 0.9043 - val_acc: 0.8255\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.8363 - acc: 0.8448 - val_loss: 0.8467 - val_acc: 0.8351\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8287 - acc: 0.8446 - val_loss: 0.7845 - val_acc: 0.8612\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8224 - acc: 0.8445 - val_loss: 0.8338 - val_acc: 0.8262\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8165 - acc: 0.8443 - val_loss: 0.7716 - val_acc: 0.8580\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8102 - acc: 0.8453 - val_loss: 0.8224 - val_acc: 0.8386\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8063 - acc: 0.8453 - val_loss: 0.7482 - val_acc: 0.8650\n",
      "Test loss: 0.748240670967102\n",
      "Test accuracy: 0.865\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_292 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_293 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_294 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.03072965453751593\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 45us/step - loss: 2.3160 - acc: 0.8299 - val_loss: 0.7306 - val_acc: 0.8962\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.7020 - acc: 0.8865 - val_loss: 0.6341 - val_acc: 0.8942\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.5989 - acc: 0.9038 - val_loss: 0.5694 - val_acc: 0.9117\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.5409 - acc: 0.9119 - val_loss: 0.4936 - val_acc: 0.9250\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.5030 - acc: 0.9192 - val_loss: 0.4557 - val_acc: 0.9336\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4788 - acc: 0.9235 - val_loss: 0.4882 - val_acc: 0.9202\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4609 - acc: 0.9263 - val_loss: 0.4335 - val_acc: 0.9280\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4500 - acc: 0.9262 - val_loss: 0.4604 - val_acc: 0.9172\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4366 - acc: 0.9287 - val_loss: 0.4239 - val_acc: 0.9297\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4279 - acc: 0.9299 - val_loss: 0.4157 - val_acc: 0.9324\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4194 - acc: 0.9308 - val_loss: 0.4361 - val_acc: 0.9245\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4103 - acc: 0.9315 - val_loss: 0.4154 - val_acc: 0.9302\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4050 - acc: 0.9333 - val_loss: 0.3919 - val_acc: 0.9321\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3996 - acc: 0.9341 - val_loss: 0.3800 - val_acc: 0.9355\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3932 - acc: 0.9342 - val_loss: 0.3937 - val_acc: 0.9315\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3883 - acc: 0.9353 - val_loss: 0.3496 - val_acc: 0.9449\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3846 - acc: 0.9367 - val_loss: 0.3869 - val_acc: 0.9302\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3786 - acc: 0.9360 - val_loss: 0.3864 - val_acc: 0.9344\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3756 - acc: 0.9377 - val_loss: 0.3682 - val_acc: 0.9370\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3721 - acc: 0.9372 - val_loss: 0.3572 - val_acc: 0.9389\n",
      "Test loss: 0.35723764622211457\n",
      "Test accuracy: 0.9389\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_295 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.005276157046672107\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 1.1158 - acc: 0.8953 - val_loss: 0.4508 - val_acc: 0.9281\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4009 - acc: 0.9369 - val_loss: 0.3389 - val_acc: 0.9515\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3303 - acc: 0.9477 - val_loss: 0.3188 - val_acc: 0.9473\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2923 - acc: 0.9540 - val_loss: 0.3113 - val_acc: 0.9458\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2652 - acc: 0.9589 - val_loss: 0.2744 - val_acc: 0.9523\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2503 - acc: 0.9603 - val_loss: 0.2287 - val_acc: 0.9664\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2399 - acc: 0.9625 - val_loss: 0.2363 - val_acc: 0.9609\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2323 - acc: 0.9623 - val_loss: 0.2511 - val_acc: 0.9570\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2232 - acc: 0.9650 - val_loss: 0.2246 - val_acc: 0.9645\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2185 - acc: 0.9639 - val_loss: 0.2135 - val_acc: 0.9664\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2138 - acc: 0.9647 - val_loss: 0.2214 - val_acc: 0.9622\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2110 - acc: 0.9658 - val_loss: 0.2262 - val_acc: 0.9582\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2067 - acc: 0.9659 - val_loss: 0.2070 - val_acc: 0.9647\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2053 - acc: 0.9659 - val_loss: 0.2059 - val_acc: 0.9671\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.2020 - acc: 0.9666 - val_loss: 0.1947 - val_acc: 0.9706\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2009 - acc: 0.9666 - val_loss: 0.1894 - val_acc: 0.9689\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1988 - acc: 0.9673 - val_loss: 0.1907 - val_acc: 0.9687\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1969 - acc: 0.9669 - val_loss: 0.2021 - val_acc: 0.9649\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1947 - acc: 0.9675 - val_loss: 0.2112 - val_acc: 0.9606\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1935 - acc: 0.9677 - val_loss: 0.2069 - val_acc: 0.9635\n",
      "Test loss: 0.20692587468624116\n",
      "Test accuracy: 0.9635\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_298 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_300 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.3860921580085245\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 15.6243 - acc: 0.4514 - val_loss: 1.7605 - val_acc: 0.6247\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.6350 - acc: 0.6490 - val_loss: 1.5529 - val_acc: 0.6634\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.4620 - acc: 0.6925 - val_loss: 1.4483 - val_acc: 0.6622\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.3752 - acc: 0.7131 - val_loss: 1.2988 - val_acc: 0.7424\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.3129 - acc: 0.7317 - val_loss: 1.2738 - val_acc: 0.7477\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.2653 - acc: 0.7525 - val_loss: 1.2390 - val_acc: 0.7417\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2242 - acc: 0.7621 - val_loss: 1.2294 - val_acc: 0.7695\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1910 - acc: 0.7672 - val_loss: 1.1164 - val_acc: 0.8023\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.1693 - acc: 0.7682 - val_loss: 1.1245 - val_acc: 0.7845\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1463 - acc: 0.7752 - val_loss: 1.1202 - val_acc: 0.7804\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.1265 - acc: 0.7804 - val_loss: 1.0912 - val_acc: 0.7947\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.1088 - acc: 0.7856 - val_loss: 1.0857 - val_acc: 0.8012\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0966 - acc: 0.7869 - val_loss: 1.0631 - val_acc: 0.8021\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0816 - acc: 0.7928 - val_loss: 1.2199 - val_acc: 0.6920\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0702 - acc: 0.7954 - val_loss: 1.0804 - val_acc: 0.7857\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0586 - acc: 0.7992 - val_loss: 1.0552 - val_acc: 0.8030\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0450 - acc: 0.8049 - val_loss: 0.9977 - val_acc: 0.8326\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0382 - acc: 0.8066 - val_loss: 1.0177 - val_acc: 0.7985\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0251 - acc: 0.8103 - val_loss: 0.9888 - val_acc: 0.8261\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0136 - acc: 0.8128 - val_loss: 1.0679 - val_acc: 0.7913\n",
      "Test loss: 1.067877157020569\n",
      "Test accuracy: 0.7913\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_301 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_302 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_303 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.021295799197794896\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 1.9194 - acc: 0.8490 - val_loss: 0.7084 - val_acc: 0.8784\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6201 - acc: 0.8986 - val_loss: 0.5814 - val_acc: 0.9001\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5265 - acc: 0.9147 - val_loss: 0.5149 - val_acc: 0.9079\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4733 - acc: 0.9243 - val_loss: 0.5095 - val_acc: 0.9050\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4418 - acc: 0.9289 - val_loss: 0.4036 - val_acc: 0.9394\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4202 - acc: 0.9325 - val_loss: 0.4139 - val_acc: 0.9321\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.4039 - acc: 0.9355 - val_loss: 0.3794 - val_acc: 0.9428\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3897 - acc: 0.9368 - val_loss: 0.3810 - val_acc: 0.9348\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3797 - acc: 0.9391 - val_loss: 0.3495 - val_acc: 0.9489\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3720 - acc: 0.9392 - val_loss: 0.3667 - val_acc: 0.9420\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3619 - acc: 0.9423 - val_loss: 0.3567 - val_acc: 0.9383\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3563 - acc: 0.9427 - val_loss: 0.3250 - val_acc: 0.9507\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3502 - acc: 0.9449 - val_loss: 0.3498 - val_acc: 0.9425\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3444 - acc: 0.9450 - val_loss: 0.3312 - val_acc: 0.9481\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3411 - acc: 0.9453 - val_loss: 0.4103 - val_acc: 0.9234\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3374 - acc: 0.9458 - val_loss: 0.3141 - val_acc: 0.9507\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3330 - acc: 0.9468 - val_loss: 0.3573 - val_acc: 0.9373\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3293 - acc: 0.9464 - val_loss: 0.3267 - val_acc: 0.9471\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3253 - acc: 0.9471 - val_loss: 0.3164 - val_acc: 0.9452\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3240 - acc: 0.9465 - val_loss: 0.3048 - val_acc: 0.9505\n",
      "Test loss: 0.3047657690525055\n",
      "Test accuracy: 0.9505\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_304 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_305 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.4366983267794396\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 17.4248 - acc: 0.3932 - val_loss: 1.9354 - val_acc: 0.4218\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.7979 - acc: 0.4844 - val_loss: 1.6896 - val_acc: 0.5142\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.6760 - acc: 0.5358 - val_loss: 1.6068 - val_acc: 0.5565\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.6034 - acc: 0.5698 - val_loss: 1.5276 - val_acc: 0.6146\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.5381 - acc: 0.6203 - val_loss: 1.4457 - val_acc: 0.6725\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4371 - acc: 0.6785 - val_loss: 1.3580 - val_acc: 0.7092\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.3631 - acc: 0.7002 - val_loss: 1.2997 - val_acc: 0.7224\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.3172 - acc: 0.7116 - val_loss: 1.2928 - val_acc: 0.7108\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2839 - acc: 0.7170 - val_loss: 1.2576 - val_acc: 0.7382\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2559 - acc: 0.7253 - val_loss: 1.2351 - val_acc: 0.7365\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2365 - acc: 0.7256 - val_loss: 1.2464 - val_acc: 0.7320\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2198 - acc: 0.7308 - val_loss: 1.2248 - val_acc: 0.7197\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2060 - acc: 0.7327 - val_loss: 1.1892 - val_acc: 0.7381\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1924 - acc: 0.7335 - val_loss: 1.1353 - val_acc: 0.7684\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1779 - acc: 0.7372 - val_loss: 1.2381 - val_acc: 0.7086\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1705 - acc: 0.7376 - val_loss: 1.1485 - val_acc: 0.7518\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1615 - acc: 0.7395 - val_loss: 1.2434 - val_acc: 0.7040\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1546 - acc: 0.7386 - val_loss: 1.1700 - val_acc: 0.7430\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1450 - acc: 0.7403 - val_loss: 1.0752 - val_acc: 0.7762\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1388 - acc: 0.7423 - val_loss: 1.0905 - val_acc: 0.7572\n",
      "Test loss: 1.0905051483154298\n",
      "Test accuracy: 0.7572\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_307 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_308 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_309 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.003698489337972187\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.9988 - acc: 0.9035 - val_loss: 0.3962 - val_acc: 0.9422\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3579 - acc: 0.9441 - val_loss: 0.3003 - val_acc: 0.9514\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2924 - acc: 0.9540 - val_loss: 0.2816 - val_acc: 0.9520\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2577 - acc: 0.9595 - val_loss: 0.2180 - val_acc: 0.9700\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2363 - acc: 0.9632 - val_loss: 0.2283 - val_acc: 0.9637\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2210 - acc: 0.9650 - val_loss: 0.2137 - val_acc: 0.9646\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2111 - acc: 0.9666 - val_loss: 0.2129 - val_acc: 0.9646\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2032 - acc: 0.9681 - val_loss: 0.1963 - val_acc: 0.9670\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1984 - acc: 0.9678 - val_loss: 0.2267 - val_acc: 0.9564\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1919 - acc: 0.9690 - val_loss: 0.1807 - val_acc: 0.9720\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1896 - acc: 0.9695 - val_loss: 0.1970 - val_acc: 0.9673\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1867 - acc: 0.9690 - val_loss: 0.2149 - val_acc: 0.9574\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1833 - acc: 0.9700 - val_loss: 0.1764 - val_acc: 0.9715\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1822 - acc: 0.9697 - val_loss: 0.1893 - val_acc: 0.9678\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1799 - acc: 0.9696 - val_loss: 0.2315 - val_acc: 0.9497\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1792 - acc: 0.9697 - val_loss: 0.1874 - val_acc: 0.9667\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1767 - acc: 0.9703 - val_loss: 0.2006 - val_acc: 0.9608\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1744 - acc: 0.9712 - val_loss: 0.1766 - val_acc: 0.9732\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1754 - acc: 0.9696 - val_loss: 0.1959 - val_acc: 0.9616\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1715 - acc: 0.9705 - val_loss: 0.1751 - val_acc: 0.9705\n",
      "Test loss: 0.17506219433546066\n",
      "Test accuracy: 0.9705\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_310 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_312 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.9229022747932609\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 34.7841 - acc: 0.1503 - val_loss: 2.4542 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.4550 - acc: 0.1101 - val_loss: 2.4544 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 2.4548 - acc: 0.1114 - val_loss: 2.4543 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 2.4546 - acc: 0.1119 - val_loss: 2.4544 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 2.4545 - acc: 0.1124 - val_loss: 2.4542 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4545 - acc: 0.1124 - val_loss: 2.4541 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4544 - acc: 0.1124 - val_loss: 2.4542 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4544 - acc: 0.1124 - val_loss: 2.4542 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4544 - acc: 0.1124 - val_loss: 2.4540 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4544 - acc: 0.1124 - val_loss: 2.4542 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4544 - acc: 0.1124 - val_loss: 2.4541 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4543 - acc: 0.1124 - val_loss: 2.4542 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4544 - acc: 0.1124 - val_loss: 2.4541 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4544 - acc: 0.1124 - val_loss: 2.4541 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4543 - acc: 0.1124 - val_loss: 2.4541 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.4544 - acc: 0.1124 - val_loss: 2.4540 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4544 - acc: 0.1124 - val_loss: 2.4542 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4544 - acc: 0.1124 - val_loss: 2.4541 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4543 - acc: 0.1124 - val_loss: 2.4541 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4543 - acc: 0.1124 - val_loss: 2.4541 - val_acc: 0.1135\n",
      "Test loss: 2.4540541217803957\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_313 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_315 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.06837157152238449\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 3.7916 - acc: 0.7814 - val_loss: 0.9420 - val_acc: 0.8638\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.8882 - acc: 0.8552 - val_loss: 0.7772 - val_acc: 0.8739\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7684 - acc: 0.8712 - val_loss: 0.8818 - val_acc: 0.8072\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7066 - acc: 0.8831 - val_loss: 0.6665 - val_acc: 0.8862\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6702 - acc: 0.8878 - val_loss: 0.6737 - val_acc: 0.8804\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6425 - acc: 0.8932 - val_loss: 0.6165 - val_acc: 0.8997\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6226 - acc: 0.8950 - val_loss: 0.5856 - val_acc: 0.9022\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6052 - acc: 0.8979 - val_loss: 0.6674 - val_acc: 0.8727\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5914 - acc: 0.8995 - val_loss: 0.5520 - val_acc: 0.9107\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5809 - acc: 0.9015 - val_loss: 0.5407 - val_acc: 0.9144\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5691 - acc: 0.9025 - val_loss: 0.5779 - val_acc: 0.8918\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5598 - acc: 0.9047 - val_loss: 0.5540 - val_acc: 0.8997\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5528 - acc: 0.9057 - val_loss: 0.5509 - val_acc: 0.9105\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5422 - acc: 0.9074 - val_loss: 0.5177 - val_acc: 0.9139\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5387 - acc: 0.9077 - val_loss: 0.5918 - val_acc: 0.8820\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5328 - acc: 0.9083 - val_loss: 0.5114 - val_acc: 0.9153\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5270 - acc: 0.9083 - val_loss: 0.5174 - val_acc: 0.9073\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5210 - acc: 0.9102 - val_loss: 0.5487 - val_acc: 0.8957\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5141 - acc: 0.9114 - val_loss: 0.4887 - val_acc: 0.9176\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5073 - acc: 0.9121 - val_loss: 0.4756 - val_acc: 0.9203\n",
      "Test loss: 0.4756234003543854\n",
      "Test accuracy: 0.9203\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_316 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_318 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.4736016471829122\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 18.7627 - acc: 0.4019 - val_loss: 1.9080 - val_acc: 0.4571\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.8246 - acc: 0.4909 - val_loss: 1.7075 - val_acc: 0.5377\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.7067 - acc: 0.5352 - val_loss: 1.6258 - val_acc: 0.5526\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.6391 - acc: 0.5565 - val_loss: 1.5641 - val_acc: 0.5885\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.5774 - acc: 0.5912 - val_loss: 1.5077 - val_acc: 0.6331\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4983 - acc: 0.6530 - val_loss: 1.4945 - val_acc: 0.6343\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.3988 - acc: 0.7016 - val_loss: 1.3480 - val_acc: 0.6997\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.3439 - acc: 0.7118 - val_loss: 1.2800 - val_acc: 0.7409\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.3056 - acc: 0.7211 - val_loss: 1.2460 - val_acc: 0.7461\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2777 - acc: 0.7252 - val_loss: 1.2588 - val_acc: 0.7395\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2551 - acc: 0.7302 - val_loss: 1.2018 - val_acc: 0.7487\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2348 - acc: 0.7361 - val_loss: 1.2405 - val_acc: 0.7324\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2221 - acc: 0.7387 - val_loss: 1.1944 - val_acc: 0.7538\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2061 - acc: 0.7422 - val_loss: 1.1490 - val_acc: 0.7688\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1954 - acc: 0.7460 - val_loss: 1.2132 - val_acc: 0.7400\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1833 - acc: 0.7494 - val_loss: 1.1762 - val_acc: 0.7491\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1745 - acc: 0.7522 - val_loss: 1.1256 - val_acc: 0.7751\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1643 - acc: 0.7580 - val_loss: 1.1024 - val_acc: 0.7895\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1532 - acc: 0.7607 - val_loss: 1.1287 - val_acc: 0.7666\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1424 - acc: 0.7655 - val_loss: 1.1303 - val_acc: 0.7630\n",
      "Test loss: 1.130294974899292\n",
      "Test accuracy: 0.763\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_319 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_320 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_321 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.08776554163061422\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 49us/step - loss: 4.5332 - acc: 0.7600 - val_loss: 1.0137 - val_acc: 0.8660\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9590 - acc: 0.8451 - val_loss: 0.8569 - val_acc: 0.8716\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.8302 - acc: 0.8635 - val_loss: 0.7713 - val_acc: 0.8784\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7648 - acc: 0.8731 - val_loss: 0.7244 - val_acc: 0.8700\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7224 - acc: 0.8779 - val_loss: 0.6627 - val_acc: 0.8950\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6954 - acc: 0.8827 - val_loss: 0.6852 - val_acc: 0.8746\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6762 - acc: 0.8854 - val_loss: 0.6483 - val_acc: 0.8910\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6588 - acc: 0.8875 - val_loss: 0.6809 - val_acc: 0.8726\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6454 - acc: 0.8882 - val_loss: 0.5896 - val_acc: 0.9110\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6326 - acc: 0.8921 - val_loss: 0.6225 - val_acc: 0.8878\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6237 - acc: 0.8920 - val_loss: 0.6630 - val_acc: 0.8687\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6153 - acc: 0.8944 - val_loss: 0.5798 - val_acc: 0.9054\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6075 - acc: 0.8945 - val_loss: 0.5774 - val_acc: 0.9008\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6003 - acc: 0.8944 - val_loss: 0.5375 - val_acc: 0.9160\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.5920 - acc: 0.8964 - val_loss: 0.6363 - val_acc: 0.8750\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.5862 - acc: 0.8976 - val_loss: 0.5666 - val_acc: 0.8977\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.5801 - acc: 0.8977 - val_loss: 0.5419 - val_acc: 0.9094\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5776 - acc: 0.8982 - val_loss: 0.5241 - val_acc: 0.9137\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5714 - acc: 0.8995 - val_loss: 0.5452 - val_acc: 0.9085\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5658 - acc: 0.8999 - val_loss: 0.5886 - val_acc: 0.8833\n",
      "Test loss: 0.5885880526065826\n",
      "Test accuracy: 0.8833\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_322 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_323 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_324 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.315135245642447\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 12.9720 - acc: 0.5523 - val_loss: 1.5790 - val_acc: 0.6853\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4871 - acc: 0.6971 - val_loss: 1.3847 - val_acc: 0.7178\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.3324 - acc: 0.7447 - val_loss: 1.3039 - val_acc: 0.7356\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2438 - acc: 0.7625 - val_loss: 1.1928 - val_acc: 0.7719\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1924 - acc: 0.7672 - val_loss: 1.1425 - val_acc: 0.7951\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1554 - acc: 0.7708 - val_loss: 1.1902 - val_acc: 0.7276\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1306 - acc: 0.7759 - val_loss: 1.0941 - val_acc: 0.7906\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1007 - acc: 0.7823 - val_loss: 1.0494 - val_acc: 0.8099\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0797 - acc: 0.7890 - val_loss: 1.1250 - val_acc: 0.7634\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0596 - acc: 0.7924 - val_loss: 1.0144 - val_acc: 0.8184\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0466 - acc: 0.7958 - val_loss: 0.9852 - val_acc: 0.8220\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0357 - acc: 0.7996 - val_loss: 0.9833 - val_acc: 0.8219\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.0187 - acc: 0.8054 - val_loss: 0.9899 - val_acc: 0.8132\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9991 - acc: 0.8135 - val_loss: 0.9461 - val_acc: 0.8414\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9809 - acc: 0.8201 - val_loss: 0.9380 - val_acc: 0.8492\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9581 - acc: 0.8264 - val_loss: 0.9185 - val_acc: 0.8401\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9443 - acc: 0.8287 - val_loss: 0.8964 - val_acc: 0.8404\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9271 - acc: 0.8312 - val_loss: 0.8762 - val_acc: 0.8559\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9170 - acc: 0.8324 - val_loss: 0.8335 - val_acc: 0.8691\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.9090 - acc: 0.8339 - val_loss: 0.8821 - val_acc: 0.8346\n",
      "Test loss: 0.8821007381439209\n",
      "Test accuracy: 0.8346\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_325 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_326 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_327 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.3915380334526548\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 15.7569 - acc: 0.4860 - val_loss: 1.7282 - val_acc: 0.6068\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.6101 - acc: 0.6571 - val_loss: 1.4907 - val_acc: 0.7041\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4550 - acc: 0.6933 - val_loss: 1.3567 - val_acc: 0.7237\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.3747 - acc: 0.7065 - val_loss: 1.3391 - val_acc: 0.7089\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.3180 - acc: 0.7224 - val_loss: 1.2610 - val_acc: 0.7563\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2810 - acc: 0.7340 - val_loss: 1.2700 - val_acc: 0.7162\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2425 - acc: 0.7514 - val_loss: 1.1795 - val_acc: 0.7916\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2004 - acc: 0.7678 - val_loss: 1.2150 - val_acc: 0.7658\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1708 - acc: 0.7711 - val_loss: 1.1377 - val_acc: 0.7830\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1489 - acc: 0.7771 - val_loss: 1.1754 - val_acc: 0.7595\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1312 - acc: 0.7768 - val_loss: 1.1356 - val_acc: 0.7617\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1162 - acc: 0.7798 - val_loss: 1.1056 - val_acc: 0.7837\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1036 - acc: 0.7792 - val_loss: 1.0680 - val_acc: 0.7933\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0933 - acc: 0.7801 - val_loss: 1.1737 - val_acc: 0.7205\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0827 - acc: 0.7812 - val_loss: 1.0425 - val_acc: 0.8128\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0721 - acc: 0.7831 - val_loss: 1.0230 - val_acc: 0.8125\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0655 - acc: 0.7839 - val_loss: 1.0108 - val_acc: 0.8163\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0565 - acc: 0.7862 - val_loss: 1.2721 - val_acc: 0.6545\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0529 - acc: 0.7844 - val_loss: 0.9898 - val_acc: 0.8113\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0459 - acc: 0.7847 - val_loss: 1.0744 - val_acc: 0.7668\n",
      "Test loss: 1.0744155967712403\n",
      "Test accuracy: 0.7668\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_328 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_330 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.5485041076810153\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 21.5104 - acc: 0.2664 - val_loss: 2.1036 - val_acc: 0.2726\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.0693 - acc: 0.2739 - val_loss: 2.0287 - val_acc: 0.2871\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.0065 - acc: 0.2909 - val_loss: 1.9715 - val_acc: 0.3148\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.9731 - acc: 0.3088 - val_loss: 1.9420 - val_acc: 0.3181\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.9445 - acc: 0.3255 - val_loss: 1.9193 - val_acc: 0.3542\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.9159 - acc: 0.3432 - val_loss: 1.8940 - val_acc: 0.3486\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.8924 - acc: 0.3626 - val_loss: 1.8783 - val_acc: 0.3812\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.8560 - acc: 0.3993 - val_loss: 1.8032 - val_acc: 0.4226\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.7656 - acc: 0.4562 - val_loss: 1.6707 - val_acc: 0.5082\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.6663 - acc: 0.5116 - val_loss: 1.5735 - val_acc: 0.5678\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.5928 - acc: 0.5473 - val_loss: 1.5609 - val_acc: 0.5696\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.5495 - acc: 0.5621 - val_loss: 1.5770 - val_acc: 0.5422\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.5207 - acc: 0.5729 - val_loss: 1.4869 - val_acc: 0.5865\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.5034 - acc: 0.5776 - val_loss: 1.4925 - val_acc: 0.5953\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4868 - acc: 0.5809 - val_loss: 1.4919 - val_acc: 0.5750\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4766 - acc: 0.5833 - val_loss: 1.4356 - val_acc: 0.6019\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4680 - acc: 0.5866 - val_loss: 1.4210 - val_acc: 0.6206\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4616 - acc: 0.5880 - val_loss: 1.4885 - val_acc: 0.5772\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4537 - acc: 0.5879 - val_loss: 1.4273 - val_acc: 0.5899\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4485 - acc: 0.5915 - val_loss: 1.4240 - val_acc: 0.6098\n",
      "Test loss: 1.4239852376937867\n",
      "Test accuracy: 0.6098\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_331 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_332 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_333 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.0956965603405087\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 4.8400 - acc: 0.7565 - val_loss: 1.0486 - val_acc: 0.8583\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9853 - acc: 0.8422 - val_loss: 0.8745 - val_acc: 0.8708\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.8561 - acc: 0.8619 - val_loss: 0.8389 - val_acc: 0.8506\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7931 - acc: 0.8680 - val_loss: 0.7376 - val_acc: 0.8811\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7504 - acc: 0.8739 - val_loss: 0.6936 - val_acc: 0.8897\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7201 - acc: 0.8781 - val_loss: 0.6917 - val_acc: 0.8819\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6954 - acc: 0.8815 - val_loss: 0.6695 - val_acc: 0.8935\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6789 - acc: 0.8829 - val_loss: 0.7004 - val_acc: 0.8744\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6632 - acc: 0.8852 - val_loss: 0.6350 - val_acc: 0.8956\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6521 - acc: 0.8852 - val_loss: 0.6128 - val_acc: 0.8936\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6424 - acc: 0.8857 - val_loss: 0.6317 - val_acc: 0.8852\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6327 - acc: 0.8864 - val_loss: 0.6395 - val_acc: 0.8857\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6266 - acc: 0.8893 - val_loss: 0.6975 - val_acc: 0.8554\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6187 - acc: 0.8877 - val_loss: 0.5863 - val_acc: 0.8982\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6110 - acc: 0.8903 - val_loss: 0.5885 - val_acc: 0.8969\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6062 - acc: 0.8902 - val_loss: 0.5959 - val_acc: 0.8892\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5996 - acc: 0.8913 - val_loss: 0.5636 - val_acc: 0.9020\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5965 - acc: 0.8896 - val_loss: 0.5521 - val_acc: 0.9043\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5899 - acc: 0.8915 - val_loss: 0.6405 - val_acc: 0.8615\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.5883 - acc: 0.8908 - val_loss: 0.5591 - val_acc: 0.9059\n",
      "Test loss: 0.5590745469093322\n",
      "Test accuracy: 0.9059\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_334 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_335 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_336 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.005243589786755075\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 1.1109 - acc: 0.8943 - val_loss: 0.4236 - val_acc: 0.9373\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3987 - acc: 0.9369 - val_loss: 0.3408 - val_acc: 0.9500\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3260 - acc: 0.9489 - val_loss: 0.3016 - val_acc: 0.9489\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2887 - acc: 0.9547 - val_loss: 0.2921 - val_acc: 0.9493\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2642 - acc: 0.9584 - val_loss: 0.3608 - val_acc: 0.9192\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2477 - acc: 0.9610 - val_loss: 0.2425 - val_acc: 0.9622\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2353 - acc: 0.9633 - val_loss: 0.2433 - val_acc: 0.9576\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2295 - acc: 0.9637 - val_loss: 0.2082 - val_acc: 0.9689\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2222 - acc: 0.9646 - val_loss: 0.2389 - val_acc: 0.9593\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2192 - acc: 0.9646 - val_loss: 0.2147 - val_acc: 0.9647\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2129 - acc: 0.9661 - val_loss: 0.2147 - val_acc: 0.9657\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2100 - acc: 0.9661 - val_loss: 0.2052 - val_acc: 0.9666\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2078 - acc: 0.9659 - val_loss: 0.1998 - val_acc: 0.9662\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2052 - acc: 0.9666 - val_loss: 0.2186 - val_acc: 0.9591\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1998 - acc: 0.9675 - val_loss: 0.2488 - val_acc: 0.9523\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2000 - acc: 0.9663 - val_loss: 0.1964 - val_acc: 0.9694\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1976 - acc: 0.9671 - val_loss: 0.2168 - val_acc: 0.9609\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1962 - acc: 0.9679 - val_loss: 0.2090 - val_acc: 0.9626\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1951 - acc: 0.9676 - val_loss: 0.1914 - val_acc: 0.9684\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1930 - acc: 0.9672 - val_loss: 0.2081 - val_acc: 0.9635\n",
      "Test loss: 0.2080934397339821\n",
      "Test accuracy: 0.9635\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_337 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_338 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_339 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.30417692740092894\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 12.5726 - acc: 0.5570 - val_loss: 1.5480 - val_acc: 0.7049\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4875 - acc: 0.6919 - val_loss: 1.3595 - val_acc: 0.7471\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.3352 - acc: 0.7425 - val_loss: 1.3054 - val_acc: 0.7246\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2491 - acc: 0.7558 - val_loss: 1.1858 - val_acc: 0.7705\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1827 - acc: 0.7691 - val_loss: 1.1288 - val_acc: 0.7848\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1353 - acc: 0.7790 - val_loss: 1.0913 - val_acc: 0.7939\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1080 - acc: 0.7790 - val_loss: 1.0422 - val_acc: 0.8069\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0849 - acc: 0.7806 - val_loss: 1.0614 - val_acc: 0.7933\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0686 - acc: 0.7835 - val_loss: 1.0346 - val_acc: 0.8107\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0531 - acc: 0.7848 - val_loss: 1.0572 - val_acc: 0.7789\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0381 - acc: 0.7880 - val_loss: 0.9990 - val_acc: 0.8064\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0273 - acc: 0.7886 - val_loss: 0.9699 - val_acc: 0.8103\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0176 - acc: 0.7886 - val_loss: 0.9816 - val_acc: 0.8127\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0080 - acc: 0.7889 - val_loss: 0.9692 - val_acc: 0.8050\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0000 - acc: 0.7907 - val_loss: 1.0085 - val_acc: 0.7826\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9912 - acc: 0.7904 - val_loss: 0.9689 - val_acc: 0.7985\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9841 - acc: 0.7934 - val_loss: 0.9331 - val_acc: 0.8194\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9793 - acc: 0.7909 - val_loss: 1.0388 - val_acc: 0.7706\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9734 - acc: 0.7937 - val_loss: 0.9711 - val_acc: 0.7935\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9696 - acc: 0.7929 - val_loss: 1.0134 - val_acc: 0.7640\n",
      "Test loss: 1.013402590751648\n",
      "Test accuracy: 0.764\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_340 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_341 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.1734105497791612\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 7.7795 - acc: 0.6842 - val_loss: 1.3675 - val_acc: 0.7468\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1897 - acc: 0.8067 - val_loss: 1.0539 - val_acc: 0.8450\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0485 - acc: 0.8253 - val_loss: 0.9768 - val_acc: 0.8382\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9671 - acc: 0.8379 - val_loss: 0.9067 - val_acc: 0.8608\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9183 - acc: 0.8426 - val_loss: 0.8812 - val_acc: 0.8555\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.8878 - acc: 0.8464 - val_loss: 0.8662 - val_acc: 0.8411\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.8635 - acc: 0.8485 - val_loss: 0.8236 - val_acc: 0.8497\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.8450 - acc: 0.8497 - val_loss: 0.8396 - val_acc: 0.8562\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.8301 - acc: 0.8497 - val_loss: 0.7770 - val_acc: 0.8722\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.8148 - acc: 0.8532 - val_loss: 0.7899 - val_acc: 0.8596\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.8038 - acc: 0.8533 - val_loss: 0.7369 - val_acc: 0.8775\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7921 - acc: 0.8565 - val_loss: 0.8409 - val_acc: 0.8252\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7842 - acc: 0.8565 - val_loss: 0.8494 - val_acc: 0.8284\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7778 - acc: 0.8561 - val_loss: 0.7371 - val_acc: 0.8690\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7664 - acc: 0.8598 - val_loss: 0.7407 - val_acc: 0.8715\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7559 - acc: 0.8613 - val_loss: 0.7256 - val_acc: 0.8690\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7474 - acc: 0.8651 - val_loss: 0.7083 - val_acc: 0.8766\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7458 - acc: 0.8621 - val_loss: 0.7387 - val_acc: 0.8753\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7396 - acc: 0.8625 - val_loss: 0.7819 - val_acc: 0.8394\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7296 - acc: 0.8656 - val_loss: 0.9718 - val_acc: 0.7691\n",
      "Test loss: 0.9717590308189392\n",
      "Test accuracy: 0.7691\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_343 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_344 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_345 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.28294310241080883\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 11.8001 - acc: 0.5721 - val_loss: 1.5656 - val_acc: 0.6908\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4583 - acc: 0.7056 - val_loss: 1.3690 - val_acc: 0.7311\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.3026 - acc: 0.7492 - val_loss: 1.2188 - val_acc: 0.7665\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2134 - acc: 0.7653 - val_loss: 1.1782 - val_acc: 0.7608\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1557 - acc: 0.7737 - val_loss: 1.0965 - val_acc: 0.7886\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1196 - acc: 0.7793 - val_loss: 1.1457 - val_acc: 0.7432\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0864 - acc: 0.7840 - val_loss: 1.1027 - val_acc: 0.7562\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0656 - acc: 0.7837 - val_loss: 1.1256 - val_acc: 0.7582\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0466 - acc: 0.7874 - val_loss: 1.0774 - val_acc: 0.7721\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0311 - acc: 0.7880 - val_loss: 1.0137 - val_acc: 0.7881\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0195 - acc: 0.7890 - val_loss: 1.0066 - val_acc: 0.7889\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0086 - acc: 0.7911 - val_loss: 0.9670 - val_acc: 0.8059\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9978 - acc: 0.7925 - val_loss: 0.9696 - val_acc: 0.8064\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9894 - acc: 0.7921 - val_loss: 1.0472 - val_acc: 0.7606\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9805 - acc: 0.7926 - val_loss: 1.1802 - val_acc: 0.6729\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9757 - acc: 0.7942 - val_loss: 1.1126 - val_acc: 0.7350\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9701 - acc: 0.7936 - val_loss: 0.9159 - val_acc: 0.8112\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9630 - acc: 0.7930 - val_loss: 0.9405 - val_acc: 0.8015\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9583 - acc: 0.7933 - val_loss: 0.9815 - val_acc: 0.7794\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9537 - acc: 0.7945 - val_loss: 0.9361 - val_acc: 0.8090\n",
      "Test loss: 0.9361442937850952\n",
      "Test accuracy: 0.809\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_346 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_347 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_348 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.8804322250042671\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 52us/step - loss: 33.2987 - acc: 0.1570 - val_loss: 2.4463 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4480 - acc: 0.1113 - val_loss: 2.4473 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4477 - acc: 0.1118 - val_loss: 2.4475 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4475 - acc: 0.1124 - val_loss: 2.4474 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4474 - acc: 0.1124 - val_loss: 2.4472 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4474 - acc: 0.1124 - val_loss: 2.4471 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4474 - acc: 0.1124 - val_loss: 2.4472 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4474 - acc: 0.1124 - val_loss: 2.4471 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4474 - acc: 0.1124 - val_loss: 2.4472 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4473 - acc: 0.1124 - val_loss: 2.4472 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4474 - acc: 0.1124 - val_loss: 2.4471 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4474 - acc: 0.1124 - val_loss: 2.4472 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4473 - acc: 0.1124 - val_loss: 2.4471 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4473 - acc: 0.1124 - val_loss: 2.4472 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4473 - acc: 0.1124 - val_loss: 2.4470 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4473 - acc: 0.1124 - val_loss: 2.4471 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4473 - acc: 0.1124 - val_loss: 2.4471 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4473 - acc: 0.1124 - val_loss: 2.4471 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4473 - acc: 0.1124 - val_loss: 2.4471 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.4473 - acc: 0.1124 - val_loss: 2.4471 - val_acc: 0.1135\n",
      "Test loss: 2.4470748279571533\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_349 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_350 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_351 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.3671158203350344\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 14.8530 - acc: 0.5343 - val_loss: 1.6736 - val_acc: 0.6333\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.5786 - acc: 0.6603 - val_loss: 1.4371 - val_acc: 0.7035\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4362 - acc: 0.6960 - val_loss: 1.5359 - val_acc: 0.6054\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.3534 - acc: 0.7221 - val_loss: 1.3562 - val_acc: 0.7169\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2833 - acc: 0.7504 - val_loss: 1.2004 - val_acc: 0.7919\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2233 - acc: 0.7673 - val_loss: 1.1551 - val_acc: 0.7903\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1871 - acc: 0.7696 - val_loss: 1.1766 - val_acc: 0.7673\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1607 - acc: 0.7748 - val_loss: 1.1840 - val_acc: 0.7652\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1379 - acc: 0.7775 - val_loss: 1.1933 - val_acc: 0.7308\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1195 - acc: 0.7776 - val_loss: 1.1699 - val_acc: 0.7474\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1060 - acc: 0.7788 - val_loss: 1.0600 - val_acc: 0.7973\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.0928 - acc: 0.7819 - val_loss: 1.0517 - val_acc: 0.7913\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.0809 - acc: 0.7827 - val_loss: 1.0311 - val_acc: 0.8010\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.0727 - acc: 0.7833 - val_loss: 1.0899 - val_acc: 0.7592\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0647 - acc: 0.7826 - val_loss: 1.1558 - val_acc: 0.7014\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0557 - acc: 0.7817 - val_loss: 0.9854 - val_acc: 0.8198\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.0474 - acc: 0.7848 - val_loss: 0.9965 - val_acc: 0.8060\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.0408 - acc: 0.7862 - val_loss: 0.9988 - val_acc: 0.8090\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.0327 - acc: 0.7875 - val_loss: 1.0540 - val_acc: 0.7873\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.0311 - acc: 0.7854 - val_loss: 1.0347 - val_acc: 0.7823\n",
      "Test loss: 1.0347260210990905\n",
      "Test accuracy: 0.7823\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_352 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_353 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_354 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.000993719589625794\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.6270 - acc: 0.9241 - val_loss: 0.3038 - val_acc: 0.9593\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2615 - acc: 0.9612 - val_loss: 0.2192 - val_acc: 0.9636\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2022 - acc: 0.9681 - val_loss: 0.1996 - val_acc: 0.9643\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1766 - acc: 0.9709 - val_loss: 0.1592 - val_acc: 0.9759\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1611 - acc: 0.9734 - val_loss: 0.1602 - val_acc: 0.9734\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1499 - acc: 0.9755 - val_loss: 0.1821 - val_acc: 0.9633\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1421 - acc: 0.9765 - val_loss: 0.1781 - val_acc: 0.9658\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1351 - acc: 0.9776 - val_loss: 0.1637 - val_acc: 0.9701\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1296 - acc: 0.9783 - val_loss: 0.1330 - val_acc: 0.9770\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1253 - acc: 0.9789 - val_loss: 0.1413 - val_acc: 0.9740\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1220 - acc: 0.9801 - val_loss: 0.1359 - val_acc: 0.9760\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1205 - acc: 0.9798 - val_loss: 0.1401 - val_acc: 0.9750\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1181 - acc: 0.9802 - val_loss: 0.1562 - val_acc: 0.9698\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1161 - acc: 0.9806 - val_loss: 0.1294 - val_acc: 0.9767\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1133 - acc: 0.9807 - val_loss: 0.1437 - val_acc: 0.9719\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1123 - acc: 0.9814 - val_loss: 0.1326 - val_acc: 0.9761\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1111 - acc: 0.9808 - val_loss: 0.1319 - val_acc: 0.9758\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1107 - acc: 0.9813 - val_loss: 0.1452 - val_acc: 0.9699\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1078 - acc: 0.9824 - val_loss: 0.1519 - val_acc: 0.9683\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1078 - acc: 0.9819 - val_loss: 0.1272 - val_acc: 0.9772\n",
      "Test loss: 0.12720440185666085\n",
      "Test accuracy: 0.9772\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_355 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_356 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_357 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.12941231985341053\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 6.1167 - acc: 0.7236 - val_loss: 1.1799 - val_acc: 0.8062\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.0763 - acc: 0.8256 - val_loss: 1.0021 - val_acc: 0.8270\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.9429 - acc: 0.8478 - val_loss: 0.9383 - val_acc: 0.8234\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.8731 - acc: 0.8558 - val_loss: 0.8034 - val_acc: 0.8815\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.8285 - acc: 0.8620 - val_loss: 0.7985 - val_acc: 0.8695\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7962 - acc: 0.8658 - val_loss: 0.7432 - val_acc: 0.8880\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7732 - acc: 0.8676 - val_loss: 0.7397 - val_acc: 0.8836\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7554 - acc: 0.8691 - val_loss: 0.7038 - val_acc: 0.8828\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7393 - acc: 0.8715 - val_loss: 0.7061 - val_acc: 0.8804\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7300 - acc: 0.8713 - val_loss: 0.6795 - val_acc: 0.8957\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7163 - acc: 0.8724 - val_loss: 0.6513 - val_acc: 0.8993\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.7066 - acc: 0.8737 - val_loss: 0.7475 - val_acc: 0.8532\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7000 - acc: 0.8733 - val_loss: 0.6641 - val_acc: 0.8777\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6921 - acc: 0.8750 - val_loss: 0.6950 - val_acc: 0.8694\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6859 - acc: 0.8754 - val_loss: 0.6615 - val_acc: 0.8836\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6785 - acc: 0.8764 - val_loss: 0.6365 - val_acc: 0.8852\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6744 - acc: 0.8761 - val_loss: 0.6861 - val_acc: 0.8694\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6662 - acc: 0.8773 - val_loss: 0.7377 - val_acc: 0.8358\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6647 - acc: 0.8766 - val_loss: 0.6142 - val_acc: 0.8980\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.6584 - acc: 0.8780 - val_loss: 0.6401 - val_acc: 0.8814\n",
      "Test loss: 0.6400570213317871\n",
      "Test accuracy: 0.8814\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_358 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_359 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_360 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.26161741615915124\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 11.0294 - acc: 0.5855 - val_loss: 1.4705 - val_acc: 0.7412\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.4290 - acc: 0.7138 - val_loss: 1.3286 - val_acc: 0.7282\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.2779 - acc: 0.7516 - val_loss: 1.1987 - val_acc: 0.7734\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1891 - acc: 0.7675 - val_loss: 1.1203 - val_acc: 0.7934\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.1329 - acc: 0.7766 - val_loss: 1.0927 - val_acc: 0.7843\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0982 - acc: 0.7799 - val_loss: 1.0684 - val_acc: 0.7938\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0709 - acc: 0.7847 - val_loss: 1.1299 - val_acc: 0.7347\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0468 - acc: 0.7858 - val_loss: 1.0855 - val_acc: 0.7515\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0251 - acc: 0.7879 - val_loss: 1.0898 - val_acc: 0.7527\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.0132 - acc: 0.7904 - val_loss: 1.0528 - val_acc: 0.7635\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9985 - acc: 0.7917 - val_loss: 0.9904 - val_acc: 0.7922\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9872 - acc: 0.7939 - val_loss: 0.9782 - val_acc: 0.8005\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.9787 - acc: 0.7923 - val_loss: 0.9511 - val_acc: 0.8028\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.9700 - acc: 0.7961 - val_loss: 1.0315 - val_acc: 0.7571\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.9618 - acc: 0.7938 - val_loss: 0.9154 - val_acc: 0.8189\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9563 - acc: 0.7953 - val_loss: 0.9231 - val_acc: 0.8087\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9519 - acc: 0.7955 - val_loss: 0.9933 - val_acc: 0.7693\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.9473 - acc: 0.7938 - val_loss: 0.8994 - val_acc: 0.8125\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.9398 - acc: 0.7961 - val_loss: 1.0069 - val_acc: 0.7537\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.9369 - acc: 0.7973 - val_loss: 0.8962 - val_acc: 0.8075\n",
      "Test loss: 0.8962290864944458\n",
      "Test accuracy: 0.8075\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_361 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_362 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_363 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.5744312081638139\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 22.3909 - acc: 0.2714 - val_loss: 2.1124 - val_acc: 0.2630\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.0779 - acc: 0.2717 - val_loss: 2.0249 - val_acc: 0.2801\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.0159 - acc: 0.2815 - val_loss: 1.9741 - val_acc: 0.2956\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.9813 - acc: 0.2936 - val_loss: 1.9723 - val_acc: 0.3048\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.9533 - acc: 0.3098 - val_loss: 1.9423 - val_acc: 0.2938\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.9318 - acc: 0.3216 - val_loss: 1.9081 - val_acc: 0.3144\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.9143 - acc: 0.3359 - val_loss: 1.8852 - val_acc: 0.3404\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.8922 - acc: 0.3724 - val_loss: 1.8240 - val_acc: 0.4589\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.7749 - acc: 0.5010 - val_loss: 1.6482 - val_acc: 0.5772\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.6601 - acc: 0.5665 - val_loss: 1.6135 - val_acc: 0.5616\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.6001 - acc: 0.5855 - val_loss: 1.5277 - val_acc: 0.6112\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.5671 - acc: 0.5872 - val_loss: 1.5731 - val_acc: 0.6001\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.5446 - acc: 0.5927 - val_loss: 1.4950 - val_acc: 0.6185\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.5299 - acc: 0.5925 - val_loss: 1.4545 - val_acc: 0.6293\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.5170 - acc: 0.5965 - val_loss: 1.4496 - val_acc: 0.6228\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.5093 - acc: 0.5957 - val_loss: 1.4620 - val_acc: 0.6105\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.5020 - acc: 0.5965 - val_loss: 1.4830 - val_acc: 0.6233\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.4947 - acc: 0.5977 - val_loss: 1.4317 - val_acc: 0.6181\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.4896 - acc: 0.5973 - val_loss: 1.4760 - val_acc: 0.6137\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.4835 - acc: 0.5989 - val_loss: 1.4101 - val_acc: 0.6272\n",
      "Test loss: 1.4101173137664795\n",
      "Test accuracy: 0.6272\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_364 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_365 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_366 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.49210002783201406\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 19.4274 - acc: 0.3707 - val_loss: 1.9877 - val_acc: 0.4020\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.8548 - acc: 0.4504 - val_loss: 1.7496 - val_acc: 0.4889\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.7380 - acc: 0.4898 - val_loss: 1.7357 - val_acc: 0.4791\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.6629 - acc: 0.5194 - val_loss: 1.6757 - val_acc: 0.5150\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.6147 - acc: 0.5435 - val_loss: 1.6699 - val_acc: 0.5220\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.5563 - acc: 0.6084 - val_loss: 1.4531 - val_acc: 0.6817\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.4460 - acc: 0.6844 - val_loss: 1.3630 - val_acc: 0.7231\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.3764 - acc: 0.7013 - val_loss: 1.3425 - val_acc: 0.6999\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.3332 - acc: 0.7115 - val_loss: 1.2653 - val_acc: 0.7406\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.3022 - acc: 0.7182 - val_loss: 1.2562 - val_acc: 0.7395\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2789 - acc: 0.7225 - val_loss: 1.3280 - val_acc: 0.6787\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2568 - acc: 0.7257 - val_loss: 1.2353 - val_acc: 0.7418\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2417 - acc: 0.7279 - val_loss: 1.1792 - val_acc: 0.7544\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2286 - acc: 0.7311 - val_loss: 1.2009 - val_acc: 0.7429\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2155 - acc: 0.7317 - val_loss: 1.2586 - val_acc: 0.7265\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2050 - acc: 0.7341 - val_loss: 1.2493 - val_acc: 0.7101\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1971 - acc: 0.7320 - val_loss: 1.2136 - val_acc: 0.7377\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1904 - acc: 0.7319 - val_loss: 1.1927 - val_acc: 0.7265\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1802 - acc: 0.7360 - val_loss: 1.2724 - val_acc: 0.6952\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1736 - acc: 0.7356 - val_loss: 1.1331 - val_acc: 0.7572\n",
      "Test loss: 1.1330681232452393\n",
      "Test accuracy: 0.7572\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_367 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_368 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_369 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.0512795298694238\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 3.1090 - acc: 0.8064 - val_loss: 0.9136 - val_acc: 0.8504\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8132 - acc: 0.8673 - val_loss: 0.7737 - val_acc: 0.8546\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6995 - acc: 0.8853 - val_loss: 0.6167 - val_acc: 0.9098\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6434 - acc: 0.8934 - val_loss: 0.6478 - val_acc: 0.8767\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6061 - acc: 0.8997 - val_loss: 0.5624 - val_acc: 0.9090\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.5798 - acc: 0.9035 - val_loss: 0.5759 - val_acc: 0.8968\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.5632 - acc: 0.9056 - val_loss: 0.5228 - val_acc: 0.9151\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.5465 - acc: 0.9082 - val_loss: 0.5570 - val_acc: 0.8932\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.5350 - acc: 0.9097 - val_loss: 0.5229 - val_acc: 0.9077\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.5246 - acc: 0.9113 - val_loss: 0.5041 - val_acc: 0.9159\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.5127 - acc: 0.9130 - val_loss: 0.4898 - val_acc: 0.9209\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.5040 - acc: 0.9152 - val_loss: 0.5633 - val_acc: 0.8972\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4958 - acc: 0.9161 - val_loss: 0.4974 - val_acc: 0.9134\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4893 - acc: 0.9171 - val_loss: 0.4554 - val_acc: 0.9254\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4838 - acc: 0.9183 - val_loss: 0.5166 - val_acc: 0.9103\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4742 - acc: 0.9203 - val_loss: 0.4685 - val_acc: 0.9222\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4700 - acc: 0.9203 - val_loss: 0.4328 - val_acc: 0.9310\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4645 - acc: 0.9209 - val_loss: 0.4296 - val_acc: 0.9311\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4595 - acc: 0.9234 - val_loss: 0.4505 - val_acc: 0.9255\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.4565 - acc: 0.9228 - val_loss: 0.4308 - val_acc: 0.9257\n",
      "Test loss: 0.4308484041213989\n",
      "Test accuracy: 0.9257\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_370 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_371 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_372 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.17031211106560823\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 7.6725 - acc: 0.6873 - val_loss: 1.3930 - val_acc: 0.7205\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2005 - acc: 0.7995 - val_loss: 1.0755 - val_acc: 0.8335\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.0552 - acc: 0.8220 - val_loss: 0.9851 - val_acc: 0.8458\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.9764 - acc: 0.8330 - val_loss: 0.9252 - val_acc: 0.8471\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.9284 - acc: 0.8402 - val_loss: 0.9951 - val_acc: 0.7771\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8977 - acc: 0.8415 - val_loss: 0.8913 - val_acc: 0.8410\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8705 - acc: 0.8471 - val_loss: 0.8259 - val_acc: 0.8561\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8511 - acc: 0.8488 - val_loss: 0.7754 - val_acc: 0.8770\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8277 - acc: 0.8537 - val_loss: 0.7811 - val_acc: 0.8735\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8133 - acc: 0.8536 - val_loss: 0.9054 - val_acc: 0.7965\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8023 - acc: 0.8542 - val_loss: 0.7937 - val_acc: 0.8420\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7898 - acc: 0.8565 - val_loss: 0.7704 - val_acc: 0.8580\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7804 - acc: 0.8570 - val_loss: 0.7397 - val_acc: 0.8666\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.7727 - acc: 0.8594 - val_loss: 0.7662 - val_acc: 0.8577\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.7599 - acc: 0.8604 - val_loss: 0.7631 - val_acc: 0.8555\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.7555 - acc: 0.8588 - val_loss: 0.7097 - val_acc: 0.8808\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.7467 - acc: 0.8625 - val_loss: 0.7009 - val_acc: 0.8808\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7418 - acc: 0.8633 - val_loss: 0.7213 - val_acc: 0.8656\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.7360 - acc: 0.8627 - val_loss: 0.6892 - val_acc: 0.8792\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7295 - acc: 0.8645 - val_loss: 0.7634 - val_acc: 0.8491\n",
      "Test loss: 0.7634184341430664\n",
      "Test accuracy: 0.8491\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_373 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_374 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_375 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.1166541939078158\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 55us/step - loss: 5.6425 - acc: 0.7386 - val_loss: 1.1693 - val_acc: 0.8144\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.0467 - acc: 0.8338 - val_loss: 1.0253 - val_acc: 0.8213\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.9174 - acc: 0.8503 - val_loss: 0.8676 - val_acc: 0.8669\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8407 - acc: 0.8638 - val_loss: 0.7668 - val_acc: 0.8812\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7925 - acc: 0.8705 - val_loss: 0.7482 - val_acc: 0.8853\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7662 - acc: 0.8718 - val_loss: 0.7336 - val_acc: 0.8844\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7444 - acc: 0.8723 - val_loss: 0.7093 - val_acc: 0.8778\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7253 - acc: 0.8759 - val_loss: 0.8432 - val_acc: 0.8216\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7139 - acc: 0.8755 - val_loss: 0.7358 - val_acc: 0.8621\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.7018 - acc: 0.8766 - val_loss: 0.6702 - val_acc: 0.8836\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6920 - acc: 0.8772 - val_loss: 0.6256 - val_acc: 0.9009\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6830 - acc: 0.8773 - val_loss: 0.6494 - val_acc: 0.8815\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6739 - acc: 0.8778 - val_loss: 0.6432 - val_acc: 0.8883\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6696 - acc: 0.8782 - val_loss: 0.6266 - val_acc: 0.8947\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6604 - acc: 0.8810 - val_loss: 0.6876 - val_acc: 0.8604\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6532 - acc: 0.8798 - val_loss: 0.6203 - val_acc: 0.8938\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6518 - acc: 0.8796 - val_loss: 0.6060 - val_acc: 0.8958\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6459 - acc: 0.8814 - val_loss: 0.6443 - val_acc: 0.8758\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6392 - acc: 0.8832 - val_loss: 0.6459 - val_acc: 0.8715\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.6332 - acc: 0.8835 - val_loss: 0.6004 - val_acc: 0.8939\n",
      "Test loss: 0.6003589509010315\n",
      "Test accuracy: 0.8939\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_376 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_377 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_378 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.43927276793727177\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 17.4681 - acc: 0.3879 - val_loss: 1.8636 - val_acc: 0.4478\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.8071 - acc: 0.4633 - val_loss: 1.7043 - val_acc: 0.4897\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.6979 - acc: 0.5016 - val_loss: 1.7766 - val_acc: 0.4779\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.6305 - acc: 0.5380 - val_loss: 1.5463 - val_acc: 0.5952\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.5422 - acc: 0.6249 - val_loss: 1.4251 - val_acc: 0.6967\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.4244 - acc: 0.6874 - val_loss: 1.3401 - val_acc: 0.7213\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.3513 - acc: 0.7059 - val_loss: 1.3352 - val_acc: 0.7111\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.3073 - acc: 0.7154 - val_loss: 1.3656 - val_acc: 0.6839\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2748 - acc: 0.7222 - val_loss: 1.2390 - val_acc: 0.7442\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2498 - acc: 0.7257 - val_loss: 1.1903 - val_acc: 0.7473\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2301 - acc: 0.7302 - val_loss: 1.1774 - val_acc: 0.7539\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2122 - acc: 0.7354 - val_loss: 1.1830 - val_acc: 0.7385\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1995 - acc: 0.7357 - val_loss: 1.1800 - val_acc: 0.7299\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1875 - acc: 0.7353 - val_loss: 1.2397 - val_acc: 0.7136\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1774 - acc: 0.7383 - val_loss: 1.1161 - val_acc: 0.7674\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1674 - acc: 0.7403 - val_loss: 1.1227 - val_acc: 0.7567\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1591 - acc: 0.7395 - val_loss: 1.1707 - val_acc: 0.7424\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1517 - acc: 0.7414 - val_loss: 1.1626 - val_acc: 0.7223\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1435 - acc: 0.7423 - val_loss: 1.1311 - val_acc: 0.7412\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1389 - acc: 0.7410 - val_loss: 1.0799 - val_acc: 0.7742\n",
      "Test loss: 1.0798810015678406\n",
      "Test accuracy: 0.7742\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_379 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_380 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_381 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.23034007527454664\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 9.8760 - acc: 0.5987 - val_loss: 1.4735 - val_acc: 0.6931\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.3681 - acc: 0.7311 - val_loss: 1.2702 - val_acc: 0.7585\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.2128 - acc: 0.7729 - val_loss: 1.2261 - val_acc: 0.7317\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.1191 - acc: 0.8044 - val_loss: 1.0413 - val_acc: 0.8342\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.0422 - acc: 0.8269 - val_loss: 0.9880 - val_acc: 0.8539\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.9910 - acc: 0.8345 - val_loss: 0.9722 - val_acc: 0.8357\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.9547 - acc: 0.8374 - val_loss: 0.9133 - val_acc: 0.8460\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.9298 - acc: 0.8377 - val_loss: 0.9384 - val_acc: 0.8172\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.9054 - acc: 0.8418 - val_loss: 0.8624 - val_acc: 0.8596\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8909 - acc: 0.8426 - val_loss: 0.8440 - val_acc: 0.8561\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8770 - acc: 0.8426 - val_loss: 0.8637 - val_acc: 0.8399\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8648 - acc: 0.8440 - val_loss: 0.8740 - val_acc: 0.8330\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8562 - acc: 0.8426 - val_loss: 0.8089 - val_acc: 0.8574\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8458 - acc: 0.8431 - val_loss: 0.8536 - val_acc: 0.8323\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8396 - acc: 0.8447 - val_loss: 0.8652 - val_acc: 0.8277\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8329 - acc: 0.8436 - val_loss: 0.7893 - val_acc: 0.8537\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8247 - acc: 0.8444 - val_loss: 0.7929 - val_acc: 0.8592\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8210 - acc: 0.8441 - val_loss: 0.8301 - val_acc: 0.8495\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8140 - acc: 0.8443 - val_loss: 0.8134 - val_acc: 0.8338\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.8069 - acc: 0.8448 - val_loss: 0.7937 - val_acc: 0.8493\n",
      "Test loss: 0.793669103050232\n",
      "Test accuracy: 0.8493\n",
      "{'l2': 0.000993719589625794}\n",
      "{'spec': None, 'exp_key': None, 'refresh_time': datetime.datetime(2018, 9, 1, 11, 13, 51, 622000), 'result': {'loss': -0.9772, 'status': 'ok'}, 'book_time': datetime.datetime(2018, 9, 1, 11, 13, 25, 814000), 'owner': None, 'misc': {'vals': {'l2': [0.000993719589625794]}, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'tid': 40, 'idxs': {'l2': [40]}, 'workdir': None}, 'state': 2, 'tid': 40, 'version': 0}\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    model_2 = Sequential()\n",
    "    model_2.add(Dense(512, activation='relu', input_shape=(784,), kernel_regularizer=regularizers.l2(params['l2'])))\n",
    "    # model_2.add(Dropout(0.2))\n",
    "    model_2.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(params['l2'])))\n",
    "    # model_2.add(Dropout(0.2))\n",
    "    model_2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_2.summary()\n",
    "    \n",
    "    print('training with L2 regularization parameter', params['l2'])\n",
    "    \n",
    "    model_2.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history_2 = model_2.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score_2 = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    print('Test loss:', score_2[0])\n",
    "    print('Test accuracy:', score_2[1])\n",
    "\n",
    "    return {'loss': - score_2[1], 'status': STATUS_OK} \n",
    "\n",
    "space = {\n",
    "    'l2': hp.uniform('l2', 0.00001, 1)\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(objective, space, algo=tpe.suggest, trials=trials, max_evals = 50)\n",
    "print (best)\n",
    "print (trials.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so let us visualize the result again and see if some new trends have emerged: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure(num=None, figsize=(10, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "t = trials.trials\n",
    "\n",
    "y = []\n",
    "x = []\n",
    "for tr in t: \n",
    "    y.append((tr['result']['loss']))\n",
    "    x.append(tr['misc']['vals']['l2'])\n",
    "    \n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is confirming again that the coefficient of L2 regularization is converging to 0. Let's run the best model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_382 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_383 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_384 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.6371 - acc: 0.9233 - val_loss: 0.3327 - val_acc: 0.9532\n",
      " — val_f1: 0.953578 — val_precision: 0.962416 — val_recall 0.944900\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2644 - acc: 0.9611 - val_loss: 0.2208 - val_acc: 0.9657\n",
      " — val_f1: 0.966502 — val_precision: 0.972273 — val_recall 0.960800\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.2036 - acc: 0.9675 - val_loss: 0.1999 - val_acc: 0.9635\n",
      " — val_f1: 0.964147 — val_precision: 0.969657 — val_recall 0.958700\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1755 - acc: 0.9715 - val_loss: 0.2550 - val_acc: 0.9407\n",
      " — val_f1: 0.940785 — val_precision: 0.947465 — val_recall 0.934200\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1594 - acc: 0.9734 - val_loss: 0.1907 - val_acc: 0.9638\n",
      " — val_f1: 0.964296 — val_precision: 0.969856 — val_recall 0.958800\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1481 - acc: 0.9756 - val_loss: 0.1613 - val_acc: 0.9709\n",
      " — val_f1: 0.971678 — val_precision: 0.975893 — val_recall 0.967500\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1413 - acc: 0.9767 - val_loss: 0.1464 - val_acc: 0.9750\n",
      " — val_f1: 0.975700 — val_precision: 0.979734 — val_recall 0.971700\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1331 - acc: 0.9784 - val_loss: 0.1658 - val_acc: 0.9677\n",
      " — val_f1: 0.967557 — val_precision: 0.971852 — val_recall 0.963300\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1298 - acc: 0.9788 - val_loss: 0.1333 - val_acc: 0.9782\n",
      " — val_f1: 0.978427 — val_precision: 0.981776 — val_recall 0.975100\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1251 - acc: 0.9796 - val_loss: 0.1357 - val_acc: 0.9760\n",
      " — val_f1: 0.976569 — val_precision: 0.979962 — val_recall 0.973200\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1228 - acc: 0.9799 - val_loss: 0.1369 - val_acc: 0.9767\n",
      " — val_f1: 0.976775 — val_precision: 0.979970 — val_recall 0.973600\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1191 - acc: 0.9803 - val_loss: 0.1498 - val_acc: 0.9694\n",
      " — val_f1: 0.969554 — val_precision: 0.972628 — val_recall 0.966500\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1179 - acc: 0.9799 - val_loss: 0.1387 - val_acc: 0.9734\n",
      " — val_f1: 0.973456 — val_precision: 0.976936 — val_recall 0.970000\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1149 - acc: 0.9805 - val_loss: 0.1345 - val_acc: 0.9763\n",
      " — val_f1: 0.976038 — val_precision: 0.978589 — val_recall 0.973500\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1117 - acc: 0.9817 - val_loss: 0.1443 - val_acc: 0.9710\n",
      " — val_f1: 0.971517 — val_precision: 0.974351 — val_recall 0.968700\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1122 - acc: 0.9814 - val_loss: 0.1668 - val_acc: 0.9623\n",
      " — val_f1: 0.963142 — val_precision: 0.967319 — val_recall 0.959000\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1105 - acc: 0.9819 - val_loss: 0.1290 - val_acc: 0.9758\n",
      " — val_f1: 0.976434 — val_precision: 0.979183 — val_recall 0.973700\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1097 - acc: 0.9815 - val_loss: 0.1320 - val_acc: 0.9763\n",
      " — val_f1: 0.976751 — val_precision: 0.978811 — val_recall 0.974700\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1076 - acc: 0.9824 - val_loss: 0.1252 - val_acc: 0.9782\n",
      " — val_f1: 0.978052 — val_precision: 0.980213 — val_recall 0.975900\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1069 - acc: 0.9813 - val_loss: 0.1288 - val_acc: 0.9769\n",
      " — val_f1: 0.977303 — val_precision: 0.979315 — val_recall 0.975300\n",
      "Test loss: 0.12878883066773414\n",
      "Test accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "l2_min = trials.best_trial['misc']['vals']['l2']\n",
    "\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(512, activation='relu', input_shape=(784,), kernel_regularizer=regularizers.l2(l2_min)))\n",
    "# model_2.add(Dropout(0.2))\n",
    "model_2.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(l2_min)))\n",
    "# model_2.add(Dropout(0.2))\n",
    "model_2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_2.summary()\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_2 = model_2.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test), callbacks=[metrics])\n",
    "score_2 = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score_2[0])\n",
    "print('Test accuracy:', score_2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, still the best model performs far less than the network without any L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.9081 - acc: 0.8545 - val_loss: 1.0652 - val_acc: 0.8935\n",
      " — val_f1: 0.889606 — val_precision: 0.927131 — val_recall 0.855000\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.9621 - acc: 0.9093 - val_loss: 0.8662 - val_acc: 0.9239\n",
      " — val_f1: 0.923234 — val_precision: 0.945493 — val_recall 0.902000\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.8498 - acc: 0.9230 - val_loss: 0.8058 - val_acc: 0.9313\n",
      " — val_f1: 0.931429 — val_precision: 0.950833 — val_recall 0.912800\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.7983 - acc: 0.9295 - val_loss: 0.7862 - val_acc: 0.9315\n",
      " — val_f1: 0.930223 — val_precision: 0.947893 — val_recall 0.913200\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.7702 - acc: 0.9341 - val_loss: 0.8002 - val_acc: 0.9224\n",
      " — val_f1: 0.923140 — val_precision: 0.942673 — val_recall 0.904400\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.7504 - acc: 0.9366 - val_loss: 0.7310 - val_acc: 0.9396\n",
      " — val_f1: 0.940144 — val_precision: 0.953984 — val_recall 0.926700\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.7335 - acc: 0.9383 - val_loss: 0.7173 - val_acc: 0.9384\n",
      " — val_f1: 0.939729 — val_precision: 0.952073 — val_recall 0.927700\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.7218 - acc: 0.9401 - val_loss: 0.6981 - val_acc: 0.9442\n",
      " — val_f1: 0.945145 — val_precision: 0.957611 — val_recall 0.933000\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.7102 - acc: 0.9419 - val_loss: 0.7261 - val_acc: 0.9336\n",
      " — val_f1: 0.934017 — val_precision: 0.948361 — val_recall 0.920100\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.7009 - acc: 0.9428 - val_loss: 0.6889 - val_acc: 0.9462\n",
      " — val_f1: 0.946836 — val_precision: 0.958031 — val_recall 0.935900\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.6922 - acc: 0.9456 - val_loss: 0.6768 - val_acc: 0.9471\n",
      " — val_f1: 0.947634 — val_precision: 0.957156 — val_recall 0.938300\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.6848 - acc: 0.9463 - val_loss: 0.6907 - val_acc: 0.9440\n",
      " — val_f1: 0.945164 — val_precision: 0.956388 — val_recall 0.934200\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.6777 - acc: 0.9478 - val_loss: 0.6670 - val_acc: 0.9496\n",
      " — val_f1: 0.949778 — val_precision: 0.959865 — val_recall 0.939900\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.6721 - acc: 0.9480 - val_loss: 0.6552 - val_acc: 0.9518\n",
      " — val_f1: 0.953045 — val_precision: 0.962472 — val_recall 0.943800\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.6672 - acc: 0.9490 - val_loss: 0.6557 - val_acc: 0.9511\n",
      " — val_f1: 0.951712 — val_precision: 0.961523 — val_recall 0.942100\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.6620 - acc: 0.9504 - val_loss: 0.6492 - val_acc: 0.9538\n",
      " — val_f1: 0.955218 — val_precision: 0.964617 — val_recall 0.946000\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.6583 - acc: 0.9503 - val_loss: 0.6761 - val_acc: 0.9437\n",
      " — val_f1: 0.943905 — val_precision: 0.954128 — val_recall 0.933900\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.6537 - acc: 0.9518 - val_loss: 0.6515 - val_acc: 0.9521\n",
      " — val_f1: 0.951948 — val_precision: 0.961068 — val_recall 0.943000\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.6507 - acc: 0.9519 - val_loss: 0.6645 - val_acc: 0.9449\n",
      " — val_f1: 0.945704 — val_precision: 0.955404 — val_recall 0.936200\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.6474 - acc: 0.9518 - val_loss: 0.6403 - val_acc: 0.9534\n",
      " — val_f1: 0.953733 — val_precision: 0.963564 — val_recall 0.944100\n",
      "Test loss: 0.12848583143949507\n",
      "Test accuracy: 0.9764\n"
     ]
    }
   ],
   "source": [
    "model_3= Sequential()\n",
    "model_3.add(Dense(512, activation='relu', input_shape=(784,), kernel_regularizer=regularizers.l1(0.001)))\n",
    "model_3.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l1(0.001)))\n",
    "model_3.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "model_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_3 = model_3.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test), callbacks=[metrics])\n",
    "score_3 = model_3.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score_2[0])\n",
    "print('Test accuracy:', score_2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_193 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 2.8357100369464785\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 3370.1246 - acc: 0.1289 - val_loss: 893.2433 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 891.3008 - acc: 0.1120 - val_loss: 888.9490 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 891.4844 - acc: 0.1121 - val_loss: 894.0403 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 891.5602 - acc: 0.1124 - val_loss: 889.1153 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 891.6158 - acc: 0.1124 - val_loss: 894.1492 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 891.7654 - acc: 0.1124 - val_loss: 889.4131 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 891.8348 - acc: 0.1124 - val_loss: 894.2561 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 891.8577 - acc: 0.1124 - val_loss: 889.4348 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 891.8518 - acc: 0.1124 - val_loss: 894.2847 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 891.8683 - acc: 0.1124 - val_loss: 889.4380 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 891.9170 - acc: 0.1124 - val_loss: 894.3842 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 891.9546 - acc: 0.1124 - val_loss: 889.5850 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 891.9924 - acc: 0.1124 - val_loss: 894.4591 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 892.0342 - acc: 0.1124 - val_loss: 889.6334 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 892.0524 - acc: 0.1124 - val_loss: 894.4883 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 892.0797 - acc: 0.1124 - val_loss: 889.6584 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 892.0822 - acc: 0.1124 - val_loss: 894.4786 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 892.0936 - acc: 0.1124 - val_loss: 889.6764 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 892.1033 - acc: 0.1124 - val_loss: 894.5043 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 892.0612 - acc: 0.1124 - val_loss: 889.6181 - val_acc: 0.1135\n",
      "Test loss: 889.618121484375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_196 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 1.7701340755263988\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 2108.5203 - acc: 0.1306 - val_loss: 561.9067 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 559.5740 - acc: 0.1122 - val_loss: 557.3997 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 559.7674 - acc: 0.1124 - val_loss: 562.1982 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 559.8488 - acc: 0.1124 - val_loss: 557.5428 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 559.9009 - acc: 0.1124 - val_loss: 562.2420 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 559.9557 - acc: 0.1124 - val_loss: 557.6524 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 559.9962 - acc: 0.1124 - val_loss: 562.3604 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 560.0662 - acc: 0.1124 - val_loss: 557.7393 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 560.0793 - acc: 0.1124 - val_loss: 562.4155 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 560.0958 - acc: 0.1124 - val_loss: 557.7587 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 560.0931 - acc: 0.1124 - val_loss: 562.4512 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 560.1089 - acc: 0.1124 - val_loss: 557.7691 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 560.1043 - acc: 0.1124 - val_loss: 562.4387 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 560.1183 - acc: 0.1124 - val_loss: 557.7758 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 560.1102 - acc: 0.1124 - val_loss: 562.4586 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 560.1181 - acc: 0.1124 - val_loss: 557.7765 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 560.1117 - acc: 0.1124 - val_loss: 562.4567 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 560.1329 - acc: 0.1124 - val_loss: 557.7881 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 560.1317 - acc: 0.1124 - val_loss: 562.4894 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 560.1377 - acc: 0.1124 - val_loss: 557.7929 - val_acc: 0.1135\n",
      "Test loss: 557.7928845703125\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_199 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 3.058101569192033\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 38us/step - loss: 3634.4500 - acc: 0.1308 - val_loss: 962.9117 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 958.8646 - acc: 0.1115 - val_loss: 954.6608 - val_acc: 0.1010\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 959.0404 - acc: 0.1118 - val_loss: 963.5666 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 959.2896 - acc: 0.1112 - val_loss: 954.9140 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 959.3360 - acc: 0.1124 - val_loss: 963.7531 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 959.4370 - acc: 0.1124 - val_loss: 955.0894 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 959.4399 - acc: 0.1124 - val_loss: 963.8399 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 959.5105 - acc: 0.1124 - val_loss: 955.1549 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 959.5263 - acc: 0.1124 - val_loss: 963.8803 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 959.5461 - acc: 0.1124 - val_loss: 955.1658 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 959.5832 - acc: 0.1124 - val_loss: 963.9295 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 959.6289 - acc: 0.1124 - val_loss: 955.3267 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 959.6240 - acc: 0.1124 - val_loss: 963.9590 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 959.6455 - acc: 0.1124 - val_loss: 955.2871 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 959.6306 - acc: 0.1124 - val_loss: 963.9213 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 959.6467 - acc: 0.1124 - val_loss: 955.3269 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 959.6482 - acc: 0.1124 - val_loss: 963.9557 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 959.6634 - acc: 0.1124 - val_loss: 955.3598 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 959.6463 - acc: 0.1124 - val_loss: 963.9885 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 959.6968 - acc: 0.1124 - val_loss: 955.3656 - val_acc: 0.1135\n",
      "Test loss: 955.3655727539062\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_202 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 3.0019110092647816\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 3568.9910 - acc: 0.1293 - val_loss: 946.5036 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 943.4091 - acc: 0.1111 - val_loss: 940.2093 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 943.5688 - acc: 0.1120 - val_loss: 946.9285 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 943.7180 - acc: 0.1124 - val_loss: 940.5814 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 943.7784 - acc: 0.1124 - val_loss: 947.0614 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 943.8516 - acc: 0.1124 - val_loss: 940.6295 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 943.8664 - acc: 0.1124 - val_loss: 947.1178 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 943.8996 - acc: 0.1124 - val_loss: 940.6722 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 943.9029 - acc: 0.1124 - val_loss: 947.1448 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 943.9185 - acc: 0.1124 - val_loss: 940.6282 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 943.9203 - acc: 0.1124 - val_loss: 947.2361 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 943.9413 - acc: 0.1124 - val_loss: 940.6510 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 943.9558 - acc: 0.1124 - val_loss: 947.2851 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 943.9821 - acc: 0.1124 - val_loss: 940.7015 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 944.0187 - acc: 0.1124 - val_loss: 947.3502 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 944.0628 - acc: 0.1124 - val_loss: 940.8530 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 944.0512 - acc: 0.1124 - val_loss: 947.3235 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 944.0546 - acc: 0.1124 - val_loss: 940.7655 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 944.0534 - acc: 0.1124 - val_loss: 947.3118 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 944.0671 - acc: 0.1124 - val_loss: 940.7548 - val_acc: 0.1135\n",
      "Test loss: 940.7547603515625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_205 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.7865372567764157\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 937.7804 - acc: 0.1276 - val_loss: 251.8119 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 251.1944 - acc: 0.1113 - val_loss: 250.5989 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 251.2444 - acc: 0.1125 - val_loss: 251.9181 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 251.3148 - acc: 0.1121 - val_loss: 250.6935 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 251.3365 - acc: 0.1124 - val_loss: 251.9777 - val_acc: 0.1135\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 21us/step - loss: 251.3494 - acc: 0.1124 - val_loss: 250.7147 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 251.3537 - acc: 0.1124 - val_loss: 251.9863 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 251.3637 - acc: 0.1124 - val_loss: 250.7376 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 251.3640 - acc: 0.1124 - val_loss: 251.9944 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 251.3764 - acc: 0.1124 - val_loss: 250.7479 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 251.3835 - acc: 0.1124 - val_loss: 252.0089 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 251.3900 - acc: 0.1124 - val_loss: 250.7757 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 251.3933 - acc: 0.1124 - val_loss: 252.0158 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 251.3980 - acc: 0.1124 - val_loss: 250.7781 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 251.4029 - acc: 0.1124 - val_loss: 252.0355 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 251.4063 - acc: 0.1124 - val_loss: 250.7715 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 251.4035 - acc: 0.1124 - val_loss: 252.0384 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 251.4055 - acc: 0.1124 - val_loss: 250.7682 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 251.4039 - acc: 0.1124 - val_loss: 252.0393 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 251.4057 - acc: 0.1124 - val_loss: 250.7689 - val_acc: 0.1135\n",
      "Test loss: 250.76893647460938\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_208 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 4.985608626353648\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 5927.8324 - acc: 0.1283 - val_loss: 1575.5128 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1568.8069 - acc: 0.1116 - val_loss: 1561.7666 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1568.9995 - acc: 0.1124 - val_loss: 1576.4301 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1569.4001 - acc: 0.1124 - val_loss: 1562.3427 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1569.5056 - acc: 0.1124 - val_loss: 1576.8988 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1569.6665 - acc: 0.1124 - val_loss: 1562.5020 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1569.8355 - acc: 0.1124 - val_loss: 1577.1997 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1569.8977 - acc: 0.1124 - val_loss: 1562.6583 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1569.8939 - acc: 0.1124 - val_loss: 1577.0268 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1569.8930 - acc: 0.1124 - val_loss: 1562.8081 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1569.8971 - acc: 0.1124 - val_loss: 1577.0256 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1569.8957 - acc: 0.1124 - val_loss: 1562.7737 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1569.8717 - acc: 0.1124 - val_loss: 1577.0091 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1569.9609 - acc: 0.1124 - val_loss: 1562.8224 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1569.9892 - acc: 0.1124 - val_loss: 1577.0928 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1570.0152 - acc: 0.1124 - val_loss: 1562.9671 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1569.9980 - acc: 0.1124 - val_loss: 1577.0416 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1570.0223 - acc: 0.1124 - val_loss: 1562.9581 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1570.0130 - acc: 0.1124 - val_loss: 1577.1120 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1569.7924 - acc: 0.1124 - val_loss: 1562.4877 - val_acc: 0.1135\n",
      "Test loss: 1562.48764765625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_211 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 2.39065953302085\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 2837.9505 - acc: 0.1295 - val_loss: 754.0586 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 751.3002 - acc: 0.1118 - val_loss: 748.4404 - val_acc: 0.1028\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 751.5187 - acc: 0.1120 - val_loss: 754.5964 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 751.7145 - acc: 0.1124 - val_loss: 748.8269 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 751.8743 - acc: 0.1124 - val_loss: 754.9520 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 752.0387 - acc: 0.1124 - val_loss: 749.1084 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 752.0679 - acc: 0.1124 - val_loss: 755.0516 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 752.1311 - acc: 0.1124 - val_loss: 749.2345 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 752.1494 - acc: 0.1124 - val_loss: 755.0975 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 752.1665 - acc: 0.1124 - val_loss: 749.2166 - val_acc: 0.1135\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 752.1583 - acc: 0.1124 - val_loss: 755.1151 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 752.1654 - acc: 0.1124 - val_loss: 749.2487 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 752.1593 - acc: 0.1124 - val_loss: 755.0799 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 752.1689 - acc: 0.1124 - val_loss: 749.2257 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 752.1614 - acc: 0.1124 - val_loss: 755.1064 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 752.1716 - acc: 0.1124 - val_loss: 749.2261 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 752.1612 - acc: 0.1124 - val_loss: 755.1005 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 752.1710 - acc: 0.1124 - val_loss: 749.2486 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 752.1655 - acc: 0.1124 - val_loss: 755.0817 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 752.1725 - acc: 0.1124 - val_loss: 749.2507 - val_acc: 0.1135\n",
      "Test loss: 749.250738671875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_214 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 3.7398292070654\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 4435.3856 - acc: 0.1287 - val_loss: 1178.3028 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1173.0877 - acc: 0.1110 - val_loss: 1167.9157 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1173.5006 - acc: 0.1124 - val_loss: 1178.9111 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1173.6854 - acc: 0.1124 - val_loss: 1168.4513 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1173.7800 - acc: 0.1124 - val_loss: 1179.0404 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1173.9166 - acc: 0.1124 - val_loss: 1168.6283 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1173.9580 - acc: 0.1124 - val_loss: 1179.2657 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1173.9845 - acc: 0.1124 - val_loss: 1168.7017 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1173.9902 - acc: 0.1124 - val_loss: 1179.2773 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1174.0092 - acc: 0.1124 - val_loss: 1168.7965 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1174.0054 - acc: 0.1124 - val_loss: 1179.1911 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1174.0613 - acc: 0.1124 - val_loss: 1168.8730 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1174.0709 - acc: 0.1124 - val_loss: 1179.2441 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1174.0859 - acc: 0.1124 - val_loss: 1168.8632 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1174.0556 - acc: 0.1124 - val_loss: 1179.2784 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1174.0675 - acc: 0.1124 - val_loss: 1168.8734 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1174.0813 - acc: 0.1124 - val_loss: 1179.3176 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1174.1008 - acc: 0.1124 - val_loss: 1168.8725 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1174.0893 - acc: 0.1124 - val_loss: 1179.3550 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1174.1243 - acc: 0.1124 - val_loss: 1168.8903 - val_acc: 0.1135\n",
      "Test loss: 1168.890294921875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_217 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.21241525252439844\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 255.4686 - acc: 0.1316 - val_loss: 70.5071 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 70.2752 - acc: 0.1114 - val_loss: 70.0464 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 70.2939 - acc: 0.1121 - val_loss: 70.5453 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 70.3022 - acc: 0.1124 - val_loss: 70.0615 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 70.3052 - acc: 0.1124 - val_loss: 70.5471 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 70.3077 - acc: 0.1124 - val_loss: 70.0708 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 70.3079 - acc: 0.1124 - val_loss: 70.5449 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 70.3130 - acc: 0.1124 - val_loss: 70.0767 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 70.3142 - acc: 0.1124 - val_loss: 70.5523 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 70.3147 - acc: 0.1124 - val_loss: 70.0761 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 70.3147 - acc: 0.1124 - val_loss: 70.5538 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 70.3160 - acc: 0.1124 - val_loss: 70.0780 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 70.3156 - acc: 0.1124 - val_loss: 70.5536 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 70.3168 - acc: 0.1124 - val_loss: 70.0774 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 70.3155 - acc: 0.1124 - val_loss: 70.5532 - val_acc: 0.1135\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 70.3162 - acc: 0.1124 - val_loss: 70.0775 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 70.3154 - acc: 0.1124 - val_loss: 70.5533 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 70.3163 - acc: 0.1124 - val_loss: 70.0782 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 70.3156 - acc: 0.1124 - val_loss: 70.5534 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 70.3163 - acc: 0.1124 - val_loss: 70.0774 - val_acc: 0.1135\n",
      "Test loss: 70.07741674804687\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_220 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 3.9038514184354653\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 4635.1892 - acc: 0.1286 - val_loss: 1228.8655 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.3631 - acc: 0.1117 - val_loss: 1221.8202 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.6613 - acc: 0.1124 - val_loss: 1229.6918 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.6378 - acc: 0.1121 - val_loss: 1221.6551 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.6842 - acc: 0.1124 - val_loss: 1229.5386 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.7203 - acc: 0.1124 - val_loss: 1221.9614 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.7995 - acc: 0.1124 - val_loss: 1229.6873 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.8492 - acc: 0.1124 - val_loss: 1221.9605 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.8561 - acc: 0.1124 - val_loss: 1229.6644 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.8596 - acc: 0.1124 - val_loss: 1221.9909 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.8642 - acc: 0.1124 - val_loss: 1229.7375 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.8906 - acc: 0.1124 - val_loss: 1221.9970 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.8812 - acc: 0.1124 - val_loss: 1229.7270 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.8953 - acc: 0.1124 - val_loss: 1222.0748 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.8944 - acc: 0.1124 - val_loss: 1229.7367 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.8971 - acc: 0.1124 - val_loss: 1222.0339 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.8863 - acc: 0.1124 - val_loss: 1229.7660 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.8964 - acc: 0.1124 - val_loss: 1222.0372 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.8864 - acc: 0.1124 - val_loss: 1229.7272 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1225.9058 - acc: 0.1124 - val_loss: 1222.0635 - val_acc: 0.1135\n",
      "Test loss: 1222.063510546875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_223 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.012245659495906466\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 16.9785 - acc: 0.1297 - val_loss: 6.3025 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2945 - acc: 0.1121 - val_loss: 6.2881 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2952 - acc: 0.1123 - val_loss: 6.3020 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2954 - acc: 0.1124 - val_loss: 6.2885 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2953 - acc: 0.1124 - val_loss: 6.3022 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2954 - acc: 0.1124 - val_loss: 6.2882 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2953 - acc: 0.1124 - val_loss: 6.3015 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2954 - acc: 0.1124 - val_loss: 6.2887 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2953 - acc: 0.1124 - val_loss: 6.3013 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2953 - acc: 0.1124 - val_loss: 6.2884 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2952 - acc: 0.1124 - val_loss: 6.3011 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2953 - acc: 0.1124 - val_loss: 6.2886 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2952 - acc: 0.1124 - val_loss: 6.3016 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2953 - acc: 0.1124 - val_loss: 6.2885 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2952 - acc: 0.1124 - val_loss: 6.3014 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2952 - acc: 0.1124 - val_loss: 6.2883 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2952 - acc: 0.1124 - val_loss: 6.3018 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2952 - acc: 0.1124 - val_loss: 6.2882 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2952 - acc: 0.1124 - val_loss: 6.3018 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.2953 - acc: 0.1124 - val_loss: 6.2881 - val_acc: 0.1135\n",
      "Test loss: 6.288106199645996\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_226 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 4.786602448837848\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 41us/step - loss: 5684.8317 - acc: 0.1270 - val_loss: 1506.8400 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1500.8737 - acc: 0.1125 - val_loss: 1494.6291 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1501.1803 - acc: 0.1122 - val_loss: 1507.7883 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1501.4429 - acc: 0.1123 - val_loss: 1495.2115 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1501.6756 - acc: 0.1124 - val_loss: 1508.1863 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1501.8765 - acc: 0.1124 - val_loss: 1495.6269 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1501.9630 - acc: 0.1124 - val_loss: 1508.3586 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1502.0405 - acc: 0.1124 - val_loss: 1495.8279 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1502.1207 - acc: 0.1124 - val_loss: 1508.4220 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1502.1559 - acc: 0.1124 - val_loss: 1495.8969 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1502.1835 - acc: 0.1124 - val_loss: 1508.4030 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1502.2716 - acc: 0.1124 - val_loss: 1496.0995 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1502.2946 - acc: 0.1124 - val_loss: 1508.4913 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1502.3205 - acc: 0.1124 - val_loss: 1496.0515 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1502.3096 - acc: 0.1124 - val_loss: 1508.4828 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1502.3413 - acc: 0.1124 - val_loss: 1496.1576 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1502.3199 - acc: 0.1124 - val_loss: 1508.5022 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1502.3504 - acc: 0.1124 - val_loss: 1496.1359 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1502.3204 - acc: 0.1124 - val_loss: 1508.5267 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1502.3342 - acc: 0.1124 - val_loss: 1496.1280 - val_acc: 0.1135\n",
      "Test loss: 1496.127947265625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_229 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 1.6949293212411656\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 2017.2330 - acc: 0.1316 - val_loss: 535.7124 - val_acc: 0.1027\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.3256 - acc: 0.1120 - val_loss: 532.7635 - val_acc: 0.1028\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.4954 - acc: 0.1119 - val_loss: 536.1969 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.6253 - acc: 0.1124 - val_loss: 533.0235 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.7185 - acc: 0.1124 - val_loss: 536.3976 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.7861 - acc: 0.1124 - val_loss: 533.1835 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.8127 - acc: 0.1124 - val_loss: 536.4359 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.8602 - acc: 0.1124 - val_loss: 533.2751 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.8678 - acc: 0.1124 - val_loss: 536.4794 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.8795 - acc: 0.1124 - val_loss: 533.2673 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.8822 - acc: 0.1124 - val_loss: 536.4688 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.8895 - acc: 0.1124 - val_loss: 533.2925 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.8880 - acc: 0.1124 - val_loss: 536.4649 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.8946 - acc: 0.1124 - val_loss: 533.2928 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.8895 - acc: 0.1124 - val_loss: 536.4753 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.9005 - acc: 0.1124 - val_loss: 533.3181 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.9003 - acc: 0.1124 - val_loss: 536.4852 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.9076 - acc: 0.1124 - val_loss: 533.3145 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.9187 - acc: 0.1124 - val_loss: 536.5223 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 534.9305 - acc: 0.1124 - val_loss: 533.3420 - val_acc: 0.1135\n",
      "Test loss: 533.341978515625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_232 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 3.8113819194700236\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 4532.2250 - acc: 0.1299 - val_loss: 1201.2111 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1197.8993 - acc: 0.1116 - val_loss: 1194.4501 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1198.4165 - acc: 0.1117 - val_loss: 1202.4355 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1198.5858 - acc: 0.1124 - val_loss: 1194.8524 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1198.8959 - acc: 0.1124 - val_loss: 1203.0867 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.1928 - acc: 0.1124 - val_loss: 1195.1587 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.2912 - acc: 0.1124 - val_loss: 1203.4814 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.3085 - acc: 0.1124 - val_loss: 1195.1244 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.3266 - acc: 0.1124 - val_loss: 1203.4625 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.3436 - acc: 0.1124 - val_loss: 1195.2475 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.3430 - acc: 0.1124 - val_loss: 1203.4980 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.3574 - acc: 0.1124 - val_loss: 1195.1935 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.3480 - acc: 0.1124 - val_loss: 1203.5032 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.3705 - acc: 0.1124 - val_loss: 1195.2178 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.3759 - acc: 0.1124 - val_loss: 1203.5886 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.4040 - acc: 0.1124 - val_loss: 1195.1866 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.3988 - acc: 0.1124 - val_loss: 1203.5841 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.4074 - acc: 0.1124 - val_loss: 1195.2752 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.4109 - acc: 0.1124 - val_loss: 1203.6052 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1199.4497 - acc: 0.1124 - val_loss: 1195.2899 - val_acc: 0.1135\n",
      "Test loss: 1195.289933203125\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_235 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 4.34675917653861\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 5168.8358 - acc: 0.1273 - val_loss: 1370.2475 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1364.5416 - acc: 0.1118 - val_loss: 1358.7074 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1364.8634 - acc: 0.1118 - val_loss: 1371.4586 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.1887 - acc: 0.1124 - val_loss: 1358.9665 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.1985 - acc: 0.1124 - val_loss: 1371.3510 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2392 - acc: 0.1124 - val_loss: 1359.0495 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2593 - acc: 0.1124 - val_loss: 1371.5827 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2662 - acc: 0.1124 - val_loss: 1359.0259 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2452 - acc: 0.1124 - val_loss: 1371.5109 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2788 - acc: 0.1124 - val_loss: 1359.0897 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2682 - acc: 0.1124 - val_loss: 1371.4401 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2927 - acc: 0.1124 - val_loss: 1359.0760 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2707 - acc: 0.1124 - val_loss: 1371.4469 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2886 - acc: 0.1124 - val_loss: 1359.1119 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2744 - acc: 0.1124 - val_loss: 1371.4613 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2960 - acc: 0.1124 - val_loss: 1359.0935 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2762 - acc: 0.1124 - val_loss: 1371.4824 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2994 - acc: 0.1124 - val_loss: 1359.0709 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2821 - acc: 0.1124 - val_loss: 1371.5159 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1365.2935 - acc: 0.1124 - val_loss: 1359.0887 - val_acc: 0.1135\n",
      "Test loss: 1359.0886609375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_238 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 1.9567264098251915\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 2328.1162 - acc: 0.1360 - val_loss: 620.2721 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.2883 - acc: 0.1110 - val_loss: 616.1647 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.4943 - acc: 0.1124 - val_loss: 620.7824 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.6727 - acc: 0.1124 - val_loss: 616.4848 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.7519 - acc: 0.1124 - val_loss: 620.9780 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.8197 - acc: 0.1124 - val_loss: 616.6429 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.8212 - acc: 0.1124 - val_loss: 621.0459 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.8560 - acc: 0.1124 - val_loss: 616.6507 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.8569 - acc: 0.1124 - val_loss: 621.0620 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.8788 - acc: 0.1124 - val_loss: 616.6727 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.9035 - acc: 0.1124 - val_loss: 621.1222 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.9071 - acc: 0.1124 - val_loss: 616.6887 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.8998 - acc: 0.1124 - val_loss: 621.1075 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.9048 - acc: 0.1124 - val_loss: 616.6844 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.9018 - acc: 0.1124 - val_loss: 621.1294 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.9158 - acc: 0.1124 - val_loss: 616.6766 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.9281 - acc: 0.1124 - val_loss: 621.1877 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.9666 - acc: 0.1124 - val_loss: 616.7323 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.9733 - acc: 0.1124 - val_loss: 621.2045 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 618.9934 - acc: 0.1124 - val_loss: 616.7730 - val_acc: 0.1135\n",
      "Test loss: 616.7730116210937\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_241 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 2.417107813958988\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 2876.3587 - acc: 0.1323 - val_loss: 764.4511 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 761.8839 - acc: 0.1118 - val_loss: 759.4522 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.0973 - acc: 0.1119 - val_loss: 764.8346 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.2183 - acc: 0.1124 - val_loss: 759.6554 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.2694 - acc: 0.1124 - val_loss: 764.8856 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.3224 - acc: 0.1124 - val_loss: 759.7483 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.3335 - acc: 0.1124 - val_loss: 764.9186 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.3504 - acc: 0.1124 - val_loss: 759.7829 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.3436 - acc: 0.1124 - val_loss: 764.8891 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.3712 - acc: 0.1124 - val_loss: 759.7974 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.3885 - acc: 0.1124 - val_loss: 764.9673 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.4255 - acc: 0.1124 - val_loss: 759.8561 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.4341 - acc: 0.1124 - val_loss: 765.0112 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.4455 - acc: 0.1124 - val_loss: 759.8477 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.4464 - acc: 0.1124 - val_loss: 765.0693 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.4567 - acc: 0.1124 - val_loss: 759.8781 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.4478 - acc: 0.1124 - val_loss: 765.0401 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.4553 - acc: 0.1124 - val_loss: 759.8800 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.4456 - acc: 0.1124 - val_loss: 765.0106 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 762.4326 - acc: 0.1124 - val_loss: 759.7804 - val_acc: 0.1135\n",
      "Test loss: 759.7803580078125\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_244 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 2.912404673604388\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 3457.1199 - acc: 0.1256 - val_loss: 919.2655 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 915.6531 - acc: 0.1120 - val_loss: 912.0569 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 915.8555 - acc: 0.1124 - val_loss: 919.7741 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 915.9657 - acc: 0.1124 - val_loss: 912.2293 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.0558 - acc: 0.1124 - val_loss: 919.9021 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.1674 - acc: 0.1124 - val_loss: 912.3356 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.1950 - acc: 0.1124 - val_loss: 920.0740 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.2195 - acc: 0.1124 - val_loss: 912.3393 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.2488 - acc: 0.1124 - val_loss: 920.1260 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.3036 - acc: 0.1124 - val_loss: 912.4545 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.3088 - acc: 0.1124 - val_loss: 920.1463 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.3412 - acc: 0.1124 - val_loss: 912.5386 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.3692 - acc: 0.1124 - val_loss: 920.1656 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.3881 - acc: 0.1124 - val_loss: 912.5854 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.3792 - acc: 0.1124 - val_loss: 920.1653 - val_acc: 0.1135\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.3947 - acc: 0.1124 - val_loss: 912.5983 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.3849 - acc: 0.1124 - val_loss: 920.1530 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.4014 - acc: 0.1124 - val_loss: 912.6005 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.3907 - acc: 0.1124 - val_loss: 920.1921 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 916.4072 - acc: 0.1124 - val_loss: 912.6116 - val_acc: 0.1135\n",
      "Test loss: 912.6115845703125\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_247 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.7327553712436691\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 874.7798 - acc: 0.1321 - val_loss: 234.2998 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 233.7324 - acc: 0.1120 - val_loss: 233.2159 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 233.8288 - acc: 0.1123 - val_loss: 234.4268 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 233.8742 - acc: 0.1124 - val_loss: 233.3326 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 233.9034 - acc: 0.1124 - val_loss: 234.4780 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 233.9221 - acc: 0.1124 - val_loss: 233.3457 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 233.9306 - acc: 0.1124 - val_loss: 234.5153 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 233.9518 - acc: 0.1124 - val_loss: 233.3901 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 233.9548 - acc: 0.1124 - val_loss: 234.5271 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 233.9659 - acc: 0.1124 - val_loss: 233.3907 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 233.9715 - acc: 0.1124 - val_loss: 234.5452 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 233.9739 - acc: 0.1124 - val_loss: 233.4035 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 233.9730 - acc: 0.1124 - val_loss: 234.5457 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 233.9750 - acc: 0.1124 - val_loss: 233.4137 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 233.9819 - acc: 0.1124 - val_loss: 234.5894 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 234.0112 - acc: 0.1124 - val_loss: 233.4306 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 234.0101 - acc: 0.1124 - val_loss: 234.5826 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 234.0129 - acc: 0.1124 - val_loss: 233.4471 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 234.0116 - acc: 0.1124 - val_loss: 234.5769 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 234.0134 - acc: 0.1124 - val_loss: 233.4512 - val_acc: 0.1135\n",
      "Test loss: 233.45115954589843\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_250 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 4.656760946591646\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 5542.2344 - acc: 0.1288 - val_loss: 1466.4115 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1461.0232 - acc: 0.1121 - val_loss: 1455.5393 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1461.3868 - acc: 0.1116 - val_loss: 1467.4267 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1461.7217 - acc: 0.1124 - val_loss: 1456.0816 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1461.8008 - acc: 0.1124 - val_loss: 1467.5426 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1461.8778 - acc: 0.1124 - val_loss: 1456.2789 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1461.9016 - acc: 0.1124 - val_loss: 1467.6191 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1461.9526 - acc: 0.1124 - val_loss: 1456.1332 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1461.9173 - acc: 0.1124 - val_loss: 1467.6417 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1461.9385 - acc: 0.1124 - val_loss: 1456.2814 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1461.9814 - acc: 0.1124 - val_loss: 1467.7539 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1462.0706 - acc: 0.1124 - val_loss: 1456.3169 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1462.1087 - acc: 0.1124 - val_loss: 1467.8490 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1462.1480 - acc: 0.1124 - val_loss: 1456.3810 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1462.1310 - acc: 0.1124 - val_loss: 1467.9118 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1462.1600 - acc: 0.1124 - val_loss: 1456.4951 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1462.1949 - acc: 0.1124 - val_loss: 1467.9059 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1462.2190 - acc: 0.1124 - val_loss: 1456.4548 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1462.2047 - acc: 0.1124 - val_loss: 1467.9934 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1462.2249 - acc: 0.1124 - val_loss: 1456.4458 - val_acc: 0.1135\n",
      "Test loss: 1456.445805859375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_253 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 3.081816484711645\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 43us/step - loss: 3663.2582 - acc: 0.1326 - val_loss: 973.3561 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 969.5737 - acc: 0.1114 - val_loss: 965.9330 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 969.9583 - acc: 0.1118 - val_loss: 974.1410 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 970.0688 - acc: 0.1124 - val_loss: 966.2527 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 970.2201 - acc: 0.1124 - val_loss: 974.2713 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 970.2767 - acc: 0.1124 - val_loss: 966.2691 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 970.3685 - acc: 0.1124 - val_loss: 974.3992 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 970.4138 - acc: 0.1124 - val_loss: 966.3901 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 970.4166 - acc: 0.1124 - val_loss: 974.4550 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 970.4369 - acc: 0.1124 - val_loss: 966.4215 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 970.4677 - acc: 0.1124 - val_loss: 974.4941 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 970.4946 - acc: 0.1124 - val_loss: 966.4699 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 970.4930 - acc: 0.1124 - val_loss: 974.5277 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 970.5265 - acc: 0.1124 - val_loss: 966.5415 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 970.5262 - acc: 0.1124 - val_loss: 974.4945 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 970.5429 - acc: 0.1124 - val_loss: 966.5996 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 970.5353 - acc: 0.1124 - val_loss: 974.4693 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 970.5504 - acc: 0.1124 - val_loss: 966.6339 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 970.5483 - acc: 0.1124 - val_loss: 974.4691 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 970.5599 - acc: 0.1124 - val_loss: 966.6015 - val_acc: 0.1135\n",
      "Test loss: 966.6014865234375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_256 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 0.9975372857148964\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 1187.9587 - acc: 0.1296 - val_loss: 317.5914 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 316.5855 - acc: 0.1125 - val_loss: 315.5058 - val_acc: 0.0980\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 316.6432 - acc: 0.1120 - val_loss: 317.7892 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 316.7257 - acc: 0.1124 - val_loss: 315.6744 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 316.7955 - acc: 0.1124 - val_loss: 317.8942 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 316.8052 - acc: 0.1124 - val_loss: 315.7061 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 316.8056 - acc: 0.1124 - val_loss: 317.8943 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 316.8099 - acc: 0.1124 - val_loss: 315.7183 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 316.8092 - acc: 0.1124 - val_loss: 317.9041 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 316.8261 - acc: 0.1124 - val_loss: 315.7338 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 316.8388 - acc: 0.1124 - val_loss: 317.9371 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 316.8475 - acc: 0.1124 - val_loss: 315.7526 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 316.8513 - acc: 0.1124 - val_loss: 317.9476 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 316.8622 - acc: 0.1124 - val_loss: 315.7800 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 316.8745 - acc: 0.1124 - val_loss: 317.9796 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 316.8934 - acc: 0.1124 - val_loss: 315.8098 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 316.8984 - acc: 0.1124 - val_loss: 317.9943 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 316.9033 - acc: 0.1124 - val_loss: 315.8025 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 316.9018 - acc: 0.1124 - val_loss: 317.9897 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 316.9060 - acc: 0.1124 - val_loss: 315.8211 - val_acc: 0.1135\n",
      "Test loss: 315.82105249023436\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_259 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 4.4827075495046085\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 5324.3841 - acc: 0.1264 - val_loss: 1409.4381 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1405.4525 - acc: 0.1118 - val_loss: 1401.5110 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1405.9156 - acc: 0.1121 - val_loss: 1410.4122 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1406.2707 - acc: 0.1124 - val_loss: 1402.1617 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1406.3848 - acc: 0.1124 - val_loss: 1410.7066 - val_acc: 0.1135\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 20us/step - loss: 1406.5453 - acc: 0.1124 - val_loss: 1402.4109 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1406.6213 - acc: 0.1124 - val_loss: 1410.8287 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1406.6681 - acc: 0.1124 - val_loss: 1402.4253 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1406.7346 - acc: 0.1124 - val_loss: 1410.9301 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1406.7722 - acc: 0.1124 - val_loss: 1402.5950 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1406.8010 - acc: 0.1124 - val_loss: 1411.0042 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1407.0254 - acc: 0.1124 - val_loss: 1402.9002 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1407.0773 - acc: 0.1124 - val_loss: 1411.1579 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1407.0828 - acc: 0.1124 - val_loss: 1402.9850 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1407.0702 - acc: 0.1124 - val_loss: 1411.1211 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1407.0832 - acc: 0.1124 - val_loss: 1402.9917 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1407.0720 - acc: 0.1124 - val_loss: 1411.1901 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1407.0861 - acc: 0.1124 - val_loss: 1402.9628 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1407.0717 - acc: 0.1124 - val_loss: 1411.1734 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 1407.0726 - acc: 0.1124 - val_loss: 1402.9751 - val_acc: 0.1135\n",
      "Test loss: 1402.9751205078126\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_262 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_264 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 3.4164537422203107\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 4062.9694 - acc: 0.1237 - val_loss: 1076.7818 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1072.7196 - acc: 0.1121 - val_loss: 1068.4923 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1073.3747 - acc: 0.1121 - val_loss: 1078.3651 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1073.6296 - acc: 0.1124 - val_loss: 1068.9459 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1073.7088 - acc: 0.1124 - val_loss: 1078.4372 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1073.7759 - acc: 0.1124 - val_loss: 1069.0190 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1073.8195 - acc: 0.1124 - val_loss: 1078.5413 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1073.8320 - acc: 0.1124 - val_loss: 1069.0564 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1073.8498 - acc: 0.1124 - val_loss: 1078.5589 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1073.9423 - acc: 0.1124 - val_loss: 1069.1337 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1073.9530 - acc: 0.1124 - val_loss: 1078.7317 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1073.9979 - acc: 0.1124 - val_loss: 1069.2703 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1073.9857 - acc: 0.1124 - val_loss: 1078.7912 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1074.0448 - acc: 0.1124 - val_loss: 1069.2836 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1074.0297 - acc: 0.1124 - val_loss: 1078.8085 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1074.0438 - acc: 0.1124 - val_loss: 1069.2472 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1074.0310 - acc: 0.1124 - val_loss: 1078.8269 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1074.0559 - acc: 0.1124 - val_loss: 1069.2770 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1074.0497 - acc: 0.1124 - val_loss: 1078.8068 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1074.0612 - acc: 0.1124 - val_loss: 1069.2805 - val_acc: 0.1135\n",
      "Test loss: 1069.280465234375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_265 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 1.0439126523684032\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 1242.1705 - acc: 0.1300 - val_loss: 332.7313 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 331.0998 - acc: 0.1106 - val_loss: 329.5310 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 331.1608 - acc: 0.1121 - val_loss: 332.8070 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 331.2406 - acc: 0.1120 - val_loss: 329.6401 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 331.2711 - acc: 0.1124 - val_loss: 332.9139 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 331.3156 - acc: 0.1124 - val_loss: 329.7177 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 331.3376 - acc: 0.1124 - val_loss: 332.9669 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 331.3618 - acc: 0.1124 - val_loss: 329.7388 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 331.3663 - acc: 0.1124 - val_loss: 332.9867 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 331.3733 - acc: 0.1124 - val_loss: 329.7480 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 331.3762 - acc: 0.1124 - val_loss: 333.0131 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 331.3829 - acc: 0.1124 - val_loss: 329.7527 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 331.3769 - acc: 0.1124 - val_loss: 333.0122 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 331.3821 - acc: 0.1124 - val_loss: 329.7422 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 331.3775 - acc: 0.1124 - val_loss: 333.0186 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 331.3831 - acc: 0.1124 - val_loss: 329.7487 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 331.3775 - acc: 0.1124 - val_loss: 333.0089 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 331.3828 - acc: 0.1124 - val_loss: 329.7508 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 331.3802 - acc: 0.1124 - val_loss: 333.0206 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 331.3891 - acc: 0.1124 - val_loss: 329.7647 - val_acc: 0.1135\n",
      "Test loss: 329.7646669433594\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_268 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_270 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 4.293005825034324\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 5104.0091 - acc: 0.1339 - val_loss: 1352.3377 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1348.1790 - acc: 0.1121 - val_loss: 1343.8810 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1348.3610 - acc: 0.1124 - val_loss: 1353.0162 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1348.6204 - acc: 0.1122 - val_loss: 1344.2242 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1348.7365 - acc: 0.1124 - val_loss: 1353.3219 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1348.9317 - acc: 0.1124 - val_loss: 1344.4373 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1349.0162 - acc: 0.1124 - val_loss: 1353.6050 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1349.0847 - acc: 0.1124 - val_loss: 1344.5283 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1349.0825 - acc: 0.1124 - val_loss: 1353.5775 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1349.1436 - acc: 0.1124 - val_loss: 1344.5131 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1349.1294 - acc: 0.1124 - val_loss: 1353.6436 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1349.1469 - acc: 0.1124 - val_loss: 1344.6128 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1349.1397 - acc: 0.1124 - val_loss: 1353.6664 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1349.1882 - acc: 0.1124 - val_loss: 1344.6329 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1349.1879 - acc: 0.1124 - val_loss: 1353.7627 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1349.2147 - acc: 0.1124 - val_loss: 1344.7200 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1349.2551 - acc: 0.1124 - val_loss: 1353.8228 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1349.2757 - acc: 0.1124 - val_loss: 1344.7204 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1349.2602 - acc: 0.1124 - val_loss: 1353.7524 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1349.2737 - acc: 0.1124 - val_loss: 1344.7853 - val_acc: 0.1135\n",
      "Test loss: 1344.785304296875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_271 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_273 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 3.4183250843270465\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 4058.6311 - acc: 0.1252 - val_loss: 1075.8100 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1071.7155 - acc: 0.1114 - val_loss: 1067.2460 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1071.7612 - acc: 0.1124 - val_loss: 1076.1001 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1071.9965 - acc: 0.1124 - val_loss: 1067.8441 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1072.2542 - acc: 0.1124 - val_loss: 1076.6437 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1072.3610 - acc: 0.1124 - val_loss: 1068.1444 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1072.4297 - acc: 0.1124 - val_loss: 1076.7245 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1072.4659 - acc: 0.1124 - val_loss: 1068.1368 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1072.4985 - acc: 0.1124 - val_loss: 1076.8253 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1072.5534 - acc: 0.1124 - val_loss: 1068.2858 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1072.5758 - acc: 0.1124 - val_loss: 1076.8500 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1072.6005 - acc: 0.1124 - val_loss: 1068.3329 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1072.5920 - acc: 0.1124 - val_loss: 1076.8498 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1072.6242 - acc: 0.1124 - val_loss: 1068.3721 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1072.6433 - acc: 0.1124 - val_loss: 1076.9233 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1072.6668 - acc: 0.1124 - val_loss: 1068.3914 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1072.6543 - acc: 0.1124 - val_loss: 1076.9105 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1072.6735 - acc: 0.1124 - val_loss: 1068.3884 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1072.6828 - acc: 0.1124 - val_loss: 1076.9734 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1072.6960 - acc: 0.1124 - val_loss: 1068.4360 - val_acc: 0.1135\n",
      "Test loss: 1068.435978515625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_274 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_276 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 1.311659237924918\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 1560.1146 - acc: 0.1300 - val_loss: 415.5335 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 414.3528 - acc: 0.1122 - val_loss: 413.2904 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 414.6028 - acc: 0.1114 - val_loss: 415.8119 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 414.6920 - acc: 0.1124 - val_loss: 413.5736 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 414.7557 - acc: 0.1124 - val_loss: 415.9006 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 414.7925 - acc: 0.1124 - val_loss: 413.6696 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 414.8096 - acc: 0.1124 - val_loss: 415.9707 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 414.8358 - acc: 0.1124 - val_loss: 413.6921 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 414.8439 - acc: 0.1124 - val_loss: 416.0106 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 414.8521 - acc: 0.1124 - val_loss: 413.6893 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 414.8502 - acc: 0.1124 - val_loss: 416.0228 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 414.8583 - acc: 0.1124 - val_loss: 413.7056 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 414.8571 - acc: 0.1124 - val_loss: 416.0186 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 414.8614 - acc: 0.1124 - val_loss: 413.7079 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 414.8570 - acc: 0.1124 - val_loss: 416.0101 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 414.8627 - acc: 0.1124 - val_loss: 413.7195 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 414.8707 - acc: 0.1124 - val_loss: 416.0243 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 414.8769 - acc: 0.1124 - val_loss: 413.7234 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 414.8744 - acc: 0.1124 - val_loss: 416.0331 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 414.8779 - acc: 0.1124 - val_loss: 413.7261 - val_acc: 0.1135\n",
      "Test loss: 413.7261015625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_277 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_279 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 4.206079198436353\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 4996.5735 - acc: 0.1304 - val_loss: 1321.8859 - val_acc: 0.0980\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1317.4849 - acc: 0.1120 - val_loss: 1312.8940 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1317.8730 - acc: 0.1122 - val_loss: 1323.0205 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.2116 - acc: 0.1124 - val_loss: 1313.1913 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.1738 - acc: 0.1124 - val_loss: 1323.2340 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.2108 - acc: 0.1124 - val_loss: 1313.1740 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1318.2725 - acc: 0.1124 - val_loss: 1323.3720 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.3203 - acc: 0.1124 - val_loss: 1313.3890 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.3356 - acc: 0.1124 - val_loss: 1323.3354 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.3551 - acc: 0.1124 - val_loss: 1313.2631 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.3404 - acc: 0.1124 - val_loss: 1323.4077 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.3608 - acc: 0.1124 - val_loss: 1313.2892 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.3467 - acc: 0.1124 - val_loss: 1323.3360 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.3642 - acc: 0.1124 - val_loss: 1313.3683 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.3471 - acc: 0.1124 - val_loss: 1323.4169 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.3600 - acc: 0.1124 - val_loss: 1313.3304 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.3450 - acc: 0.1124 - val_loss: 1323.3763 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.3670 - acc: 0.1124 - val_loss: 1313.3308 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.3494 - acc: 0.1124 - val_loss: 1323.3950 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1318.3766 - acc: 0.1124 - val_loss: 1313.3862 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1313.3861716796875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_280 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L2 regularization parameter 2.0985786606159245\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 2496.8232 - acc: 0.1304 - val_loss: 664.6103 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.1828 - acc: 0.1113 - val_loss: 659.6731 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.3803 - acc: 0.1120 - val_loss: 665.1964 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.6874 - acc: 0.1124 - val_loss: 660.1333 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.7973 - acc: 0.1124 - val_loss: 665.3758 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.8554 - acc: 0.1124 - val_loss: 660.3426 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.9180 - acc: 0.1124 - val_loss: 665.5172 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.9775 - acc: 0.1124 - val_loss: 660.4260 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.9753 - acc: 0.1124 - val_loss: 665.5665 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.9813 - acc: 0.1124 - val_loss: 660.4120 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.9680 - acc: 0.1124 - val_loss: 665.5424 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.9793 - acc: 0.1124 - val_loss: 660.4201 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.9701 - acc: 0.1124 - val_loss: 665.5351 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.9817 - acc: 0.1124 - val_loss: 660.3931 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.9791 - acc: 0.1124 - val_loss: 665.5692 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.9894 - acc: 0.1124 - val_loss: 660.4074 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.9808 - acc: 0.1124 - val_loss: 665.5624 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.9901 - acc: 0.1124 - val_loss: 660.4278 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.9839 - acc: 0.1124 - val_loss: 665.5397 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 662.9941 - acc: 0.1124 - val_loss: 660.4244 - val_acc: 0.1135\n",
      "Test loss: 660.4243828125\n",
      "Test accuracy: 0.1135\n",
      "{'l1': 2.8357100369464785}\n",
      "{'tid': 0, 'misc': {'tid': 0, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'vals': {'l1': [2.8357100369464785]}, 'workdir': None, 'idxs': {'l1': [0]}}, 'state': 2, 'refresh_time': datetime.datetime(2018, 9, 3, 7, 26, 45, 535000), 'spec': None, 'owner': None, 'result': {'status': 'ok', 'loss': -0.1135}, 'exp_key': None, 'version': 0, 'book_time': datetime.datetime(2018, 9, 3, 7, 26, 20, 34000)}\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    model_3 = Sequential()\n",
    "    model_3.add(Dense(512, activation='relu', input_shape=(784,), kernel_regularizer=regularizers.l1(params['l1'])))\n",
    "    model_3.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l1(params['l1'])))\n",
    "    model_3.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_3.summary()\n",
    "    \n",
    "    print('training with L2 regularization parameter', params['l1'])\n",
    "    \n",
    "    model_3.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history_3 = model_3.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score_3 = model_3.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    print('Test loss:', score_3[0])\n",
    "    print('Test accuracy:', score_3[1])\n",
    "\n",
    "    return {'loss': - score_3[1], 'status': STATUS_OK} \n",
    "\n",
    "space = {\n",
    "    'l1': hp.uniform('l1', 0.0001, 5)\n",
    "}\n",
    "\n",
    "trials_2 = Trials()\n",
    "best_2 = fmin(objective, space, algo=tpe.suggest, trials=trials_2, max_evals = 30)\n",
    "print (best_2)\n",
    "print (trials_2.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure(num=None, figsize=(10, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "t = trials_2.trials\n",
    "\n",
    "y = []\n",
    "x = []\n",
    "for tr in t: \n",
    "    y.append((tr['result']['loss']))\n",
    "    x.append(tr['misc']['vals']['l1'])\n",
    "    \n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_109 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 14.3069 - acc: 0.5162 - val_loss: 1.6698 - val_acc: 0.6676\n",
      " — val_f1: 0.437753 — val_precision: 0.928363 — val_recall 0.286400\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.5503 - acc: 0.6724 - val_loss: 1.4394 - val_acc: 0.7080\n",
      " — val_f1: 0.571666 — val_precision: 0.928298 — val_recall 0.413000\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.4003 - acc: 0.7156 - val_loss: 1.3310 - val_acc: 0.7586\n",
      " — val_f1: 0.632103 — val_precision: 0.917253 — val_recall 0.482200\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.3086 - acc: 0.7466 - val_loss: 1.2788 - val_acc: 0.7375\n",
      " — val_f1: 0.659060 — val_precision: 0.875290 — val_recall 0.528500\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.2413 - acc: 0.7627 - val_loss: 1.1872 - val_acc: 0.7827\n",
      " — val_f1: 0.711474 — val_precision: 0.910622 — val_recall 0.583800\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.1951 - acc: 0.7693 - val_loss: 1.1354 - val_acc: 0.7961\n",
      " — val_f1: 0.741051 — val_precision: 0.905195 — val_recall 0.627300\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.1623 - acc: 0.7724 - val_loss: 1.1081 - val_acc: 0.7915\n",
      " — val_f1: 0.739516 — val_precision: 0.894311 — val_recall 0.630400\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.1369 - acc: 0.7758 - val_loss: 1.1568 - val_acc: 0.7662\n",
      " — val_f1: 0.734539 — val_precision: 0.885207 — val_recall 0.627700\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.1168 - acc: 0.7788 - val_loss: 1.0656 - val_acc: 0.8037\n",
      " — val_f1: 0.762025 — val_precision: 0.898763 — val_recall 0.661400\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.0987 - acc: 0.7803 - val_loss: 1.1103 - val_acc: 0.7863\n",
      " — val_f1: 0.740522 — val_precision: 0.877191 — val_recall 0.640700\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.0852 - acc: 0.7804 - val_loss: 1.0539 - val_acc: 0.7940\n",
      " — val_f1: 0.760403 — val_precision: 0.874740 — val_recall 0.672500\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.0730 - acc: 0.7840 - val_loss: 1.1013 - val_acc: 0.7570\n",
      " — val_f1: 0.735707 — val_precision: 0.844410 — val_recall 0.651800\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.0616 - acc: 0.7832 - val_loss: 1.0420 - val_acc: 0.7911\n",
      " — val_f1: 0.768104 — val_precision: 0.879923 — val_recall 0.681500\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.0509 - acc: 0.7859 - val_loss: 1.0185 - val_acc: 0.7886\n",
      " — val_f1: 0.766924 — val_precision: 0.870460 — val_recall 0.685400\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0439 - acc: 0.7862 - val_loss: 0.9732 - val_acc: 0.8154\n",
      " — val_f1: 0.791092 — val_precision: 0.895162 — val_recall 0.708700\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.0332 - acc: 0.7867 - val_loss: 1.0143 - val_acc: 0.7888\n",
      " — val_f1: 0.770727 — val_precision: 0.867309 — val_recall 0.693500\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.0285 - acc: 0.7871 - val_loss: 1.1029 - val_acc: 0.7384\n",
      " — val_f1: 0.719712 — val_precision: 0.822931 — val_recall 0.639500\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.0222 - acc: 0.7871 - val_loss: 1.1734 - val_acc: 0.7156\n",
      " — val_f1: 0.704854 — val_precision: 0.794952 — val_recall 0.633100\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.0160 - acc: 0.7845 - val_loss: 1.0154 - val_acc: 0.7963\n",
      " — val_f1: 0.775754 — val_precision: 0.878861 — val_recall 0.694300\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.0087 - acc: 0.7896 - val_loss: 1.0061 - val_acc: 0.7973\n",
      " — val_f1: 0.774478 — val_precision: 0.876548 — val_recall 0.693700\n",
      "Test loss: 1.0061459907531738\n",
      "Test accuracy: 0.7973\n"
     ]
    }
   ],
   "source": [
    "l1_min = trials_2.best_trial['misc']['vals']['l1']\n",
    "\n",
    "model_3 = Sequential()\n",
    "model_3.add(Dense(512, activation='relu', input_shape=(784,), kernel_regularizer=regularizers.l2(l1_min)))\n",
    "# model_2.add(Dropout(0.2))\n",
    "model_3.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(l1_min)))\n",
    "# model_2.add(Dropout(0.2))\n",
    "model_3.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_3.summary()\n",
    "\n",
    "model_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_3 = model_3.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test), callbacks=[metrics])\n",
    "score_3 = model_3.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score_3[0])\n",
    "print('Test accuracy:', score_3[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 and L2 regularizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.9380 - acc: 0.8520 - val_loss: 1.0698 - val_acc: 0.9056\n",
      " — val_f1: 0.903111 — val_precision: 0.943072 — val_recall 0.866400\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.9788 - acc: 0.9072 - val_loss: 0.8836 - val_acc: 0.9186\n",
      " — val_f1: 0.918627 — val_precision: 0.944538 — val_recall 0.894100\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.8622 - acc: 0.9188 - val_loss: 0.8246 - val_acc: 0.9174\n",
      " — val_f1: 0.919826 — val_precision: 0.939239 — val_recall 0.901200\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.8201 - acc: 0.9245 - val_loss: 0.7865 - val_acc: 0.9296\n",
      " — val_f1: 0.929486 — val_precision: 0.948195 — val_recall 0.911500\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.7956 - acc: 0.9275 - val_loss: 0.7780 - val_acc: 0.9282\n",
      " — val_f1: 0.930323 — val_precision: 0.948747 — val_recall 0.912600\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.7758 - acc: 0.9301 - val_loss: 0.7576 - val_acc: 0.9318\n",
      " — val_f1: 0.933394 — val_precision: 0.950923 — val_recall 0.916500\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.7617 - acc: 0.9320 - val_loss: 0.7385 - val_acc: 0.9373\n",
      " — val_f1: 0.937913 — val_precision: 0.954922 — val_recall 0.921500\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.7470 - acc: 0.9336 - val_loss: 0.7390 - val_acc: 0.9359\n",
      " — val_f1: 0.937836 — val_precision: 0.952838 — val_recall 0.923300\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.7373 - acc: 0.9357 - val_loss: 0.7158 - val_acc: 0.9402\n",
      " — val_f1: 0.940722 — val_precision: 0.956774 — val_recall 0.925200\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.7265 - acc: 0.9371 - val_loss: 0.7154 - val_acc: 0.9375\n",
      " — val_f1: 0.939190 — val_precision: 0.952866 — val_recall 0.925900\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.7189 - acc: 0.9381 - val_loss: 0.7032 - val_acc: 0.9420\n",
      " — val_f1: 0.941505 — val_precision: 0.956365 — val_recall 0.927100\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.7101 - acc: 0.9398 - val_loss: 0.7125 - val_acc: 0.9368\n",
      " — val_f1: 0.938568 — val_precision: 0.952435 — val_recall 0.925100\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.7042 - acc: 0.9410 - val_loss: 0.6893 - val_acc: 0.9430\n",
      " — val_f1: 0.942565 — val_precision: 0.954947 — val_recall 0.930500\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.6988 - acc: 0.9411 - val_loss: 0.6872 - val_acc: 0.9450\n",
      " — val_f1: 0.946414 — val_precision: 0.958846 — val_recall 0.934300\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.6939 - acc: 0.9421 - val_loss: 0.6899 - val_acc: 0.9383\n",
      " — val_f1: 0.938666 — val_precision: 0.949371 — val_recall 0.928200\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.6893 - acc: 0.9434 - val_loss: 0.6753 - val_acc: 0.9448\n",
      " — val_f1: 0.943795 — val_precision: 0.955053 — val_recall 0.932800\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.6856 - acc: 0.9430 - val_loss: 0.6716 - val_acc: 0.9470\n",
      " — val_f1: 0.947576 — val_precision: 0.959127 — val_recall 0.936300\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.6808 - acc: 0.9442 - val_loss: 0.6775 - val_acc: 0.9425\n",
      " — val_f1: 0.942386 — val_precision: 0.954368 — val_recall 0.930700\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.6800 - acc: 0.9435 - val_loss: 0.6510 - val_acc: 0.9521\n",
      " — val_f1: 0.952063 — val_precision: 0.961927 — val_recall 0.942400\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.6758 - acc: 0.9447 - val_loss: 0.6564 - val_acc: 0.9502\n",
      " — val_f1: 0.950579 — val_precision: 0.961818 — val_recall 0.939600\n",
      "Test loss: 0.6564340365409851\n",
      "Test accuracy: 0.9502\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Dense(512, activation='relu', input_shape=(784,), kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "model_4.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "model_4.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "model_4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_4 = model_4.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test), callbacks=[metrics])\n",
    "score_4 = model_4.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score_4[0])\n",
    "print('Test accuracy:', score_4[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.19662018084800856 2.46899936932645\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 332.9074 - acc: 0.1321 - val_loss: 67.9444 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 67.9452 - acc: 0.1122 - val_loss: 67.9447 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 67.9450 - acc: 0.1115 - val_loss: 67.9445 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 67.9449 - acc: 0.1124 - val_loss: 67.9454 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 67.9448 - acc: 0.1124 - val_loss: 67.9451 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9448 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9449 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9441 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9439 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9441 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9442 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9445 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9445 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9445 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9446 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9444 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9441 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9445 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9445 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 67.9447 - acc: 0.1124 - val_loss: 67.9444 - val_acc: 0.1135\n",
      "Test loss: 67.9444455078125\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.5981425577840882 0.9455186849086826\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 759.7690 - acc: 0.1267 - val_loss: 201.3158 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 200.9095 - acc: 0.1121 - val_loss: 200.8088 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 200.9074 - acc: 0.1123 - val_loss: 200.9328 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 200.9073 - acc: 0.1124 - val_loss: 200.8997 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 200.9073 - acc: 0.1124 - val_loss: 200.9080 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 200.9073 - acc: 0.1124 - val_loss: 200.9065 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 200.9072 - acc: 0.1124 - val_loss: 200.9071 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 200.9072 - acc: 0.1124 - val_loss: 200.9071 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 200.9072 - acc: 0.1124 - val_loss: 200.9067 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 200.9072 - acc: 0.1124 - val_loss: 200.9073 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 200.9072 - acc: 0.1124 - val_loss: 200.9071 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 200.9072 - acc: 0.1124 - val_loss: 200.9067 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 200.9072 - acc: 0.1124 - val_loss: 200.9070 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 200.9072 - acc: 0.1124 - val_loss: 200.9069 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 200.9072 - acc: 0.1124 - val_loss: 200.9070 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 200.9072 - acc: 0.1124 - val_loss: 200.9061 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 200.9072 - acc: 0.1124 - val_loss: 200.9082 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 200.9072 - acc: 0.1124 - val_loss: 200.9065 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 200.9072 - acc: 0.1124 - val_loss: 200.9076 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 200.9072 - acc: 0.1124 - val_loss: 200.9071 - val_acc: 0.1135\n",
      "Test loss: 200.90712829589845\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 2.187455493032807 1.9407735748149249\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 2707.8651 - acc: 0.1296 - val_loss: 729.5963 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 728.3813 - acc: 0.1114 - val_loss: 727.8236 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 728.3666 - acc: 0.1124 - val_loss: 728.6136 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 728.3652 - acc: 0.1124 - val_loss: 728.2531 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 728.3641 - acc: 0.1124 - val_loss: 728.4149 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 728.3643 - acc: 0.1124 - val_loss: 728.3400 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 728.3641 - acc: 0.1124 - val_loss: 728.3755 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 728.3642 - acc: 0.1124 - val_loss: 728.3584 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 728.3642 - acc: 0.1124 - val_loss: 728.3670 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 728.3642 - acc: 0.1124 - val_loss: 728.3629 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 728.3642 - acc: 0.1124 - val_loss: 728.3623 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 728.3642 - acc: 0.1124 - val_loss: 728.3646 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 728.3641 - acc: 0.1124 - val_loss: 728.3639 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 728.3641 - acc: 0.1124 - val_loss: 728.3645 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 728.3641 - acc: 0.1124 - val_loss: 728.3638 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 728.3641 - acc: 0.1124 - val_loss: 728.3644 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 728.3641 - acc: 0.1124 - val_loss: 728.3633 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 728.3641 - acc: 0.1124 - val_loss: 728.3642 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 728.3641 - acc: 0.1124 - val_loss: 728.3640 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 728.3641 - acc: 0.1124 - val_loss: 728.3632 - val_acc: 0.1135\n",
      "Test loss: 728.3632263671875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 3.9896812649823943 4.157213921980944\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 4969.6077 - acc: 0.1244 - val_loss: 1329.7759 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6926 - acc: 0.1117 - val_loss: 1325.4596 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6678 - acc: 0.1120 - val_loss: 1327.1478 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6667 - acc: 0.1122 - val_loss: 1326.4749 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1326.6654 - acc: 0.1124 - val_loss: 1326.7402 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6656 - acc: 0.1124 - val_loss: 1326.6356 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6654 - acc: 0.1124 - val_loss: 1326.6768 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6655 - acc: 0.1124 - val_loss: 1326.6604 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6654 - acc: 0.1124 - val_loss: 1326.6666 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6654 - acc: 0.1124 - val_loss: 1326.6655 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6653 - acc: 0.1124 - val_loss: 1326.6648 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6653 - acc: 0.1124 - val_loss: 1326.6651 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6653 - acc: 0.1124 - val_loss: 1326.6656 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6653 - acc: 0.1124 - val_loss: 1326.6640 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6653 - acc: 0.1124 - val_loss: 1326.6661 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1326.6653 - acc: 0.1124 - val_loss: 1326.6641 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1326.6652 - acc: 0.1124 - val_loss: 1326.6660 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6653 - acc: 0.1124 - val_loss: 1326.6641 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6653 - acc: 0.1124 - val_loss: 1326.6671 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1326.6653 - acc: 0.1124 - val_loss: 1326.6649 - val_acc: 0.1135\n",
      "Test loss: 1326.664941015625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.5315382920861155 1.314855565689687\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 693.9693 - acc: 0.1273 - val_loss: 178.9598 - val_acc: 0.1028\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8719 - acc: 0.1117 - val_loss: 178.8624 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8713 - acc: 0.1119 - val_loss: 178.8721 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 178.8713 - acc: 0.1124 - val_loss: 178.8709 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 178.8711 - acc: 0.1124 - val_loss: 178.8707 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8711 - acc: 0.1124 - val_loss: 178.8710 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 178.8711 - acc: 0.1124 - val_loss: 178.8712 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8711 - acc: 0.1124 - val_loss: 178.8704 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 178.8711 - acc: 0.1124 - val_loss: 178.8714 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8711 - acc: 0.1124 - val_loss: 178.8702 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8710 - acc: 0.1124 - val_loss: 178.8720 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8711 - acc: 0.1124 - val_loss: 178.8701 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8711 - acc: 0.1124 - val_loss: 178.8708 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8711 - acc: 0.1124 - val_loss: 178.8707 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8711 - acc: 0.1124 - val_loss: 178.8702 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8711 - acc: 0.1124 - val_loss: 178.8707 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8711 - acc: 0.1124 - val_loss: 178.8709 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8710 - acc: 0.1124 - val_loss: 178.8708 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8710 - acc: 0.1124 - val_loss: 178.8703 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 178.8710 - acc: 0.1124 - val_loss: 178.8715 - val_acc: 0.1135\n",
      "Test loss: 178.87145419921876\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 2.384811677563921 0.4722559805539051\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2885.3025 - acc: 0.1277 - val_loss: 795.7012 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 793.5786 - acc: 0.1118 - val_loss: 791.7907 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 793.5667 - acc: 0.1120 - val_loss: 795.0622 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 793.5674 - acc: 0.1124 - val_loss: 792.3084 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 793.5603 - acc: 0.1124 - val_loss: 794.6131 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 793.5617 - acc: 0.1124 - val_loss: 792.6753 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 793.5573 - acc: 0.1124 - val_loss: 794.2994 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 793.5587 - acc: 0.1124 - val_loss: 792.9346 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 793.5559 - acc: 0.1124 - val_loss: 794.0787 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 793.5572 - acc: 0.1124 - val_loss: 793.1169 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 793.5553 - acc: 0.1124 - val_loss: 793.9226 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 793.5563 - acc: 0.1124 - val_loss: 793.2474 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 793.5551 - acc: 0.1124 - val_loss: 793.8135 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 793.5558 - acc: 0.1124 - val_loss: 793.3392 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 793.5551 - acc: 0.1124 - val_loss: 793.7357 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 793.5555 - acc: 0.1124 - val_loss: 793.4039 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 793.5550 - acc: 0.1124 - val_loss: 793.6817 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 793.5554 - acc: 0.1124 - val_loss: 793.4480 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 793.5550 - acc: 0.1124 - val_loss: 793.6437 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 793.5553 - acc: 0.1124 - val_loss: 793.4806 - val_acc: 0.1135\n",
      "Test loss: 793.4806265625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.6033073216746152 3.6076293746603993\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 868.6483 - acc: 0.1353 - val_loss: 203.0676 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 203.0630 - acc: 0.1115 - val_loss: 203.0632 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 203.0629 - acc: 0.1124 - val_loss: 203.0624 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 203.0628 - acc: 0.1124 - val_loss: 203.0626 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 203.0628 - acc: 0.1124 - val_loss: 203.0624 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 203.0627 - acc: 0.1124 - val_loss: 203.0629 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 203.0627 - acc: 0.1124 - val_loss: 203.0629 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 203.0627 - acc: 0.1124 - val_loss: 203.0627 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 203.0627 - acc: 0.1124 - val_loss: 203.0618 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 203.0627 - acc: 0.1124 - val_loss: 203.0621 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 203.0627 - acc: 0.1124 - val_loss: 203.0627 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 203.0626 - acc: 0.1124 - val_loss: 203.0626 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 203.0626 - acc: 0.1124 - val_loss: 203.0625 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 203.0626 - acc: 0.1124 - val_loss: 203.0627 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 203.0627 - acc: 0.1124 - val_loss: 203.0628 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 203.0627 - acc: 0.1124 - val_loss: 203.0632 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 203.0627 - acc: 0.1124 - val_loss: 203.0622 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 203.0626 - acc: 0.1124 - val_loss: 203.0622 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 203.0627 - acc: 0.1124 - val_loss: 203.0630 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 203.0627 - acc: 0.1124 - val_loss: 203.0621 - val_acc: 0.1135\n",
      "Test loss: 203.06207290039063\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 3.176820705993929 3.684779234368637\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 3966.5537 - acc: 0.1391 - val_loss: 1059.2937 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1056.9195 - acc: 0.1112 - val_loss: 1056.0657 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1056.9019 - acc: 0.1124 - val_loss: 1057.2001 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1056.9015 - acc: 0.1124 - val_loss: 1056.7959 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1056.9007 - acc: 0.1124 - val_loss: 1056.9364 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1056.9009 - acc: 0.1124 - val_loss: 1056.8870 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1056.9007 - acc: 0.1124 - val_loss: 1056.9029 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1056.9007 - acc: 0.1124 - val_loss: 1056.8983 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1056.9007 - acc: 0.1124 - val_loss: 1056.9005 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1056.9007 - acc: 0.1124 - val_loss: 1056.9001 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1056.9007 - acc: 0.1124 - val_loss: 1056.9014 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1056.9006 - acc: 0.1124 - val_loss: 1056.9004 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1056.9007 - acc: 0.1124 - val_loss: 1056.9006 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1056.9007 - acc: 0.1124 - val_loss: 1056.9008 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1056.9006 - acc: 0.1124 - val_loss: 1056.9000 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1056.9006 - acc: 0.1124 - val_loss: 1056.9005 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1056.9006 - acc: 0.1124 - val_loss: 1056.9006 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1056.9006 - acc: 0.1124 - val_loss: 1056.8994 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1056.9006 - acc: 0.1124 - val_loss: 1056.9007 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1056.9006 - acc: 0.1124 - val_loss: 1056.8998 - val_acc: 0.1135\n",
      "Test loss: 1056.8998296875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.2667870015538244 4.124395283064556\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 479.9256 - acc: 0.1339 - val_loss: 91.4992 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 91.4995 - acc: 0.1116 - val_loss: 91.4989 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 91.4992 - acc: 0.1121 - val_loss: 91.4990 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 91.4991 - acc: 0.1124 - val_loss: 91.4984 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 91.4991 - acc: 0.1124 - val_loss: 91.4991 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 91.4990 - acc: 0.1124 - val_loss: 91.4987 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 91.4990 - acc: 0.1124 - val_loss: 91.4992 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 91.4990 - acc: 0.1124 - val_loss: 91.4989 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 91.4990 - acc: 0.1124 - val_loss: 91.4987 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 91.4990 - acc: 0.1124 - val_loss: 91.4989 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 91.4990 - acc: 0.1124 - val_loss: 91.4990 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 91.4990 - acc: 0.1124 - val_loss: 91.4988 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 91.4990 - acc: 0.1124 - val_loss: 91.4989 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 91.4990 - acc: 0.1124 - val_loss: 91.4984 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 91.4990 - acc: 0.1124 - val_loss: 91.4988 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 91.4990 - acc: 0.1124 - val_loss: 91.4985 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 91.4990 - acc: 0.1124 - val_loss: 91.4987 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 91.4989 - acc: 0.1124 - val_loss: 91.4988 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 91.4989 - acc: 0.1124 - val_loss: 91.4988 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 91.4989 - acc: 0.1124 - val_loss: 91.4984 - val_acc: 0.1135\n",
      "Test loss: 91.49843356933594\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.8392024279905012 3.578276556781874\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1153.0245 - acc: 0.1327 - val_loss: 281.3620 - val_acc: 0.1028\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 281.3221 - acc: 0.1122 - val_loss: 281.3214 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 281.3219 - acc: 0.1122 - val_loss: 281.3211 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 281.3218 - acc: 0.1123 - val_loss: 281.3218 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 281.3218 - acc: 0.1124 - val_loss: 281.3215 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 281.3217 - acc: 0.1124 - val_loss: 281.3217 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 281.3217 - acc: 0.1124 - val_loss: 281.3226 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 281.3217 - acc: 0.1124 - val_loss: 281.3212 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 281.3217 - acc: 0.1124 - val_loss: 281.3214 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 281.3217 - acc: 0.1124 - val_loss: 281.3212 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 281.3217 - acc: 0.1124 - val_loss: 281.3214 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 281.3217 - acc: 0.1124 - val_loss: 281.3217 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 281.3217 - acc: 0.1124 - val_loss: 281.3213 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 281.3217 - acc: 0.1124 - val_loss: 281.3207 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 281.3217 - acc: 0.1124 - val_loss: 281.3211 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 281.3216 - acc: 0.1124 - val_loss: 281.3213 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 281.3216 - acc: 0.1124 - val_loss: 281.3213 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 281.3216 - acc: 0.1124 - val_loss: 281.3213 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 281.3216 - acc: 0.1124 - val_loss: 281.3220 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 281.3216 - acc: 0.1124 - val_loss: 281.3213 - val_acc: 0.1135\n",
      "Test loss: 281.3213375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 2.177505654409245 1.4861872186500493\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 2682.1375 - acc: 0.1270 - val_loss: 726.0311 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 725.0095 - acc: 0.1120 - val_loss: 724.4485 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 724.9939 - acc: 0.1124 - val_loss: 725.2901 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 724.9909 - acc: 0.1123 - val_loss: 724.8268 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 724.9891 - acc: 0.1124 - val_loss: 725.0763 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 724.9891 - acc: 0.1124 - val_loss: 724.9407 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 724.9887 - acc: 0.1124 - val_loss: 725.0129 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 724.9888 - acc: 0.1124 - val_loss: 724.9759 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 724.9887 - acc: 0.1124 - val_loss: 724.9957 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 724.9887 - acc: 0.1124 - val_loss: 724.9857 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 724.9887 - acc: 0.1124 - val_loss: 724.9901 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 724.9887 - acc: 0.1124 - val_loss: 724.9873 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 724.9886 - acc: 0.1124 - val_loss: 724.9898 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 724.9886 - acc: 0.1124 - val_loss: 724.9875 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 724.9887 - acc: 0.1124 - val_loss: 724.9889 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 724.9887 - acc: 0.1124 - val_loss: 724.9878 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 724.9888 - acc: 0.1124 - val_loss: 724.9886 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 724.9888 - acc: 0.1124 - val_loss: 724.9884 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 724.9888 - acc: 0.1124 - val_loss: 724.9873 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 724.9888 - acc: 0.1124 - val_loss: 724.9892 - val_acc: 0.1135\n",
      "Test loss: 724.989212890625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 3.349665657578151 4.4338825621761675\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 24us/step - loss: 4206.9797 - acc: 0.1274 - val_loss: 1117.0761 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1114.3902 - acc: 0.1115 - val_loss: 1113.5551 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1114.3742 - acc: 0.1120 - val_loss: 1114.6274 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1114.3744 - acc: 0.1124 - val_loss: 1114.2963 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1114.3738 - acc: 0.1124 - val_loss: 1114.3942 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1114.3739 - acc: 0.1124 - val_loss: 1114.3684 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1114.3739 - acc: 0.1124 - val_loss: 1114.3759 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1114.3739 - acc: 0.1124 - val_loss: 1114.3740 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1114.3740 - acc: 0.1124 - val_loss: 1114.3707 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1114.3741 - acc: 0.1124 - val_loss: 1114.3753 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1114.3740 - acc: 0.1124 - val_loss: 1114.3720 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1114.3740 - acc: 0.1124 - val_loss: 1114.3739 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1114.3740 - acc: 0.1124 - val_loss: 1114.3721 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1114.3740 - acc: 0.1124 - val_loss: 1114.3746 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1114.3740 - acc: 0.1124 - val_loss: 1114.3730 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1114.3740 - acc: 0.1124 - val_loss: 1114.3746 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1114.3740 - acc: 0.1124 - val_loss: 1114.3744 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1114.3740 - acc: 0.1124 - val_loss: 1114.3737 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1114.3740 - acc: 0.1124 - val_loss: 1114.3732 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1114.3740 - acc: 0.1124 - val_loss: 1114.3744 - val_acc: 0.1135\n",
      "Test loss: 1114.37437421875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 2.9263675944217535 2.4692866411458607\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 3623.0142 - acc: 0.1304 - val_loss: 975.7852 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 973.6313 - acc: 0.1120 - val_loss: 972.6069 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 973.6102 - acc: 0.1123 - val_loss: 974.0860 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 973.6084 - acc: 0.1122 - val_loss: 973.3821 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 973.6066 - acc: 0.1124 - val_loss: 973.7128 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 973.6068 - acc: 0.1124 - val_loss: 973.5562 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 973.6065 - acc: 0.1124 - val_loss: 973.6297 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 973.6066 - acc: 0.1124 - val_loss: 973.5949 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 973.6066 - acc: 0.1124 - val_loss: 973.6117 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 973.6066 - acc: 0.1124 - val_loss: 973.6030 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 973.6065 - acc: 0.1124 - val_loss: 973.6084 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 973.6065 - acc: 0.1124 - val_loss: 973.6056 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 973.6066 - acc: 0.1124 - val_loss: 973.6059 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 973.6066 - acc: 0.1124 - val_loss: 973.6057 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 973.6066 - acc: 0.1124 - val_loss: 973.6069 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 973.6066 - acc: 0.1124 - val_loss: 973.6068 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 973.6065 - acc: 0.1124 - val_loss: 973.6044 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 973.6066 - acc: 0.1124 - val_loss: 973.6065 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 973.6066 - acc: 0.1124 - val_loss: 973.6068 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 973.6066 - acc: 0.1124 - val_loss: 973.6065 - val_acc: 0.1135\n",
      "Test loss: 973.6065072265625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 1.5359529948178223 0.10284995453290459\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1854.4392 - acc: 0.1338 - val_loss: 513.2840 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8243 - acc: 0.1118 - val_loss: 510.4413 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8194 - acc: 0.1122 - val_loss: 513.1265 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 511.8232 - acc: 0.1124 - val_loss: 510.5906 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 511.8186 - acc: 0.1124 - val_loss: 512.9790 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8219 - acc: 0.1124 - val_loss: 510.7249 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8179 - acc: 0.1124 - val_loss: 512.8517 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 511.8208 - acc: 0.1124 - val_loss: 510.8447 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8173 - acc: 0.1124 - val_loss: 512.7371 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8200 - acc: 0.1124 - val_loss: 510.9532 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8169 - acc: 0.1124 - val_loss: 512.6310 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8193 - acc: 0.1124 - val_loss: 511.0521 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8166 - acc: 0.1124 - val_loss: 512.5386 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8188 - acc: 0.1124 - val_loss: 511.1379 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8164 - acc: 0.1124 - val_loss: 512.4585 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8183 - acc: 0.1124 - val_loss: 511.2158 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8163 - acc: 0.1124 - val_loss: 512.3850 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8180 - acc: 0.1124 - val_loss: 511.2832 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8162 - acc: 0.1124 - val_loss: 512.3183 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 511.8177 - acc: 0.1124 - val_loss: 511.3459 - val_acc: 0.1135\n",
      "Test loss: 511.3458926757813\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 1.8565415691400038 2.880145101533955\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 2349.9207 - acc: 0.1283 - val_loss: 619.9641 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 618.7400 - acc: 0.1117 - val_loss: 618.4258 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 618.7333 - acc: 0.1124 - val_loss: 618.8108 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 618.7333 - acc: 0.1124 - val_loss: 618.7131 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 618.7332 - acc: 0.1124 - val_loss: 618.7382 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 618.7332 - acc: 0.1124 - val_loss: 618.7307 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 618.7332 - acc: 0.1124 - val_loss: 618.7344 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 618.7332 - acc: 0.1124 - val_loss: 618.7324 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 618.7332 - acc: 0.1124 - val_loss: 618.7331 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 618.7332 - acc: 0.1124 - val_loss: 618.7329 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 618.7332 - acc: 0.1124 - val_loss: 618.7326 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 618.7332 - acc: 0.1124 - val_loss: 618.7334 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 618.7332 - acc: 0.1124 - val_loss: 618.7327 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 618.7332 - acc: 0.1124 - val_loss: 618.7334 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 618.7332 - acc: 0.1124 - val_loss: 618.7329 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 618.7331 - acc: 0.1124 - val_loss: 618.7331 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 618.7331 - acc: 0.1124 - val_loss: 618.7330 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 618.7331 - acc: 0.1124 - val_loss: 618.7324 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 618.7331 - acc: 0.1124 - val_loss: 618.7338 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 618.7331 - acc: 0.1124 - val_loss: 618.7325 - val_acc: 0.1135\n",
      "Test loss: 618.732476171875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 4.953359611639218 3.524406035781454\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 6107.7340 - acc: 0.1312 - val_loss: 1649.3344 - val_acc: 0.1010\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.3284 - acc: 0.1108 - val_loss: 1644.7212 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2920 - acc: 0.1124 - val_loss: 1647.1285 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2866 - acc: 0.1125 - val_loss: 1645.8360 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2824 - acc: 0.1124 - val_loss: 1646.5192 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2825 - acc: 0.1124 - val_loss: 1646.1558 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2818 - acc: 0.1124 - val_loss: 1646.3480 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2821 - acc: 0.1124 - val_loss: 1646.2462 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2819 - acc: 0.1124 - val_loss: 1646.3004 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2820 - acc: 0.1124 - val_loss: 1646.2720 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2820 - acc: 0.1124 - val_loss: 1646.2851 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2821 - acc: 0.1124 - val_loss: 1646.2802 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2820 - acc: 0.1124 - val_loss: 1646.2828 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2820 - acc: 0.1124 - val_loss: 1646.2816 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2820 - acc: 0.1124 - val_loss: 1646.2821 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2820 - acc: 0.1124 - val_loss: 1646.2822 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2820 - acc: 0.1124 - val_loss: 1646.2819 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2820 - acc: 0.1124 - val_loss: 1646.2818 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2820 - acc: 0.1124 - val_loss: 1646.2820 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1646.2820 - acc: 0.1124 - val_loss: 1646.2814 - val_acc: 0.1135\n",
      "Test loss: 1646.281411328125\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 3.7982636350163306 0.9453609817408769\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 4606.0026 - acc: 0.1311 - val_loss: 1266.4455 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.6206 - acc: 0.1117 - val_loss: 1259.5466 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5986 - acc: 0.1123 - val_loss: 1265.0535 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5997 - acc: 0.1122 - val_loss: 1260.6234 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5879 - acc: 0.1124 - val_loss: 1264.1679 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5898 - acc: 0.1124 - val_loss: 1261.3199 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5834 - acc: 0.1124 - val_loss: 1263.6000 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5855 - acc: 0.1124 - val_loss: 1261.7699 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5819 - acc: 0.1124 - val_loss: 1263.2342 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5835 - acc: 0.1124 - val_loss: 1262.0608 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5814 - acc: 0.1124 - val_loss: 1263.0008 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5825 - acc: 0.1124 - val_loss: 1262.2461 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5812 - acc: 0.1124 - val_loss: 1262.8509 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5820 - acc: 0.1124 - val_loss: 1262.3626 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5813 - acc: 0.1124 - val_loss: 1262.7541 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5818 - acc: 0.1124 - val_loss: 1262.4420 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5813 - acc: 0.1124 - val_loss: 1262.6919 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5817 - acc: 0.1124 - val_loss: 1262.4918 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5814 - acc: 0.1124 - val_loss: 1262.6521 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1262.5816 - acc: 0.1124 - val_loss: 1262.5248 - val_acc: 0.1135\n",
      "Test loss: 1262.524776953125\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 3.7605507299259666 3.244134375833746\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 4651.7004 - acc: 0.1267 - val_loss: 1252.7568 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.5209 - acc: 0.1118 - val_loss: 1249.4728 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4953 - acc: 0.1124 - val_loss: 1250.9720 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4926 - acc: 0.1124 - val_loss: 1250.2697 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4907 - acc: 0.1124 - val_loss: 1250.5927 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4909 - acc: 0.1124 - val_loss: 1250.4430 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4906 - acc: 0.1124 - val_loss: 1250.5135 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4908 - acc: 0.1124 - val_loss: 1250.4810 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4907 - acc: 0.1124 - val_loss: 1250.4954 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4908 - acc: 0.1124 - val_loss: 1250.4884 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4907 - acc: 0.1124 - val_loss: 1250.4915 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4907 - acc: 0.1124 - val_loss: 1250.4895 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4907 - acc: 0.1124 - val_loss: 1250.4916 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4907 - acc: 0.1124 - val_loss: 1250.4903 - val_acc: 0.1135\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4907 - acc: 0.1124 - val_loss: 1250.4911 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4907 - acc: 0.1124 - val_loss: 1250.4906 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4907 - acc: 0.1124 - val_loss: 1250.4912 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4907 - acc: 0.1124 - val_loss: 1250.4893 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4907 - acc: 0.1124 - val_loss: 1250.4909 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1250.4907 - acc: 0.1124 - val_loss: 1250.4900 - val_acc: 0.1135\n",
      "Test loss: 1250.4900255859375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 2.045399605307633 1.3542163658872952\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 2516.8520 - acc: 0.1282 - val_loss: 682.5210 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 681.1517 - acc: 0.1118 - val_loss: 680.3895 - val_acc: 0.1028\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 681.1361 - acc: 0.1113 - val_loss: 681.5514 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 681.1338 - acc: 0.1123 - val_loss: 680.9004 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 681.1316 - acc: 0.1124 - val_loss: 681.2610 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 681.1317 - acc: 0.1124 - val_loss: 681.0592 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 681.1313 - acc: 0.1124 - val_loss: 681.1723 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 681.1314 - acc: 0.1124 - val_loss: 681.1078 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 681.1313 - acc: 0.1124 - val_loss: 681.1446 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 681.1313 - acc: 0.1124 - val_loss: 681.1242 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 681.1313 - acc: 0.1124 - val_loss: 681.1356 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 681.1313 - acc: 0.1124 - val_loss: 681.1289 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 681.1313 - acc: 0.1124 - val_loss: 681.1332 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 681.1314 - acc: 0.1124 - val_loss: 681.1303 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 681.1314 - acc: 0.1124 - val_loss: 681.1324 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 681.1314 - acc: 0.1124 - val_loss: 681.1310 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 681.1313 - acc: 0.1124 - val_loss: 681.1313 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 681.1314 - acc: 0.1124 - val_loss: 681.1309 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 681.1314 - acc: 0.1124 - val_loss: 681.1314 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 681.1314 - acc: 0.1124 - val_loss: 681.1309 - val_acc: 0.1135\n",
      "Test loss: 681.1309418945312\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 4.09995508349755 1.3005496836040633\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 4985.5885 - acc: 0.1345 - val_loss: 1365.3616 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1362.7900 - acc: 0.1116 - val_loss: 1360.8414 - val_acc: 0.1010\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1362.7675 - acc: 0.1119 - val_loss: 1364.2237 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1362.7623 - acc: 0.1122 - val_loss: 1361.6548 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1362.7529 - acc: 0.1124 - val_loss: 1363.5835 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1362.7525 - acc: 0.1124 - val_loss: 1362.1232 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1362.7485 - acc: 0.1124 - val_loss: 1363.2214 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1362.7491 - acc: 0.1124 - val_loss: 1362.3904 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1362.7472 - acc: 0.1124 - val_loss: 1363.0172 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1362.7478 - acc: 0.1124 - val_loss: 1362.5432 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1362.7469 - acc: 0.1124 - val_loss: 1362.9021 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1362.7473 - acc: 0.1124 - val_loss: 1362.6300 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1362.7469 - acc: 0.1124 - val_loss: 1362.8355 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1362.7471 - acc: 0.1124 - val_loss: 1362.6801 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1362.7469 - acc: 0.1124 - val_loss: 1362.7978 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1362.7471 - acc: 0.1124 - val_loss: 1362.7082 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1362.7469 - acc: 0.1124 - val_loss: 1362.7769 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1362.7470 - acc: 0.1124 - val_loss: 1362.7241 - val_acc: 0.1135\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 1362.7469 - acc: 0.1124 - val_loss: 1362.7647 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1362.7469 - acc: 0.1124 - val_loss: 1362.7331 - val_acc: 0.1135\n",
      "Test loss: 1362.733150390625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 4.529268850893798 2.886585055440854\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 5561.7485 - acc: 0.1237 - val_loss: 1507.7188 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1505.5139 - acc: 0.1122 - val_loss: 1504.2539 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1505.4811 - acc: 0.1122 - val_loss: 1506.1769 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1505.4747 - acc: 0.1124 - val_loss: 1505.0738 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1505.4702 - acc: 0.1124 - val_loss: 1505.6960 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1505.4702 - acc: 0.1124 - val_loss: 1505.3405 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1505.4693 - acc: 0.1124 - val_loss: 1505.5425 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1505.4695 - acc: 0.1124 - val_loss: 1505.4275 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1505.4692 - acc: 0.1124 - val_loss: 1505.4917 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1505.4694 - acc: 0.1124 - val_loss: 1505.4555 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1505.4693 - acc: 0.1124 - val_loss: 1505.4774 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1505.4692 - acc: 0.1124 - val_loss: 1505.4648 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1505.4691 - acc: 0.1124 - val_loss: 1505.4721 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1505.4692 - acc: 0.1124 - val_loss: 1505.4661 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1505.4692 - acc: 0.1124 - val_loss: 1505.4700 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1505.4692 - acc: 0.1124 - val_loss: 1505.4679 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1505.4692 - acc: 0.1124 - val_loss: 1505.4700 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1505.4692 - acc: 0.1124 - val_loss: 1505.4691 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1505.4692 - acc: 0.1124 - val_loss: 1505.4694 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1505.4693 - acc: 0.1124 - val_loss: 1505.4690 - val_acc: 0.1135\n",
      "Test loss: 1505.4689755859374\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 1.344177550788886 2.1681430675139195\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 1706.2830 - acc: 0.1306 - val_loss: 449.3815 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 448.6307 - acc: 0.1115 - val_loss: 448.4486 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 448.6263 - acc: 0.1123 - val_loss: 448.6676 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 448.6263 - acc: 0.1117 - val_loss: 448.6161 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6283 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6277 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6262 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6264 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6254 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6245 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6268 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6257 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6264 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6262 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6258 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6259 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6257 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6264 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6253 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 448.6262 - acc: 0.1124 - val_loss: 448.6260 - val_acc: 0.1135\n",
      "Test loss: 448.62595859375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 4.906197273772635 1.8564407346110405\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 28us/step - loss: 5975.7383 - acc: 0.1357 - val_loss: 1633.1665 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1630.3875 - acc: 0.1115 - val_loss: 1628.3936 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1630.3561 - acc: 0.1122 - val_loss: 1631.7625 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1630.3485 - acc: 0.1124 - val_loss: 1629.3345 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1630.3386 - acc: 0.1124 - val_loss: 1631.0579 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1630.3379 - acc: 0.1124 - val_loss: 1629.8211 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1630.3344 - acc: 0.1124 - val_loss: 1630.7010 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1630.3348 - acc: 0.1124 - val_loss: 1630.0705 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1630.3335 - acc: 0.1124 - val_loss: 1630.5207 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1630.3339 - acc: 0.1124 - val_loss: 1630.1993 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1630.3333 - acc: 0.1124 - val_loss: 1630.4293 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1630.3336 - acc: 0.1124 - val_loss: 1630.2639 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1630.3333 - acc: 0.1124 - val_loss: 1630.3826 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1630.3335 - acc: 0.1124 - val_loss: 1630.2974 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1630.3333 - acc: 0.1124 - val_loss: 1630.3592 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1630.3334 - acc: 0.1124 - val_loss: 1630.3145 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1630.3333 - acc: 0.1124 - val_loss: 1630.3469 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1630.3333 - acc: 0.1124 - val_loss: 1630.3237 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1630.3333 - acc: 0.1124 - val_loss: 1630.3398 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1630.3332 - acc: 0.1124 - val_loss: 1630.3280 - val_acc: 0.1135\n",
      "Test loss: 1630.327965234375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_79 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 4.555762472615902 4.952027067746041\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 5678.9401 - acc: 0.1276 - val_loss: 1516.7441 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6339 - acc: 0.1117 - val_loss: 1513.8230 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6092 - acc: 0.1121 - val_loss: 1514.9078 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6074 - acc: 0.1124 - val_loss: 1514.4905 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6064 - acc: 0.1124 - val_loss: 1514.6502 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6065 - acc: 0.1124 - val_loss: 1514.5896 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6063 - acc: 0.1124 - val_loss: 1514.6124 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6063 - acc: 0.1124 - val_loss: 1514.6027 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6063 - acc: 0.1124 - val_loss: 1514.6083 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6062 - acc: 0.1124 - val_loss: 1514.6048 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6062 - acc: 0.1124 - val_loss: 1514.6069 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6062 - acc: 0.1124 - val_loss: 1514.6054 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6061 - acc: 0.1124 - val_loss: 1514.6065 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6062 - acc: 0.1124 - val_loss: 1514.6052 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6061 - acc: 0.1124 - val_loss: 1514.6064 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6062 - acc: 0.1124 - val_loss: 1514.6048 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6061 - acc: 0.1124 - val_loss: 1514.6068 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6061 - acc: 0.1124 - val_loss: 1514.6049 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6061 - acc: 0.1124 - val_loss: 1514.6054 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1514.6061 - acc: 0.1124 - val_loss: 1514.6069 - val_acc: 0.1135\n",
      "Test loss: 1514.606916796875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_82 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 1.2209227964137404 2.2346097056533663\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 1561.2774 - acc: 0.1317 - val_loss: 408.3212 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 407.7469 - acc: 0.1119 - val_loss: 407.6326 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 407.7439 - acc: 0.1124 - val_loss: 407.7659 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 407.7439 - acc: 0.1124 - val_loss: 407.7394 - val_acc: 0.1135\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 407.7438 - acc: 0.1124 - val_loss: 407.7447 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 407.7437 - acc: 0.1124 - val_loss: 407.7448 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 407.7437 - acc: 0.1124 - val_loss: 407.7441 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 407.7437 - acc: 0.1124 - val_loss: 407.7430 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 407.7437 - acc: 0.1124 - val_loss: 407.7439 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 407.7437 - acc: 0.1124 - val_loss: 407.7436 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 407.7436 - acc: 0.1124 - val_loss: 407.7438 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 407.7437 - acc: 0.1124 - val_loss: 407.7426 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 407.7437 - acc: 0.1124 - val_loss: 407.7436 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 407.7437 - acc: 0.1124 - val_loss: 407.7437 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 407.7437 - acc: 0.1124 - val_loss: 407.7436 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 407.7437 - acc: 0.1124 - val_loss: 407.7435 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 407.7436 - acc: 0.1124 - val_loss: 407.7435 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 407.7436 - acc: 0.1124 - val_loss: 407.7434 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 407.7436 - acc: 0.1124 - val_loss: 407.7437 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 407.7436 - acc: 0.1124 - val_loss: 407.7427 - val_acc: 0.1135\n",
      "Test loss: 407.742690625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.11439069696824654 1.8060305932222662\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 208.5015 - acc: 0.1391 - val_loss: 40.5536 - val_acc: 0.0958\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 40.5534 - acc: 0.1115 - val_loss: 40.5530 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 40.5532 - acc: 0.1123 - val_loss: 40.5530 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 40.5531 - acc: 0.1122 - val_loss: 40.5530 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 40.5530 - acc: 0.1124 - val_loss: 40.5524 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 40.5530 - acc: 0.1124 - val_loss: 40.5529 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 40.5530 - acc: 0.1124 - val_loss: 40.5528 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 40.5530 - acc: 0.1124 - val_loss: 40.5526 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 40.5529 - acc: 0.1124 - val_loss: 40.5524 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 40.5530 - acc: 0.1124 - val_loss: 40.5539 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 40.5529 - acc: 0.1124 - val_loss: 40.5527 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 40.5529 - acc: 0.1124 - val_loss: 40.5524 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 40.5529 - acc: 0.1124 - val_loss: 40.5520 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 40.5529 - acc: 0.1124 - val_loss: 40.5515 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 40.5530 - acc: 0.1124 - val_loss: 40.5527 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 40.5529 - acc: 0.1124 - val_loss: 40.5537 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 40.5529 - acc: 0.1124 - val_loss: 40.5527 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 40.5529 - acc: 0.1124 - val_loss: 40.5526 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 40.5529 - acc: 0.1124 - val_loss: 40.5528 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 40.5529 - acc: 0.1124 - val_loss: 40.5527 - val_acc: 0.1135\n",
      "Test loss: 40.552699908447266\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 2.813612912416505 4.803654501926219\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 3575.6228 - acc: 0.1333 - val_loss: 938.0311 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 936.5955 - acc: 0.1116 - val_loss: 936.2765 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 936.5876 - acc: 0.1116 - val_loss: 936.6553 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 936.5876 - acc: 0.1124 - val_loss: 936.5732 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 936.5875 - acc: 0.1124 - val_loss: 936.5904 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 936.5875 - acc: 0.1124 - val_loss: 936.5871 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 936.5876 - acc: 0.1124 - val_loss: 936.5872 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 936.5877 - acc: 0.1124 - val_loss: 936.5871 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 936.5877 - acc: 0.1124 - val_loss: 936.5875 - val_acc: 0.1135\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 18us/step - loss: 936.5877 - acc: 0.1124 - val_loss: 936.5869 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 936.5876 - acc: 0.1124 - val_loss: 936.5865 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 936.5877 - acc: 0.1124 - val_loss: 936.5883 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 936.5876 - acc: 0.1124 - val_loss: 936.5878 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 936.5876 - acc: 0.1124 - val_loss: 936.5875 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 936.5876 - acc: 0.1124 - val_loss: 936.5874 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 936.5876 - acc: 0.1124 - val_loss: 936.5873 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 936.5876 - acc: 0.1124 - val_loss: 936.5876 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 936.5876 - acc: 0.1124 - val_loss: 936.5868 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 936.5876 - acc: 0.1124 - val_loss: 936.5874 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 936.5876 - acc: 0.1124 - val_loss: 936.5875 - val_acc: 0.1135\n",
      "Test loss: 936.5874650390625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 1.1947267185828143 2.587979424635442\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 1544.0802 - acc: 0.1270 - val_loss: 399.5428 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 399.1138 - acc: 0.1117 - val_loss: 399.0493 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 399.1117 - acc: 0.1116 - val_loss: 399.1210 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 399.1118 - acc: 0.1124 - val_loss: 399.1108 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 399.1117 - acc: 0.1124 - val_loss: 399.1115 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 399.1117 - acc: 0.1124 - val_loss: 399.1118 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 399.1117 - acc: 0.1124 - val_loss: 399.1113 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 399.1117 - acc: 0.1124 - val_loss: 399.1116 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 399.1117 - acc: 0.1124 - val_loss: 399.1109 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 399.1116 - acc: 0.1124 - val_loss: 399.1122 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 399.1117 - acc: 0.1124 - val_loss: 399.1118 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 399.1116 - acc: 0.1124 - val_loss: 399.1128 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 399.1117 - acc: 0.1124 - val_loss: 399.1109 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 399.1116 - acc: 0.1124 - val_loss: 399.1111 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 399.1116 - acc: 0.1124 - val_loss: 399.1109 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 399.1116 - acc: 0.1124 - val_loss: 399.1115 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 399.1116 - acc: 0.1124 - val_loss: 399.1112 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 399.1116 - acc: 0.1124 - val_loss: 399.1115 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 399.1116 - acc: 0.1124 - val_loss: 399.1114 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 399.1116 - acc: 0.1124 - val_loss: 399.1117 - val_acc: 0.1135\n",
      "Test loss: 399.1117498046875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_94 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.03805490663209177 0.657973874519397\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 72.9073 - acc: 0.1336 - val_loss: 15.0362 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0366 - acc: 0.1103 - val_loss: 15.0358 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0364 - acc: 0.1123 - val_loss: 15.0360 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0363 - acc: 0.1124 - val_loss: 15.0362 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0362 - acc: 0.1124 - val_loss: 15.0363 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0362 - acc: 0.1124 - val_loss: 15.0358 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0362 - acc: 0.1124 - val_loss: 15.0360 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0362 - acc: 0.1124 - val_loss: 15.0356 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 15.0361 - acc: 0.1124 - val_loss: 15.0362 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 15.0361 - acc: 0.1124 - val_loss: 15.0358 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0361 - acc: 0.1124 - val_loss: 15.0357 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0361 - acc: 0.1124 - val_loss: 15.0359 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 15.0361 - acc: 0.1124 - val_loss: 15.0361 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0361 - acc: 0.1124 - val_loss: 15.0359 - val_acc: 0.1135\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0361 - acc: 0.1124 - val_loss: 15.0358 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0361 - acc: 0.1124 - val_loss: 15.0358 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 15.0361 - acc: 0.1124 - val_loss: 15.0357 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0361 - acc: 0.1124 - val_loss: 15.0359 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0361 - acc: 0.1124 - val_loss: 15.0356 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 15.0361 - acc: 0.1124 - val_loss: 15.0355 - val_acc: 0.1135\n",
      "Test loss: 15.035450747680665\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_97 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 2.766696815362127 4.810480664453415\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 3519.9654 - acc: 0.1305 - val_loss: 922.3116 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 921.0290 - acc: 0.1117 - val_loss: 920.7525 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 921.0218 - acc: 0.1124 - val_loss: 921.0793 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 921.0218 - acc: 0.1124 - val_loss: 921.0089 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 921.0216 - acc: 0.1124 - val_loss: 921.0236 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 921.0216 - acc: 0.1124 - val_loss: 921.0223 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 921.0215 - acc: 0.1124 - val_loss: 921.0226 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 921.0217 - acc: 0.1124 - val_loss: 921.0225 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 921.0218 - acc: 0.1124 - val_loss: 921.0208 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 921.0217 - acc: 0.1124 - val_loss: 921.0215 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 921.0217 - acc: 0.1124 - val_loss: 921.0212 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 921.0217 - acc: 0.1124 - val_loss: 921.0217 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 921.0217 - acc: 0.1124 - val_loss: 921.0212 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 921.0217 - acc: 0.1124 - val_loss: 921.0212 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 921.0217 - acc: 0.1124 - val_loss: 921.0232 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 921.0217 - acc: 0.1124 - val_loss: 921.0207 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 921.0217 - acc: 0.1124 - val_loss: 921.0219 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 921.0217 - acc: 0.1124 - val_loss: 921.0237 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 921.0217 - acc: 0.1124 - val_loss: 921.0210 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 921.0217 - acc: 0.1124 - val_loss: 921.0215 - val_acc: 0.1135\n",
      "Test loss: 921.021529296875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_100 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.8896920672331583 2.7802817011999066\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 1184.2336 - acc: 0.1304 - val_loss: 298.0223 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 297.9416 - acc: 0.1110 - val_loss: 297.9364 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 297.9412 - acc: 0.1124 - val_loss: 297.9414 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 297.9411 - acc: 0.1124 - val_loss: 297.9406 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 297.9411 - acc: 0.1124 - val_loss: 297.9405 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 297.9410 - acc: 0.1124 - val_loss: 297.9408 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 297.9410 - acc: 0.1124 - val_loss: 297.9404 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 297.9410 - acc: 0.1124 - val_loss: 297.9405 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 297.9410 - acc: 0.1124 - val_loss: 297.9401 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 297.9410 - acc: 0.1124 - val_loss: 297.9407 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 297.9410 - acc: 0.1124 - val_loss: 297.9414 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 297.9410 - acc: 0.1124 - val_loss: 297.9408 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 297.9410 - acc: 0.1124 - val_loss: 297.9409 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 297.9410 - acc: 0.1124 - val_loss: 297.9409 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 297.9409 - acc: 0.1124 - val_loss: 297.9405 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 297.9409 - acc: 0.1124 - val_loss: 297.9408 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 297.9409 - acc: 0.1124 - val_loss: 297.9408 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 297.9409 - acc: 0.1124 - val_loss: 297.9409 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 297.9409 - acc: 0.1124 - val_loss: 297.9413 - val_acc: 0.1135\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 16us/step - loss: 297.9409 - acc: 0.1124 - val_loss: 297.9404 - val_acc: 0.1135\n",
      "Test loss: 297.94044780273435\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_103 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.18512682940238157 0.637759853869355\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 250.1300 - acc: 0.1307 - val_loss: 63.8374 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8281 - acc: 0.1117 - val_loss: 63.8270 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8280 - acc: 0.1122 - val_loss: 63.8287 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8278 - acc: 0.1124 - val_loss: 63.8284 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8278 - acc: 0.1124 - val_loss: 63.8283 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8267 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8285 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8276 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8275 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8272 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8274 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8278 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8273 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8266 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8273 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8276 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8273 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8273 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8275 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 63.8277 - acc: 0.1124 - val_loss: 63.8275 - val_acc: 0.1135\n",
      "Test loss: 63.827533581542966\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_106 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 2.7590885127600298 4.172087336805581\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 3490.9509 - acc: 0.1290 - val_loss: 919.8709 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 918.4001 - acc: 0.1119 - val_loss: 918.0122 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 918.3903 - acc: 0.1122 - val_loss: 918.4881 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 918.3903 - acc: 0.1124 - val_loss: 918.3643 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 918.3901 - acc: 0.1124 - val_loss: 918.3958 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 918.3901 - acc: 0.1124 - val_loss: 918.3889 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 918.3902 - acc: 0.1124 - val_loss: 918.3902 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 918.3901 - acc: 0.1124 - val_loss: 918.3900 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 918.3900 - acc: 0.1124 - val_loss: 918.3893 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 918.3900 - acc: 0.1124 - val_loss: 918.3899 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 918.3900 - acc: 0.1124 - val_loss: 918.3907 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 918.3900 - acc: 0.1124 - val_loss: 918.3912 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 918.3899 - acc: 0.1124 - val_loss: 918.3891 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 918.3899 - acc: 0.1124 - val_loss: 918.3899 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 918.3899 - acc: 0.1124 - val_loss: 918.3894 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 918.3899 - acc: 0.1124 - val_loss: 918.3890 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 918.3899 - acc: 0.1124 - val_loss: 918.3902 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 918.3899 - acc: 0.1124 - val_loss: 918.3894 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 918.3899 - acc: 0.1124 - val_loss: 918.3899 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 918.3899 - acc: 0.1124 - val_loss: 918.3889 - val_acc: 0.1135\n",
      "Test loss: 918.3888763671875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_109 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.857859829893108 3.030642411318299\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 28us/step - loss: 1154.3941 - acc: 0.1307 - val_loss: 287.4916 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 287.4215 - acc: 0.1120 - val_loss: 287.4185 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 287.4211 - acc: 0.1123 - val_loss: 287.4205 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 287.4210 - acc: 0.1124 - val_loss: 287.4195 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 287.4210 - acc: 0.1124 - val_loss: 287.4206 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 287.4209 - acc: 0.1124 - val_loss: 287.4199 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 287.4210 - acc: 0.1124 - val_loss: 287.4206 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 287.4209 - acc: 0.1124 - val_loss: 287.4203 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 287.4209 - acc: 0.1124 - val_loss: 287.4199 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 287.4209 - acc: 0.1124 - val_loss: 287.4213 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 287.4208 - acc: 0.1124 - val_loss: 287.4201 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 287.4208 - acc: 0.1124 - val_loss: 287.4206 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 287.4209 - acc: 0.1124 - val_loss: 287.4205 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 287.4209 - acc: 0.1124 - val_loss: 287.4210 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 287.4209 - acc: 0.1124 - val_loss: 287.4199 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 287.4209 - acc: 0.1124 - val_loss: 287.4203 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 287.4208 - acc: 0.1124 - val_loss: 287.4205 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 287.4209 - acc: 0.1124 - val_loss: 287.4206 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 287.4208 - acc: 0.1124 - val_loss: 287.4214 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 287.4209 - acc: 0.1124 - val_loss: 287.4224 - val_acc: 0.1135\n",
      "Test loss: 287.4224403320313\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_112 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 1.669041144958348 0.05140607128130115\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 2007.5552 - acc: 0.1270 - val_loss: 557.2928 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7102 - acc: 0.1115 - val_loss: 554.1637 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7083 - acc: 0.1124 - val_loss: 557.2145 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 555.7139 - acc: 0.1123 - val_loss: 554.2477 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7101 - acc: 0.1124 - val_loss: 557.1379 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7145 - acc: 0.1124 - val_loss: 554.3264 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7099 - acc: 0.1124 - val_loss: 557.0588 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 555.7149 - acc: 0.1124 - val_loss: 554.4034 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7106 - acc: 0.1124 - val_loss: 556.9850 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7145 - acc: 0.1124 - val_loss: 554.4744 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7105 - acc: 0.1124 - val_loss: 556.9145 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 555.7142 - acc: 0.1124 - val_loss: 554.5425 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7104 - acc: 0.1124 - val_loss: 556.8498 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7139 - acc: 0.1124 - val_loss: 554.6054 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7103 - acc: 0.1124 - val_loss: 556.7892 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7136 - acc: 0.1124 - val_loss: 554.6626 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7104 - acc: 0.1124 - val_loss: 556.7325 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7158 - acc: 0.1124 - val_loss: 554.7216 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7126 - acc: 0.1124 - val_loss: 556.6788 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 555.7157 - acc: 0.1124 - val_loss: 554.7757 - val_acc: 0.1135\n",
      "Test loss: 554.775726953125\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 4.213543170742539 1.0893652130487093\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 5123.1126 - acc: 0.1346 - val_loss: 1403.5930 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4494 - acc: 0.1114 - val_loss: 1397.9394 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4263 - acc: 0.1124 - val_loss: 1402.4088 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4237 - acc: 0.1124 - val_loss: 1398.8395 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4126 - acc: 0.1124 - val_loss: 1401.6668 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4132 - acc: 0.1124 - val_loss: 1399.4121 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4075 - acc: 0.1124 - val_loss: 1401.2014 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4087 - acc: 0.1124 - val_loss: 1399.7766 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4056 - acc: 0.1124 - val_loss: 1400.9064 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4067 - acc: 0.1124 - val_loss: 1400.0075 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4050 - acc: 0.1124 - val_loss: 1400.7215 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4059 - acc: 0.1124 - val_loss: 1400.1541 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4048 - acc: 0.1124 - val_loss: 1400.6040 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4054 - acc: 0.1124 - val_loss: 1400.2467 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4048 - acc: 0.1124 - val_loss: 1400.5308 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4052 - acc: 0.1124 - val_loss: 1400.3044 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4048 - acc: 0.1124 - val_loss: 1400.4841 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4051 - acc: 0.1124 - val_loss: 1400.3408 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4049 - acc: 0.1124 - val_loss: 1400.4560 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1400.4050 - acc: 0.1124 - val_loss: 1400.3644 - val_acc: 0.1135\n",
      "Test loss: 1400.364387109375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_118 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 4.4301797864384636 3.1652163946923166\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 5462.7437 - acc: 0.1266 - val_loss: 1474.2791 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6760 - acc: 0.1113 - val_loss: 1471.8198 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6455 - acc: 0.1116 - val_loss: 1473.0837 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6397 - acc: 0.1124 - val_loss: 1472.4026 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6365 - acc: 0.1124 - val_loss: 1472.7599 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6364 - acc: 0.1124 - val_loss: 1472.5706 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6378 - acc: 0.1124 - val_loss: 1472.6731 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6382 - acc: 0.1124 - val_loss: 1472.6188 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6381 - acc: 0.1124 - val_loss: 1472.6473 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6382 - acc: 0.1124 - val_loss: 1472.6320 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6382 - acc: 0.1124 - val_loss: 1472.6411 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6382 - acc: 0.1124 - val_loss: 1472.6356 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6382 - acc: 0.1124 - val_loss: 1472.6389 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6382 - acc: 0.1124 - val_loss: 1472.6368 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6382 - acc: 0.1124 - val_loss: 1472.6381 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6382 - acc: 0.1124 - val_loss: 1472.6377 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6382 - acc: 0.1124 - val_loss: 1472.6385 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6382 - acc: 0.1124 - val_loss: 1472.6373 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6382 - acc: 0.1124 - val_loss: 1472.6377 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1472.6382 - acc: 0.1124 - val_loss: 1472.6384 - val_acc: 0.1135\n",
      "Test loss: 1472.63840703125\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_121 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 3.3168097893816877 2.135867135337457\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 4081.6024 - acc: 0.1278 - val_loss: 1104.3356 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.1172 - acc: 0.1117 - val_loss: 1102.4213 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0941 - acc: 0.1124 - val_loss: 1103.4751 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0890 - acc: 0.1124 - val_loss: 1102.8693 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0860 - acc: 0.1124 - val_loss: 1103.2091 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0858 - acc: 0.1124 - val_loss: 1103.0162 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0853 - acc: 0.1124 - val_loss: 1103.1251 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0854 - acc: 0.1124 - val_loss: 1103.0606 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0853 - acc: 0.1124 - val_loss: 1103.0997 - val_acc: 0.1135\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0854 - acc: 0.1124 - val_loss: 1103.0750 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0853 - acc: 0.1124 - val_loss: 1103.0911 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0854 - acc: 0.1124 - val_loss: 1103.0820 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0854 - acc: 0.1124 - val_loss: 1103.0884 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0854 - acc: 0.1124 - val_loss: 1103.0832 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0854 - acc: 0.1124 - val_loss: 1103.0855 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0853 - acc: 0.1124 - val_loss: 1103.0844 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0853 - acc: 0.1124 - val_loss: 1103.0862 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0853 - acc: 0.1124 - val_loss: 1103.0840 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0853 - acc: 0.1124 - val_loss: 1103.0861 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1103.0853 - acc: 0.1124 - val_loss: 1103.0847 - val_acc: 0.1135\n",
      "Test loss: 1103.0846580078125\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_124 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.4460841692160761 1.6876735145912714\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 606.4124 - acc: 0.1304 - val_loss: 150.6097 - val_acc: 0.1010\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5813 - acc: 0.1113 - val_loss: 150.5796 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5810 - acc: 0.1122 - val_loss: 150.5808 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5809 - acc: 0.1124 - val_loss: 150.5802 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5809 - acc: 0.1124 - val_loss: 150.5789 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5809 - acc: 0.1120 - val_loss: 150.5792 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5808 - acc: 0.1124 - val_loss: 150.5799 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5809 - acc: 0.1124 - val_loss: 150.5808 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5808 - acc: 0.1124 - val_loss: 150.5813 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5808 - acc: 0.1124 - val_loss: 150.5801 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5808 - acc: 0.1124 - val_loss: 150.5817 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5808 - acc: 0.1124 - val_loss: 150.5786 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5808 - acc: 0.1124 - val_loss: 150.5800 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5808 - acc: 0.1124 - val_loss: 150.5780 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5808 - acc: 0.1124 - val_loss: 150.5806 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5808 - acc: 0.1124 - val_loss: 150.5802 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5808 - acc: 0.1124 - val_loss: 150.5808 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5808 - acc: 0.1124 - val_loss: 150.5803 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5808 - acc: 0.1124 - val_loss: 150.5804 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 150.5808 - acc: 0.1124 - val_loss: 150.5807 - val_acc: 0.1135\n",
      "Test loss: 150.58066313476562\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_127 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 1.2876811457717188 2.310805470608252\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 1642.3249 - acc: 0.1331 - val_loss: 430.6220 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9087 - acc: 0.1119 - val_loss: 429.7599 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9052 - acc: 0.1122 - val_loss: 429.9356 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9053 - acc: 0.1124 - val_loss: 429.8988 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9050 - acc: 0.1124 - val_loss: 429.9054 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9051 - acc: 0.1124 - val_loss: 429.9043 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9050 - acc: 0.1124 - val_loss: 429.9049 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9051 - acc: 0.1124 - val_loss: 429.9040 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9050 - acc: 0.1124 - val_loss: 429.9043 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9050 - acc: 0.1124 - val_loss: 429.9049 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9050 - acc: 0.1124 - val_loss: 429.9057 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9050 - acc: 0.1124 - val_loss: 429.9052 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9050 - acc: 0.1124 - val_loss: 429.9047 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9050 - acc: 0.1124 - val_loss: 429.9042 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9050 - acc: 0.1124 - val_loss: 429.9045 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9050 - acc: 0.1124 - val_loss: 429.9045 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9050 - acc: 0.1124 - val_loss: 429.9040 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9050 - acc: 0.1124 - val_loss: 429.9046 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9050 - acc: 0.1124 - val_loss: 429.9050 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 429.9050 - acc: 0.1124 - val_loss: 429.9040 - val_acc: 0.1135\n",
      "Test loss: 429.9039864257812\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_130 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 2.4106778915796774 1.659464872327673\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 2968.0911 - acc: 0.1323 - val_loss: 804.3406 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3997 - acc: 0.1118 - val_loss: 801.3422 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3806 - acc: 0.1121 - val_loss: 802.9416 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3784 - acc: 0.1122 - val_loss: 802.0707 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3759 - acc: 0.1124 - val_loss: 802.5423 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3762 - acc: 0.1124 - val_loss: 802.2860 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3756 - acc: 0.1124 - val_loss: 802.4251 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3758 - acc: 0.1124 - val_loss: 802.3486 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3757 - acc: 0.1124 - val_loss: 802.3899 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3758 - acc: 0.1124 - val_loss: 802.3680 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3757 - acc: 0.1124 - val_loss: 802.3784 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3758 - acc: 0.1124 - val_loss: 802.3735 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3757 - acc: 0.1124 - val_loss: 802.3763 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3758 - acc: 0.1124 - val_loss: 802.3753 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3758 - acc: 0.1124 - val_loss: 802.3753 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3759 - acc: 0.1124 - val_loss: 802.3760 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3759 - acc: 0.1124 - val_loss: 802.3747 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3759 - acc: 0.1124 - val_loss: 802.3755 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3759 - acc: 0.1124 - val_loss: 802.3758 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 802.3759 - acc: 0.1124 - val_loss: 802.3752 - val_acc: 0.1135\n",
      "Test loss: 802.3752234375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_133 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 4.96065955574805 2.017111375361833\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 6039.2616 - acc: 0.1317 - val_loss: 1649.3617 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4860 - acc: 0.1107 - val_loss: 1647.8704 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4579 - acc: 0.1124 - val_loss: 1648.8653 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4466 - acc: 0.1124 - val_loss: 1648.1513 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4394 - acc: 0.1124 - val_loss: 1648.6408 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4372 - acc: 0.1124 - val_loss: 1648.2949 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4352 - acc: 0.1124 - val_loss: 1648.5329 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4348 - acc: 0.1124 - val_loss: 1648.3647 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4342 - acc: 0.1124 - val_loss: 1648.4819 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4343 - acc: 0.1124 - val_loss: 1648.4007 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4340 - acc: 0.1124 - val_loss: 1648.4583 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4341 - acc: 0.1124 - val_loss: 1648.4177 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4340 - acc: 0.1124 - val_loss: 1648.4455 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4340 - acc: 0.1124 - val_loss: 1648.4248 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4339 - acc: 0.1124 - val_loss: 1648.4387 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4339 - acc: 0.1124 - val_loss: 1648.4296 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4338 - acc: 0.1124 - val_loss: 1648.4352 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4338 - acc: 0.1124 - val_loss: 1648.4318 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4338 - acc: 0.1124 - val_loss: 1648.4346 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1648.4338 - acc: 0.1124 - val_loss: 1648.4332 - val_acc: 0.1135\n",
      "Test loss: 1648.433195703125\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_136 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 4.68775752333888 3.935129026281556\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 5798.7017 - acc: 0.1244 - val_loss: 1561.5723 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2653 - acc: 0.1117 - val_loss: 1556.6907 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2347 - acc: 0.1124 - val_loss: 1558.9692 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2330 - acc: 0.1124 - val_loss: 1557.8819 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2302 - acc: 0.1124 - val_loss: 1558.3946 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2305 - acc: 0.1124 - val_loss: 1558.1518 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2300 - acc: 0.1124 - val_loss: 1558.2665 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2301 - acc: 0.1124 - val_loss: 1558.2124 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2300 - acc: 0.1124 - val_loss: 1558.2378 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2300 - acc: 0.1124 - val_loss: 1558.2254 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2299 - acc: 0.1124 - val_loss: 1558.2307 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2299 - acc: 0.1124 - val_loss: 1558.2287 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2298 - acc: 0.1124 - val_loss: 1558.2277 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2298 - acc: 0.1124 - val_loss: 1558.2320 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2298 - acc: 0.1124 - val_loss: 1558.2285 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2298 - acc: 0.1124 - val_loss: 1558.2308 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2299 - acc: 0.1124 - val_loss: 1558.2294 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2299 - acc: 0.1124 - val_loss: 1558.2300 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2298 - acc: 0.1124 - val_loss: 1558.2307 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1558.2298 - acc: 0.1124 - val_loss: 1558.2283 - val_acc: 0.1135\n",
      "Test loss: 1558.228288671875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_139 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 3.628389621329498 4.370542927092534\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 4535.5152 - acc: 0.1322 - val_loss: 1209.3984 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8535 - acc: 0.1107 - val_loss: 1205.9721 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8347 - acc: 0.1121 - val_loss: 1207.1293 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8344 - acc: 0.1124 - val_loss: 1206.7318 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8336 - acc: 0.1124 - val_loss: 1206.8677 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8337 - acc: 0.1124 - val_loss: 1206.8222 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8336 - acc: 0.1124 - val_loss: 1206.8377 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8336 - acc: 0.1124 - val_loss: 1206.8317 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8335 - acc: 0.1124 - val_loss: 1206.8341 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8336 - acc: 0.1124 - val_loss: 1206.8331 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8337 - acc: 0.1124 - val_loss: 1206.8326 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8337 - acc: 0.1124 - val_loss: 1206.8329 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8336 - acc: 0.1124 - val_loss: 1206.8339 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8336 - acc: 0.1124 - val_loss: 1206.8328 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8336 - acc: 0.1124 - val_loss: 1206.8334 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8337 - acc: 0.1124 - val_loss: 1206.8328 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8336 - acc: 0.1124 - val_loss: 1206.8342 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8336 - acc: 0.1124 - val_loss: 1206.8325 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8336 - acc: 0.1124 - val_loss: 1206.8342 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1206.8336 - acc: 0.1124 - val_loss: 1206.8331 - val_acc: 0.1135\n",
      "Test loss: 1206.8331421875\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_142 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.6215302903922093 3.3671882915510762\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 32us/step - loss: 882.3306 - acc: 0.1331 - val_loss: 209.0797 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0691 - acc: 0.1114 - val_loss: 209.0687 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0689 - acc: 0.1122 - val_loss: 209.0683 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0689 - acc: 0.1124 - val_loss: 209.0689 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0688 - acc: 0.1124 - val_loss: 209.0683 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0677 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0683 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0689 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0682 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0684 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0686 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0682 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0677 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0694 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0686 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0676 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0681 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0688 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0683 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 209.0687 - acc: 0.1124 - val_loss: 209.0682 - val_acc: 0.1135\n",
      "Test loss: 209.0681733642578\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_145 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 1.1034043063939412 2.5083206134521743\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 1430.1598 - acc: 0.1307 - val_loss: 369.0452 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8020 - acc: 0.1110 - val_loss: 368.7677 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8006 - acc: 0.1119 - val_loss: 368.8042 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8006 - acc: 0.1124 - val_loss: 368.7995 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8005 - acc: 0.1124 - val_loss: 368.8005 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8005 - acc: 0.1124 - val_loss: 368.8005 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8005 - acc: 0.1124 - val_loss: 368.7996 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8004 - acc: 0.1124 - val_loss: 368.8007 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8005 - acc: 0.1124 - val_loss: 368.8007 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8004 - acc: 0.1124 - val_loss: 368.8003 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8004 - acc: 0.1124 - val_loss: 368.8001 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8004 - acc: 0.1124 - val_loss: 368.8000 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8004 - acc: 0.1124 - val_loss: 368.8003 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8004 - acc: 0.1124 - val_loss: 368.8007 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8004 - acc: 0.1124 - val_loss: 368.8004 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8004 - acc: 0.1124 - val_loss: 368.7996 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8004 - acc: 0.1124 - val_loss: 368.8006 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8004 - acc: 0.1124 - val_loss: 368.8001 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8004 - acc: 0.1124 - val_loss: 368.8002 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 368.8004 - acc: 0.1124 - val_loss: 368.8000 - val_acc: 0.1135\n",
      "Test loss: 368.800005078125\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_148 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.05017666552758701 0.9983318696174882\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 100.1903 - acc: 0.1433 - val_loss: 19.1147 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1148 - acc: 0.1113 - val_loss: 19.1149 - val_acc: 0.1028\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1146 - acc: 0.1123 - val_loss: 19.1140 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1144 - acc: 0.1124 - val_loss: 19.1144 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1144 - acc: 0.1124 - val_loss: 19.1138 - val_acc: 0.1135\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1143 - acc: 0.1124 - val_loss: 19.1139 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1143 - acc: 0.1124 - val_loss: 19.1145 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1143 - acc: 0.1124 - val_loss: 19.1142 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1143 - acc: 0.1124 - val_loss: 19.1142 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1143 - acc: 0.1124 - val_loss: 19.1141 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1143 - acc: 0.1124 - val_loss: 19.1139 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1143 - acc: 0.1124 - val_loss: 19.1140 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1143 - acc: 0.1124 - val_loss: 19.1138 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1143 - acc: 0.1124 - val_loss: 19.1142 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 19.1143 - acc: 0.1124 - val_loss: 19.1139 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1143 - acc: 0.1124 - val_loss: 19.1140 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1142 - acc: 0.1124 - val_loss: 19.1140 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1143 - acc: 0.1124 - val_loss: 19.1140 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1143 - acc: 0.1124 - val_loss: 19.1141 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 19.1143 - acc: 0.1124 - val_loss: 19.1144 - val_acc: 0.1135\n",
      "Test loss: 19.11444370727539\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_151 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.33316195534341053 0.27450039611360233\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 413.9892 - acc: 0.1300 - val_loss: 113.1011 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8842 - acc: 0.1116 - val_loss: 112.7741 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8818 - acc: 0.1124 - val_loss: 112.9352 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8814 - acc: 0.1124 - val_loss: 112.8531 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8812 - acc: 0.1124 - val_loss: 112.8957 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8812 - acc: 0.1124 - val_loss: 112.8719 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8812 - acc: 0.1124 - val_loss: 112.8858 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8811 - acc: 0.1124 - val_loss: 112.8774 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8811 - acc: 0.1124 - val_loss: 112.8832 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8811 - acc: 0.1124 - val_loss: 112.8789 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8811 - acc: 0.1124 - val_loss: 112.8818 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8811 - acc: 0.1124 - val_loss: 112.8804 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8811 - acc: 0.1124 - val_loss: 112.8814 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8811 - acc: 0.1124 - val_loss: 112.8805 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8811 - acc: 0.1124 - val_loss: 112.8810 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8811 - acc: 0.1124 - val_loss: 112.8799 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8811 - acc: 0.1124 - val_loss: 112.8813 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8811 - acc: 0.1124 - val_loss: 112.8807 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8811 - acc: 0.1124 - val_loss: 112.8809 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 112.8811 - acc: 0.1124 - val_loss: 112.8808 - val_acc: 0.1135\n",
      "Test loss: 112.88077437744141\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_154 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 3.0835102882522873 3.778973021471932\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 3864.3998 - acc: 0.1302 - val_loss: 1028.1415 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9797 - acc: 0.1116 - val_loss: 1025.2453 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9639 - acc: 0.1124 - val_loss: 1026.2052 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9636 - acc: 0.1124 - val_loss: 1025.8822 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9630 - acc: 0.1124 - val_loss: 1025.9909 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9631 - acc: 0.1124 - val_loss: 1025.9545 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9629 - acc: 0.1124 - val_loss: 1025.9663 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9629 - acc: 0.1124 - val_loss: 1025.9623 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9629 - acc: 0.1124 - val_loss: 1025.9621 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9629 - acc: 0.1124 - val_loss: 1025.9620 - val_acc: 0.1135\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9629 - acc: 0.1124 - val_loss: 1025.9632 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9629 - acc: 0.1124 - val_loss: 1025.9622 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9629 - acc: 0.1124 - val_loss: 1025.9636 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9629 - acc: 0.1124 - val_loss: 1025.9621 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9629 - acc: 0.1124 - val_loss: 1025.9638 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9629 - acc: 0.1124 - val_loss: 1025.9630 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9629 - acc: 0.1124 - val_loss: 1025.9630 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9629 - acc: 0.1124 - val_loss: 1025.9624 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9629 - acc: 0.1124 - val_loss: 1025.9632 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1025.9629 - acc: 0.1124 - val_loss: 1025.9620 - val_acc: 0.1135\n",
      "Test loss: 1025.9620115234375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_157 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 2.572524102574175 4.512068782679032\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 3275.8887 - acc: 0.1289 - val_loss: 857.9187 - val_acc: 0.1028\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5573 - acc: 0.1123 - val_loss: 856.2668 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5504 - acc: 0.1114 - val_loss: 856.6093 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5506 - acc: 0.1124 - val_loss: 856.5373 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5503 - acc: 0.1124 - val_loss: 856.5528 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5504 - acc: 0.1124 - val_loss: 856.5490 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5501 - acc: 0.1124 - val_loss: 856.5512 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5501 - acc: 0.1124 - val_loss: 856.5494 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5501 - acc: 0.1124 - val_loss: 856.5500 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5501 - acc: 0.1124 - val_loss: 856.5497 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5501 - acc: 0.1124 - val_loss: 856.5501 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5501 - acc: 0.1124 - val_loss: 856.5497 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5501 - acc: 0.1124 - val_loss: 856.5505 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5500 - acc: 0.1124 - val_loss: 856.5490 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5501 - acc: 0.1124 - val_loss: 856.5498 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5500 - acc: 0.1124 - val_loss: 856.5494 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5500 - acc: 0.1124 - val_loss: 856.5505 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5501 - acc: 0.1124 - val_loss: 856.5495 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5500 - acc: 0.1124 - val_loss: 856.5499 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 856.5500 - acc: 0.1124 - val_loss: 856.5497 - val_acc: 0.1135\n",
      "Test loss: 856.5496853515625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_160 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 1.9137927687530987 2.4893060543491448\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 2405.1076 - acc: 0.1303 - val_loss: 638.7473 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 637.6730 - acc: 0.1118 - val_loss: 637.3311 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 637.6643 - acc: 0.1123 - val_loss: 637.7692 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 637.6642 - acc: 0.1124 - val_loss: 637.6310 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 637.6638 - acc: 0.1124 - val_loss: 637.6740 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 637.6638 - acc: 0.1124 - val_loss: 637.6603 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 637.6637 - acc: 0.1124 - val_loss: 637.6652 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 637.6638 - acc: 0.1124 - val_loss: 637.6623 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 637.6637 - acc: 0.1124 - val_loss: 637.6641 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 637.6637 - acc: 0.1124 - val_loss: 637.6631 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 637.6637 - acc: 0.1124 - val_loss: 637.6643 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 637.6637 - acc: 0.1124 - val_loss: 637.6647 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 637.6637 - acc: 0.1124 - val_loss: 637.6635 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 637.6637 - acc: 0.1124 - val_loss: 637.6633 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 637.6636 - acc: 0.1124 - val_loss: 637.6646 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 637.6637 - acc: 0.1124 - val_loss: 637.6632 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 637.6637 - acc: 0.1124 - val_loss: 637.6632 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 637.6636 - acc: 0.1124 - val_loss: 637.6631 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 637.6637 - acc: 0.1124 - val_loss: 637.6635 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 637.6636 - acc: 0.1124 - val_loss: 637.6630 - val_acc: 0.1135\n",
      "Test loss: 637.6630140625\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_163 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 1.6189817491424092 1.4311345729804106\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 2009.6067 - acc: 0.1310 - val_loss: 540.6998 - val_acc: 0.1028\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6877 - acc: 0.1110 - val_loss: 539.2181 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6767 - acc: 0.1119 - val_loss: 539.8869 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6755 - acc: 0.1122 - val_loss: 539.5765 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6748 - acc: 0.1124 - val_loss: 539.7169 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6748 - acc: 0.1124 - val_loss: 539.6555 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6747 - acc: 0.1124 - val_loss: 539.6845 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6748 - acc: 0.1124 - val_loss: 539.6695 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6748 - acc: 0.1124 - val_loss: 539.6765 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6747 - acc: 0.1124 - val_loss: 539.6734 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6748 - acc: 0.1124 - val_loss: 539.6749 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6747 - acc: 0.1124 - val_loss: 539.6737 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6747 - acc: 0.1124 - val_loss: 539.6751 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6746 - acc: 0.1124 - val_loss: 539.6743 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6746 - acc: 0.1124 - val_loss: 539.6743 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6746 - acc: 0.1124 - val_loss: 539.6746 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6747 - acc: 0.1124 - val_loss: 539.6743 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6747 - acc: 0.1124 - val_loss: 539.6753 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6746 - acc: 0.1124 - val_loss: 539.6743 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 539.6747 - acc: 0.1124 - val_loss: 539.6751 - val_acc: 0.1135\n",
      "Test loss: 539.6750625976563\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_166 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.6534396555696191 0.6568754139625469\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 814.6968 - acc: 0.1318 - val_loss: 219.7486 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2099 - acc: 0.1120 - val_loss: 218.9864 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2054 - acc: 0.1124 - val_loss: 219.2954 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2051 - acc: 0.1124 - val_loss: 219.1676 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1123 - val_loss: 219.2202 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.1993 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.2070 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.2031 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.2049 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.2042 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.2054 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.2023 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.2041 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.2051 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.2038 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.2053 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.2039 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.2049 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.2044 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 219.2049 - acc: 0.1124 - val_loss: 219.2045 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 219.204520703125\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_169 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 1.0375257742609916 0.4596238692362703\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 1269.3773 - acc: 0.1313 - val_loss: 347.2863 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6124 - acc: 0.1116 - val_loss: 346.1535 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6049 - acc: 0.1120 - val_loss: 346.9115 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6033 - acc: 0.1124 - val_loss: 346.3922 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6014 - acc: 0.1124 - val_loss: 346.7425 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6013 - acc: 0.1124 - val_loss: 346.5045 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6006 - acc: 0.1124 - val_loss: 346.6648 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6008 - acc: 0.1124 - val_loss: 346.5562 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6006 - acc: 0.1124 - val_loss: 346.6293 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6006 - acc: 0.1124 - val_loss: 346.5809 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6005 - acc: 0.1124 - val_loss: 346.6149 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6006 - acc: 0.1124 - val_loss: 346.5902 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6005 - acc: 0.1124 - val_loss: 346.6087 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6006 - acc: 0.1124 - val_loss: 346.5941 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6005 - acc: 0.1124 - val_loss: 346.6037 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6005 - acc: 0.1124 - val_loss: 346.5972 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6005 - acc: 0.1124 - val_loss: 346.6017 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6005 - acc: 0.1124 - val_loss: 346.6003 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6005 - acc: 0.1124 - val_loss: 346.6001 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 346.6005 - acc: 0.1124 - val_loss: 346.5997 - val_acc: 0.1135\n",
      "Test loss: 346.59971728515626\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_172 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 2.22033936296866 4.686068665605178\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 2858.6413 - acc: 0.1316 - val_loss: 740.5703 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7376 - acc: 0.1123 - val_loss: 739.6081 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7342 - acc: 0.1123 - val_loss: 739.7542 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7342 - acc: 0.1124 - val_loss: 739.7299 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7340 - acc: 0.1124 - val_loss: 739.7339 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7339 - acc: 0.1124 - val_loss: 739.7329 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7338 - acc: 0.1124 - val_loss: 739.7331 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7338 - acc: 0.1124 - val_loss: 739.7332 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7338 - acc: 0.1124 - val_loss: 739.7339 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7338 - acc: 0.1124 - val_loss: 739.7327 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7338 - acc: 0.1124 - val_loss: 739.7329 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7338 - acc: 0.1124 - val_loss: 739.7332 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7338 - acc: 0.1124 - val_loss: 739.7335 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7338 - acc: 0.1124 - val_loss: 739.7347 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7338 - acc: 0.1124 - val_loss: 739.7344 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7338 - acc: 0.1124 - val_loss: 739.7336 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7338 - acc: 0.1124 - val_loss: 739.7340 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7338 - acc: 0.1124 - val_loss: 739.7336 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7338 - acc: 0.1124 - val_loss: 739.7341 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 739.7338 - acc: 0.1124 - val_loss: 739.7336 - val_acc: 0.1135\n",
      "Test loss: 739.733633984375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_175 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 3.560143584925067 3.9229703492214534\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 35us/step - loss: 4444.2432 - acc: 0.1332 - val_loss: 1186.6636 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1429 - acc: 0.1118 - val_loss: 1183.1870 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1222 - acc: 0.1124 - val_loss: 1184.4747 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1215 - acc: 0.1120 - val_loss: 1183.9875 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1205 - acc: 0.1124 - val_loss: 1184.1707 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1207 - acc: 0.1124 - val_loss: 1184.1013 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1206 - acc: 0.1124 - val_loss: 1184.1275 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1205 - acc: 0.1124 - val_loss: 1184.1174 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1205 - acc: 0.1124 - val_loss: 1184.1216 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1205 - acc: 0.1124 - val_loss: 1184.1195 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1205 - acc: 0.1124 - val_loss: 1184.1208 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1207 - acc: 0.1124 - val_loss: 1184.1201 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1206 - acc: 0.1124 - val_loss: 1184.1207 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1206 - acc: 0.1124 - val_loss: 1184.1210 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1206 - acc: 0.1124 - val_loss: 1184.1199 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1206 - acc: 0.1124 - val_loss: 1184.1190 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1206 - acc: 0.1124 - val_loss: 1184.1195 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1206 - acc: 0.1124 - val_loss: 1184.1205 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1206 - acc: 0.1124 - val_loss: 1184.1207 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1184.1206 - acc: 0.1124 - val_loss: 1184.1209 - val_acc: 0.1135\n",
      "Test loss: 1184.12084609375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_178 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.9141027154363028 2.920803022730635\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 1216.8266 - acc: 0.1292 - val_loss: 306.1663 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0638 - acc: 0.1119 - val_loss: 306.0567 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0634 - acc: 0.1121 - val_loss: 306.0634 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0633 - acc: 0.1124 - val_loss: 306.0636 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0632 - acc: 0.1124 - val_loss: 306.0631 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0632 - acc: 0.1124 - val_loss: 306.0636 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0632 - acc: 0.1124 - val_loss: 306.0633 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0632 - acc: 0.1124 - val_loss: 306.0629 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0631 - acc: 0.1124 - val_loss: 306.0629 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0632 - acc: 0.1124 - val_loss: 306.0628 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0632 - acc: 0.1124 - val_loss: 306.0635 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0632 - acc: 0.1124 - val_loss: 306.0629 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0631 - acc: 0.1124 - val_loss: 306.0621 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0631 - acc: 0.1124 - val_loss: 306.0614 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0631 - acc: 0.1124 - val_loss: 306.0638 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0631 - acc: 0.1124 - val_loss: 306.0631 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0631 - acc: 0.1124 - val_loss: 306.0636 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0631 - acc: 0.1124 - val_loss: 306.0621 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0631 - acc: 0.1124 - val_loss: 306.0612 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 306.0631 - acc: 0.1124 - val_loss: 306.0642 - val_acc: 0.1135\n",
      "Test loss: 306.06416943359375\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_181 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.4182569700905743 2.7630048547030563\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 613.1490 - acc: 0.1317 - val_loss: 141.5303 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5277 - acc: 0.1117 - val_loss: 141.5272 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5275 - acc: 0.1125 - val_loss: 141.5270 - val_acc: 0.1028\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5273 - acc: 0.1118 - val_loss: 141.5269 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5273 - acc: 0.1124 - val_loss: 141.5268 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5273 - acc: 0.1124 - val_loss: 141.5267 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5273 - acc: 0.1124 - val_loss: 141.5266 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5273 - acc: 0.1124 - val_loss: 141.5270 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5272 - acc: 0.1124 - val_loss: 141.5264 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5273 - acc: 0.1124 - val_loss: 141.5270 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5272 - acc: 0.1124 - val_loss: 141.5271 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5272 - acc: 0.1124 - val_loss: 141.5270 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5272 - acc: 0.1124 - val_loss: 141.5273 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5272 - acc: 0.1124 - val_loss: 141.5273 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5272 - acc: 0.1124 - val_loss: 141.5270 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5272 - acc: 0.1124 - val_loss: 141.5271 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5272 - acc: 0.1124 - val_loss: 141.5271 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5272 - acc: 0.1124 - val_loss: 141.5267 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5272 - acc: 0.1124 - val_loss: 141.5272 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 141.5272 - acc: 0.1124 - val_loss: 141.5272 - val_acc: 0.1135\n",
      "Test loss: 141.52716154785156\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_184 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 1.4844550715749756 1.230596261006428\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 1838.8333 - acc: 0.1273 - val_loss: 496.2660 - val_acc: 0.1028\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0244 - acc: 0.1119 - val_loss: 494.4261 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0133 - acc: 0.1119 - val_loss: 495.2937 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0123 - acc: 0.1124 - val_loss: 494.8758 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0113 - acc: 0.1124 - val_loss: 495.0753 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0115 - acc: 0.1124 - val_loss: 494.9799 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0112 - acc: 0.1124 - val_loss: 495.0257 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0113 - acc: 0.1124 - val_loss: 495.0038 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0113 - acc: 0.1124 - val_loss: 495.0146 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0113 - acc: 0.1124 - val_loss: 495.0096 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0113 - acc: 0.1124 - val_loss: 495.0118 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0113 - acc: 0.1124 - val_loss: 495.0107 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0113 - acc: 0.1124 - val_loss: 495.0121 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0113 - acc: 0.1124 - val_loss: 495.0122 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0113 - acc: 0.1124 - val_loss: 495.0119 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0113 - acc: 0.1124 - val_loss: 495.0123 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0113 - acc: 0.1124 - val_loss: 495.0094 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0113 - acc: 0.1124 - val_loss: 495.0085 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0113 - acc: 0.1124 - val_loss: 495.0118 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 495.0113 - acc: 0.1124 - val_loss: 495.0127 - val_acc: 0.1135\n",
      "Test loss: 495.01275004882814\n",
      "Test accuracy: 0.1135\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_187 (Dense)            (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training with L1, L2 regularization parameter 0.18645279383461155 0.7702942496200026\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 257.1528 - acc: 0.1313 - val_loss: 64.2994 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2900 - acc: 0.1116 - val_loss: 64.2892 - val_acc: 0.1135\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2898 - acc: 0.1114 - val_loss: 64.2891 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2898 - acc: 0.1124 - val_loss: 64.2886 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2897 - acc: 0.1124 - val_loss: 64.2891 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2897 - acc: 0.1124 - val_loss: 64.2892 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2897 - acc: 0.1124 - val_loss: 64.2895 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2897 - acc: 0.1124 - val_loss: 64.2895 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2896 - acc: 0.1124 - val_loss: 64.2898 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2896 - acc: 0.1124 - val_loss: 64.2897 - val_acc: 0.1135\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2896 - acc: 0.1124 - val_loss: 64.2895 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2896 - acc: 0.1124 - val_loss: 64.2891 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2896 - acc: 0.1124 - val_loss: 64.2899 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2896 - acc: 0.1124 - val_loss: 64.2893 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2896 - acc: 0.1124 - val_loss: 64.2889 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2896 - acc: 0.1124 - val_loss: 64.2878 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2896 - acc: 0.1124 - val_loss: 64.2893 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2896 - acc: 0.1124 - val_loss: 64.2894 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2896 - acc: 0.1124 - val_loss: 64.2893 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 64.2896 - acc: 0.1124 - val_loss: 64.2895 - val_acc: 0.1135\n",
      "Test loss: 64.28950173339844\n",
      "Test accuracy: 0.1135\n",
      "{'l2': 2.46899936932645, 'l1': 0.19662018084800856}\n",
      "{'tid': 0, 'misc': {'tid': 0, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'vals': {'l1': [0.19662018084800856], 'l2': [2.46899936932645]}, 'workdir': None, 'idxs': {'l1': [0], 'l2': [0]}}, 'state': 2, 'refresh_time': datetime.datetime(2018, 9, 3, 6, 48, 28, 908000), 'spec': None, 'owner': None, 'result': {'status': 'ok', 'loss': -0.1135}, 'exp_key': None, 'version': 0, 'book_time': datetime.datetime(2018, 9, 3, 6, 48, 9, 602000)}\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    model_4 = Sequential()\n",
    "    model_4.add(Dense(512, activation='relu', input_shape=(784,), kernel_regularizer=regularizers.l1_l2(l1=params['l1'], l2=params['l2'])))\n",
    "    model_4.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=params['l1'], l2=params['l2'])))\n",
    "    model_4.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_4.summary()\n",
    "    \n",
    "    print('training with L1, L2 regularization parameter', params['l1'], params['l2'])\n",
    "    \n",
    "    model_4.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history_4 = model_4.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score_4 = model_4.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    print('Test loss:', score_4[0])\n",
    "    print('Test accuracy:', score_4[1])\n",
    "\n",
    "    return {'loss': - score_4[1], 'status': STATUS_OK} \n",
    "\n",
    "space = {\n",
    "    'l1': hp.uniform('l1', 0.0001, 5),\n",
    "    'l2': hp.uniform('l2', 0.0001, 5)\n",
    "}\n",
    "\n",
    "trials_3 = Trials()\n",
    "best_3 = fmin(objective, space, algo=tpe.suggest, trials=trials_3, max_evals = 60)\n",
    "print (best_3)\n",
    "print (trials_3.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7kAAAJzCAYAAADKo9SmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3clvJOd5P/Bv7wub5AyH5Gg2Doc9I86+SRrNaBgDPgQGctDBtmIYieG52LoItmEgPiU3x39BfFBsw0YgxBBi+yDYPhhIEAQxbPwkR1Jsycv03tz3Jrt6ra76HSZvuXplL9XVVcXvBxgI4jKs7mlW17ee930el6qqKoiIiIiIiIgcwD3qAyAiIiIiIiIyCkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5BkMuEREREREROQZDLhERERERETkGQy4RERERERE5hnfUB0BERNanKApkWYaqqvB4PHC73XC5XHC5XKM+NCIiIqI6DLlERNSWCLe1Wg2VSgWKomjB1uVywePxaH/cbjfDLxEREY2cS1VVddQHQURE1qGqKlRV1cIt8CzQVqtVqKoKl8ulfY34I4iAy/BLREREo8JKLhERAXgWbkXlVlEUAGgbTNt9XB+Qq9Vq0/d4PB54vV6GXyIiIhoahlwiomOul3B7lE7hF3i2/LlcLjdVf1tVfkUAJiIiIuoFQy4R0TFlZLg9in4fb+MxAM/C78HBARKJBG7duqUti2b4JSIiol4x5BIRHTOqqqJWq2ndkoHhhdujNDaxEt2b9eG3VqvV7QV2uVxwu91t9/0SERHR8caQS0R0TKiqimKxiFKphFAopAVbKwVDfejW/7fx86qqolqtolKpaJ9j+CUiIiKAIZeIyPH0nZK3t7exubmJW7du9fz3iErqsHQTRPsJvwC08Ov1erXg6/F4GH6JiIgciCGXiMihxFJfWZYB1C8JtqJBQnS78At07vjcqfLLAExERGRPDLlERA4jmknpZ9yKwOZ2ux0Zco/6e7sJv+JrVFVl+CUiIrIxhlwiIgfQB7ZW4VYY9pLjQZh9bL2GX/E9DL9ERETWxpBLRGRjvY4Bcrlc2tdRa92G38bvEXt+GX6JiIhGiyGXiMiG+p1xexyXKxulU/gFni0TL5fLdY+Bs36JiIjMx5BLRGQj/YZbwcpB0srH1slRHZ/bzfpl+CUiIhoOhlwiIhtQVVXrlKyfJdtrIBp0ubIIaMNg15DbTr/hl7N+iYiIBsOQS0RkYfpmUiIEDbLPc5DlygxZxuhn1i/DLxERUfcYcomILKhVuHW73QP/vVaullr52MzQT/gVH5dlGRMTEwy/REREYMglIrIUsYRVlmUAMCzcClburnzcQ2477cIv8Czg7uzsYGNjA4uLi3Wf46xfIiI6rhhyiYgsQDST6jTj1ghWDpJWPjarEjdBXC4XvN4/v6W3mvUrnluGXyIicjqGXCKiEdEHkWGHW8HKI4SoP63+Pbud9av/mnYdnxl+iYjIbhhyiYhMNugYoEFYuVrKINW/XkZIdRN+9Vj5JSIiu2HIJSIyySjDrWDlPbk0Op3CL4Cm8VXiezjrl4iIrIghl4hoyKwQboV+lytXKhWkUilUKhVEIhGMjY1hbGysbh8oOU+/s34ZfomIaJR4dUJENCSqqjZVwEa9xLPX5cqlUgmpVArr6+s4d+4cxsfHUSgUsL29DUmSoKoqwuGwFnoZfo+HQcOvWALN8EtERMPAqxAiIoO1mnE76nDbq0KhgGQyie3tbVy8eBFLS0twuVyoVqt1I41qtRoKhQIkSYIkSdje3kahUECtVmsKvuFwGD6fb4SPioat2/DbqNO+XyIiol4x5BIRGaRVuDVyxq0Z8vk8EokE9vf3MT8/j2vXrmmPoVU48Xg8GB8fx/j4eN3HG8Pvzs4OJElCrVZrWfll+HW2o8KvqqqoVquoVCp1nxeB1+v1MvwSEVHXGHKJiAYkqlOyLAOALcPtwcEB4vE4JEnCwsICbt68OdBjaBd+FUWpC7+7u7t14VeWZaysrDD8HhPtwi/QXcdnr9fbtOeXAZiIiBhyiYj6JJpJmTXjdhj29vYQj8dRqVSwsLCA06dPD31ObyQSQSQSqfu4CL//8z//g3K53BR+Wfk9fnqZ9Ssqwhx3REREAEMuEVFP9BfYdg23qqpie3sb8XgcALCwsIDp6emRPgYRfj0eDxYWFrSPt6r8FgoFyLJcF37D4TAikcixDL9WnXs8LL2EX/33MPwSER0fDLlERF3QjwGKxWKYnJwceTDslaqq2NzcRLVaRTKZxJUrVzA1NTXqw2oi9jMDnSu/xWJRC797e3uQJAmyLCMUCjVVfv1+/ygeimns9Doclm7Db+PnSqUSTp48yfBLROQgDLlERB20mnFbrVYhy7JtLoJVVcXa2hqSySRCoRD8fj9eeOGFnvfcmvF49eNmOnG73VqA1WsMvysrK8c6/FLn8FsoFPD06VPcuXOnriLOWb9ERPbGkEtE1EKrcCsult1ut/YxK1MUBaurq0gmk5iYmMDt27cxPj6O//qv/4KiKJZtjjXI8lujwq/P52OYcTh90yuPx6N9vNWsX/33MPwSEVkfQy4RkY6qqlqn5HYzbt1ut6X3QdZqNWSzWWQyGUxNTeH+/ft1oc/Kxz+soNBL+C0UCqhWqwgGg4hEInV7f/1+P8OMg7RaNdDtrF/xveK/+uDLcUdERKPFkEtEhNYzbtstc7RqJVeWZWQyGWSzWczOzuLBgwcIBoNNX6fvRms1Zh9bp/BbKpW08Lu2tgZJklCpVNoue2aYsZ9ulsYL3YbfRp06PhMR0XAw5BLRsdYq3B61jNdqIbdSqSCdTmNlZQVnz57Fw4cPEQgE2n69y+Wy1PHrWSWAu91uhMNhhMNhzMzMaB9n+HWWXkJuO0eFX1VVUa1WUalU6j4vAq/X62X4JSIyGEMuER1LouoiyzIAdBVuBbfb3bJiY7ZSqYRUKoX19XVcuHABjx8/7mqEjlWCZCtWv8BvF35VVa1b9mx2+LX682ZVRoTcdtqFX/Fz23V8FpVfr9fbtOeX/85ERN1hyCWiY0U0kxpkxq3b7W66MDVToVBAMpnE9vY25ubmsLS0BK+3+9O5lffkAvac++pyuTqG30KhgHw+j/X1dUiShHK5jGAw2BR+A4EAg4yJhhlyO+ll1q/4fei07JmvGSKiegy5ROR4+gvHQcKtMKrlyvl8HolEAvv7+5ifn8fVq1frusJ2i8uVzaMPv9PT09rHxXxWUfnd2NjoO/w66fky26hCbju9hF/99zD8EhHVY8glIsfqNAZoEGaH3IODA8TjcUiShEuXLuHmzZsDjf+xcpC08rEZyeVyIRQKIRQKDRx+qX9WC7ntdBt+9Vj5JaLjjCGXiBxnWOFWMKsSure3h0QigXK5jIWFBZw+fdqQx8DlytbVT/j1eDxwuVzIZDIYGxtDOBxGMBhkkOmCXUJuO/2E31aVX/EasvNzQUSkx5BLRI4x7HArDLOSq6oqdnZ2kEgkoCgKotEopqenDW9SZNUgyYvs1jqF39XVVWxvbwMANjc3IUkSSqUSAoFAU+WX4bee3UNuO53CL1A/61f/Pa0qv+z4TER2xJBLRLanqqrWKfmoGbdGGEbIVVUVW1tbiMfj8Hq9uHz5Mk6ePDmUx8A9uc7hcrng9/sRDAYxNzenfVxVVZTLZa3yu7W1hVQqxfDbwKkht51uZ/2K50X8t7Hqy/BLRFbHkEtEttVqxq0ZS+6MXO6rqirW19eRSCQQCoVw/fp1TE5OGvJ3t2Pl5coMucZwuVwIBoMIBoM4deqU9nGG33rHLeS20234bSTGqQUCAfh8PoZfIrIMhlwisp1W4XaQRky9MqKSqygKVldXkUwmMTExgdu3b2N8fNygI+zM6kHSysdmd53Cb6VSQT6fR6FQwNbWFtLpNIrFIgKBAMLhcF34DYVCjggyDLmdHRV+VVXFBx98gKtXryIYDGqf1y97ZuWXiEaBIZeIbENUE2RZBgDTw60wSMit1WpYXl5GOp3G1NQU7t+/j7GxMYOPsDOrL1em3g36vLlcLgQCAQQCgZbhV1R+d3Z2kMlkUCwW4ff7myq/dgu/DLn90YdfVVXh8/m0Wd2i6VW1WkWlUqn7PrHc2ev11u35HcV5nIicjSGXiCxPNJMyYsatEfoJubIsI5PJIJvNYnZ2Fi+99BJCodCQjrCzfpcrm/G8W73KfNzow+/U1JT2caeEX4bcwSmKUhdSOe6IiKyAIZeILEl/QWSVcCv0EnIrlQrS6TRWVlZw5swZPHz4cOSzTa0cJK18bFY1iuer1/BbKpXg8/la7vkdZRWPIXdwjSG3nW7Dr/5r2nV8tsp7ARFZF0MuEVmKWWOABtFNyC2Xy0gmk1hfX8f58+fx+PFj+Hw+k46wM6svV2bIta9O4bdarWp7fnd3d5HNZlEsFuHz+Vru+TUj/DLkDq7bkNtOr5Vf8fUMv0TUCUMuEVmCHcKt0CnkFotFJJNJbG1tYW5uDktLS9peNauwcndlciYx6mhqaqpl+BWV3729PSwvL6NYLMLr9bZc9mxk+GXINcawRp31uuxZhF/9nl+Px2PZ9xIiGh5rXXkR0bFjp3ArtAqJ+XweyWQSe3t7mJ+fx+LiIjwez4iOsDMrV0utfGxkPBF+/X4/Tp48Wfc5/bLnYYVfhlz76RR+gWeV5XK5XHceaVf5ZcdnIudiyCWikVBVVeuUbOaMWyPol/seHBwgkUggn8/j0qVLuHHjhuU7hXK5MtmBGeGXIdc5up31K/7NxX8ZfomciSGXiEzVasatXcKt4Ha7IcsyfvOb36BcLmNhYQGnT5+2zWOw8nJlhlw6ylHht1AoYH9/HysrKygUCvB6vU17fsPhsPZ7YPWbUlZmh9/VbsNvo04dn4nI+hhyicgUItweHBwgnU7j+vXrtru4VFUVu7u7iMfjqFarmJubw/T0tO0uehgkyYnahV/9nt9cLofV1VUUCgVtr2YgENDGHonwS92xcyX8qPDbbtavPvgy/BJZF0MuEQ2VuEsuy7L2MUmSbHVBoKoqtra2EI/H4fV6EY1G8eGHH2JmZmbUh9YXK4dcKx+bldnp98lsPp8PJ06cwIkTJ+o+Xq1WEYvFoChKU/htXPbM8NvaoJ2Vrahd+AX+3PSqVfgVlV990yvxh4jMx5BLREMhmkk1zrj1eDwtl4ZZkaqqWF9fRyKRQCgUwrVr17QLZTtfuHBPLtGz8BsIBBAMBnH27Fnt49VqFYVCAfl8HgcHB1hdXUWxWITb7dYCrz78WrXBnBmcGHI76afjc6dlz7w5RTQ8DLlEZBj9G31juBU8Ho9lA5agKApWV1eRTCYxMTGB27dvY3x8vOnr7LpUz+12W/ZGA0Nu7/h89a/V77DP58Pk5CQmJyfrPi7CryRJODw8xPr6OgqFAtxud8s9v8ch/B63kNtOt+FX/zWc9Us0XAy5RDSwXsYAdZoxO2q1Wg3Ly8tIp9OYmprC/fv3MTY21vJr9d057YZBkuiZXn6H24VfWZa1Pb/68OtyuVoue3ZS+GXI7azb8FutVpFKpfD8888z/BIZhCGXiPrWz4xbKy5XlmUZmUwG2WwWMzMzeOmllxAKhTp+j1jya8cLvEGWKw/7IosBnMxkxI0qr9d7bMOvXc+Bo9b4PilWCYiO362WPYvwq9/zK5qnMfwSNWPIJaKeiRm3tVqt63ArWOnNuFKpIJ1OY2VlBWfOnMHDhw8RCAS6+l4rV6SPMsgIIfF9w/p3ZMglMw1zNUan8Cv2/ObzeWxsbGjN+Br3/I6NjVk6/HIEkzFqtVrHaq1+3FG5XK47R3LWL1FrDLlE1DUnzLgFgHK5jFQqhbW1NZw/fx6PHz+Gz+fr6e+wc8i1cpC08rGR84xiy4HX68XExAQmJibqPi7Cr6j+bm5uauG3MfhaJfyykmuMWq3W8d+z21m/4vUs/svwS8cZQy4RHcnocDuqEFMsFpFMJrG1tYW5uTksLS3B6+3vNDhINXTUrNxdGWAjJTKPlfbVtwu/tVpNC74i/BYKBaiq2nLZc7/ntH4oimKZ58/Ojgq57XQbfht16vhM5BQMuUTUlgi3Ysaty+Uy5K692ftZJUlCIpHA3t4e5ufnsbi4OHAVxM6VXCsHdF5kkZmsFHLb8Xg8XYXfra0tSJJkavhlJdcYiqIYWpk/Kvy2mvUr3t8ZfskpGHKJqIm4+6sPt0a+yYkxQsO+ODo8PEQ8Hkc+n8elS5dw48YNw36mnUOulZcEW/nYrIrPV//sEHLb6RR+9cueG8Nv49LnQcIvQ64x+q3k9qpd+AX+3PG5MfwCf678tmp6RWRVDLlEpBGdktvNuDWK6LA8rGV1+/v7iMfjKJfLWFhYwOnTpw1/HHYPuYN0Vx5mqGLI7Q8vNvtj55Dbjsfjwfj4eNNs78bwu729rYXfVnt+uzk/M+Qaw6yQ20m34470OlV+nfZ7RfbDkEt0zOnv3vbaKblfwwiIqqpid3cX8XgciqJgYWEBMzMzQ3scdg+5Vg6SVj42cpbj1B24l/BbKBSgKMqR4Zch1xiiu7IVdRt+xdeI3ymGXxo1hlyiY6qfGbdGMXJWrqqq2NraQiKRgMfjQTQaxdTU1NAfh51DLvfkEj1j1d8DM3Ubfnd2diBJEmq1GsLhMCKRCCqVCtxuN6rVas8d6unPrFDJ7VWv4Vd8D8MvmYUhl+iYGWW4FYwIiKqqYn19HYlEAsFgEFevXsWJEycMOsKj2Tnk9lvJNeM1YvUqMzmLE5crG6Vd+FUURQu/a2trKJfL+M1vfqOF38bKL8Pv0Wq1Gvx+/6gPwxD9LHsW4dfr9TL8kmEYcomOCVVVUavVUKvVRhZuhUEquYqiYHV1FalUCpFIBLdv3266CDODncNYv3ty8/k8UqkUfD4fxsbGEIlEEAqFDH0N2fl5JfthyO2d2+1GJBJBJBJBqVSC2+3GhQsX6sKvJEnY3d2tq/wy/LZndHdlK+oUfoFnz0G5XK47/3PWLw2CIZfI4YyecWuEfqqgtVoNKysrSKVSOHnyJO7du4exsbEhHeHR7FzJ7XW5sr5L9fnz51Gr1bC3t4dsNotisQi/36+FXnEBGwwG+3qNMeSSmRhyB6MoirZHVx9+G7+mMfwWCgXIsszw+3/suFzZKN3O+hW/q+K/DL90FIZcIoeyYrgV3G5315VcWZaRzWaRyWQwMzODl156CaFQaMhHeDQ7h9xug+TBwQHi8TgkSUI0GsWdO3dQrVbrgoGqqqhUKnXjSlKpFEqlEoLBYN3FayQSgd/vP/I1yJBLZmHIHUw3jac6hd9isaidO/b29iBJEmRZRigUQiQSqQvBTlnO28pxDrnt9Bt+gWfXDZFIhLN+jzmGXCKHEeFWP+PWal0bxZzcTiqVCjKZDJaXl3HmzBk8fPgQgUDApCM8mt1Dbqdjz+VyiMfjKBaLiEajHUcwuVwuBAIBBAIBTE1NaR9XVRWlUkm7gN3Y2EA8HkelUtEuYPUBWFzAspJLZmLIHcwgz5/b7dZ+//Uaw+/Kykpd+G2s/Doh/DLkdu+o8FsoFPD73/8ed+/erfueTh2fyZkYcokcQtzV1Idbq568O1Vyy+UyUqkU1tbWcP78ebzyyiuWvIixe8htFST184Wj0ShmZ2ebXkPdhlCXy4VQKIRQKITp6Wnt46qqahew+Xy+7gI2HA5DVVV4PB7kcrmuZ3Ued7wp0D+G3MEMYy/pcQy/Vh4hZBf61UU+n0977xDnRzEqsVKp1H2fCL9er1cLvh6Ph+cFB+DVA5HNiU7JIjRaOdwKrSq5xWIRyWQSW1tbmJubw9LSkqUDjp1DbuOe3L29PcTjcVSrVUSj0aHOF3a5XAiHwwiHw5iZmdE+LvbtZbNZFAoFZDIZSJKkzepsrPyy6lHP6r/zVnWc5uQOg6Iopr32egm/hUIB1Wq1Zfj1+XyW+31hJdc4sizXPZftKr9A547PnPVrf9a9giSitsSJuVqtjrxTcj/03ZUlSUIikcDe3h7m5+exuLhoizf7XvYVW42oxu7t7SEWi0GWZVy+fBnT09Mjew2JfXuTk5MIBAJYWFgAUD+rM5/PY3NzE5IkweVyNe33DYfDDCzUE1bBB9PNntxh6xR+9VsmVldXIUkSqtUqgsFgyz2/ozr/HYfuymaRZbnrG+S9zPoV5wp9+M3n8zg4OEA0GjX0MZAxGHKJbMQKM26N4Ha7USgU8MEHH+Dw8BCXLl3CjRs3Rn6x1It+x/BYwf7+PiRJwh//+EdcvnwZp06dssxrqHE5dLtZnbIso1AoIJ/P4/DwEOvr65AkCR6Ppy74jo2NIRQK2eq1RebhcuXBWCHktuN2u9uuGtGH37W1tbrw22rZ87BfI6zkGqeXkNtOt+H3P/7jP/CLX/wC3/ve9wb6eTQcDLlENiBOqpIkac2X7BhugWcBa3l5GeVyGdeuXcOdO3ds+TjstlxZVVXs7u4iFotpe5Zefvllyz333e759Xq9mJiYwMTERN3Hq9VqXbfW5eVlFItFbbav/o/RM37JfhhyB2PlkNtOu/Cr7xegD7+iWd4wwy/35BrHiJDbTuN1Vy6Xw+Tk5FB+Fg2OIZfIwlRVRa1WQ61WQz6fx0cffYQHDx7Y7qJMBKxEIgFZlnHq1CkAwJkzZ0Z8ZP2zS8hVVRU7OzuIxWLweDy4cuUKJicn8ctf/tKyr6NBlpD6fD6cOHECJ06cqPv7qtUq8vk8JEnCzs4OMpkMisUiAoFA04zfQCBg2eeGjMWQOxg7htx22vULEOFXrBwRq0bK5TJCoZDWM0D8t9/wy9ehMRr35A5TLpere68ha2HIJbKgVjNuvV4varWard4IVVXF1tYWEokE3G43otEopqamsLGxgd3d3VEf3kAamzdZjaqq2N7eRiwWg9frxeLiIk6ePAng2YWpVQP6MF7fLpcLfr8fU1NTTWOOyuVy3Zgj/cVr455fKzasocEw5A7GSSG3HX34bewU3zgmLZFIoFwut1z23O7mmZXfR+yoVquZNm4wl8vh9OnTpvws6h1DLpGFtAq34o8IuXagqqr2hh8IBHD16tW6u53dzMm1OqtWcsWNhXg8Dr/fj2vXrjXdaR50Fu0wg4GZc3JdLheCwSCCwaC2ugD488WrqPzq9+yJ8Kuv/Pp8PlOOl4zHkDuY4xBy2+k0Jq0x/IqbZ63CrxhdQ8YY5nLlRrlcDouLi6b8LOodQy6RBYhwq59x2/imp+9IbFWKomBtbQ3JZBKRSAQ3b95s2jMJ2LszsWC1kKuqKjY3NxGPxxEIBHD9+vW2e4UGuagfdiAwM+R2OgZx8drYsEa/Z293dxeSJKFWq7Ucc2TlEVj0DEPuYI5zyG2nn/AryzJ+//vfd1X5pc7MDLkHBwfck2thfAcmGiFFUVCr1erCbbs3NStc/LdTq9WwsrKCVCqFkydP4t69e03jHPRYyTWOqJrH43GEw+G2Nxbswsqv806jSsR+PUmSsL29DUmSoKpqyzFHRu8Xs+rzZRcMEv3jnOHutQu/xWIRv/3tbzE7OwtJkrQxaaVSCcFgsG7P79jYGILBIF+zHdRqNVNDLvfkWhdDLpHJ9C3oRTXTrp2SZVlGNptFJpPBzMwMXnrpJYRCoSO/zw5V6aOMOuSqqor19XXE43GMjY3h1q1btg63enYLbWLGbyQSqft4rVbTqjaiclMoFOrCsvgz6IxfO54/yP7YFXhwiqLA5/Ph1KlTTdsm9D0Dtra2kEqlUCqVtIZ5+j8Mv8+Y2Xhqf3+fIdfCGHKJTCLCbbVa7XvGrZjNOuqLimq1inQ6jeXlZZw5cwYPHz7sqdHDqAOiEUb1GFRVxdraGhKJBCKRCO7cudM0Q9bOnHSR5vF4Wo45EuPA8vk8crkcVldXUSgU4PV6W874ddJzQs7C5d6Dazcjt1PPAIbf9sxeriwaOpL1MOQSDZmqqlAUBbIs9x1uBVEBHVXILZfLSKVSWFtbw7lz5/DKK6/A7/f3/PdwT27vxH7nRCKBiYkJ3L17t6ly6ARWXq5sFK/Xi8nJyaa9XJVKpW6/rxhz5Pf7m/b7HrcLV7Iuvg4H0+t7eqfwW6lUkM/nUSgUsLW1hXQ6XTcq7TicQ8xuPMWQa10MuURDYmS4FUTINbuba7FYRDKZxNbWFi5cuIClpaWB3kS4J7d7iqJgdXUVyWQSk5OTuHfvniHhVoRJq13kHIeQ247f74ff76+7aBIXrqLyq6/aiE6tYrRYuVzue0YnEY1Gu0pur1wuFwKBAAKBQMvwK26gbW9vI51Oo1Qqwe/3a3t9xR+7rx4xa5+4qqooFApdbdGi0WDIJTKYqqpaMylxsW7Unluz97JKkoRkMond3V1cvHgRi4uLhrwZO6GSK5aOD4uiKFhZWUEymcTJkydx//79js28emXVkEv19BeujTN+RadWMeLoww8/RKVSQSgUaqr89rPigoiGT1GUoe4h7XQO0YffnZ2dutUjjZVfO4RfM2+QivfPUW8fo/YYcokM0mnGrVHMmpV7eHiIRCKBg4M6A57IAAAgAElEQVQDXLp0CdevXzf0RO6USu4w3lAVRcHy8jJSqRSmpqbw4osvIhwOG/5zrFoxtepxWY2+U2ulUsHY2BgWFhagqqo25iifz2NlZQWSJEGW5bqKjQjBx3nMEV9ng+HzZwyjKrm96jX8lkol+Hw+S4dfM3uWiNU0Vnns1Oz4vrsRGcSMcCsMu5K7v7+PRCKBYrGIhYUF3L59eyiPwwlvCkYvV67Valq4nZ6e7rpTdb9EJbrXi6vjMCfXzlwuF8LhMMLhcNOM30KhULfnN5/PN405En9GcdFN9mKFJohOMKqQ206n8FutVrU9v7u7u8hmsygWi1r41Y87CoVCpr8+zNyPu7+/zxm5FseQS9QnEW71M26HfUIfRshVVRW7u7tIJBKQZRnRaBQzMzOOCKLDZFTIrdVqyGazSKfTmJmZwYMHD0zZ4zOsSvSgGHKHo9OYI/2MXzGj0+VytZzx66RQw+X6g2HINYbVQm47LpcLfr8fU1NTLcOv/gaaCL/6jvH6yu+wXjdmN53i+CBrY8gl6pGiKNqeW8DcGbcej0f7uYNSVRXb29uIx+Nwu92IRqOYmpoy9aLPzheZg4Zc/Yzh2dlZvPzyywgGgwYeYWcMk84xyL+jx+PB+Ph40xgqMeZIkiQcHh5ibW0NhUIBHo+nbrnzsC9ah8msBjVOxZBrjFqtZuttAyL8NjbNA+o7xu/t7WF5eXmo4dfM55KVXOuz728VkYnEjFuxLBkwN9wKRlRyVVXFxsYGEokEAoEAFhcXR9IC3+6Nj/o9blmWkclkkM1mcfr06Z5nDBtl2I2z+sXw3R+jf4/ajTkSFZt8Pl930dq4Vy8SiVh+v5qdzz9WwJBrjGE3nhols8OvLMumPZes5FofQy5RByLcVqtVw8YADWKQkCvmrCaTSUQiEdy8eRMTExMGH2H3RIdlO18k9RLGZFlGOp1GNpvFmTNnRhZuBS5Xpn74fD6cOHGi7uJOv1dPNKoRI0rEfE595TcQCFgiXPJ1NhiGXGPYZbmykTqFX9E7YH9/HysrKygUClr41e/5bbV9wuzlyqzkWhtDLlELw5hxa4R+Qm6tVsPKygpSqRROnjyJu3fvGjJndVBO6LDcjWq1inQ6jeXlZZw9exavvPKKJca5WDVMWvW4qL1Oe/XK5bJWsdnY2IAkSSiXywiFQk2VX7N/L1jJHQyXexvjOIbcdkT4bayQ6vf86sOv2D4h/oiPmeHg4IAh1+IYcol0rBpuBY/Hg0ql0tXX6vd8zszMDL1bb6+cMiu3nWq1ilQqhZWVFZw7d84y4Vaw6nJlgBU2p3C5XAgGgwgGgzh16pT2cf2YI/2c32q12nLGr8/nG8rxMeQOhpVcYzDkHq3VChKgPvzmcjns7OygWq1ia2uradmz0Y3zcrncSLZ6UfcYconw7GJHNJMSF9hWCreC1+tFsVjs+DX6yuFzzz1nekOjbjmlktt4oVepVJBOp7GysoLz58/j8ePHQ7tIH0S/y5XNGCFEztZpzJF+xu/u7i4kSUKtVmvZ6XnQZYkMuYNRFIXPnwEYcvvXGH6TyST8fj9mZ2e1rvEHBwdYXV1FsViE2+2uC72RSAShUKiv5z+Xy+HSpUtGPyQyEEMuHWtmzrg1QqflyuVyGalUCmtra5asHDZyQiVXHxQrlQqSySTW1tZw4cIFy4ZbwarLgq16XDR8+gvQ2dlZ7eNizJGo2Gxvb0OSpLoZv6L6Gw6Hu75gZcgdDCu5xrB7bworkWUZ4XAYPp+vbeM8cS45PDzE+vo6CoUC3G43wuFwU+W307mEe3KtjyGXjiW7hVuhVcgtlUpIJpPY3NzEhQsXsLS0ZItxBE6o5LrdbhSLRaysrGB9fd1Wz79Vlysz5FKjTmOO2l2wNlZ+W3VoZcgdDEOuMZzcXdlsRzWeahd+G0emiXOJfl741tYWVFXFrVu3EIlEel6urCgKvvrVr+LnP/85XC4Xvva1r+GNN95o+bVf+cpX8M477yCdTuP999/H3bt3tc89ffoUX/ziF7G9vY3JyUn84Ac/wI0bNwAAP//5z/H3f//32ra7v/u7v8MXv/jFro/Raax/JUZkoFYzbu30Jq0PuZIkIZlMYnd3FxcvXsTS0pKt3ijtXsktlUqoVCp47733cPHiRTx+/NgW4Vawapi06nGR9Xi9XkxMTDR1iRfVmnw+j1wuh9XV1boOrSL42uncb0UMucbgcmXj9Ntdud3INH34/fDDD/GjH/0IqVRKa3j1L//yL1heXsb169dx9epVhMPhtj/jrbfewscff4w//elPyOVyuHfvHj75yU9qAVXvs5/9LL7xjW9gaWmp6XOvv/46vvzlL+PJkyf40Y9+hCdPnuDdd9+Fqqr427/9W/znf/4nbt++jVQqhatXr+LTn/500w3C48I+V2REAxB3tUY549YIHo8H5XIZH374IQ4ODnDp0iVcv37dlhcadq3k6ivnbrcbL774oiW6VffKqiOEqHf8d6zXrlqjn825s7ODg4MDSJKEd999t6lJjdVn/FoBQ64xGHKNY/QIIX34ff311/H6668DAPb29vCZz3wG165dw4cffoh//dd/xR/+8Ae43W5cv34dN27cwF/8xV/gr/7qr7S/6+2338aXvvQleDweTE1N4XOf+xx++MMf4pvf/GbTz/3EJz7R8ng2Nzfx3nvv4Re/+AUA4DOf+QzeeOMNxGIxRKNRuFwu7O/vA3jW/fnUqVMjHVU4agy55Fhixq0Twi3wbP/Hn/70JxwcHGBubg63b9+27WMBnoUsO4XcYrGIZDKJra0trXL+m9/8xrb/Blyu7Cx2fR2aqXE25+HhIRKJBK5evarN+N3a2kIqlUKpVEIwGGya8ev3+/lc/x+GXOPwNWUMs24YnDx5ErlcDl/60pfqOj4fHh7iD3/4Az7++GMtbAqZTAYXL17U/n9+fh6//vWve/q52WwWZ86c0YK8y+XC3NwcMpkMLl++jLfffhuf/vSnMTY2hr29PfzkJz+xdG+WYWPIJccR4bZarSKZTCIcDmN2dtaWbyKqqmJvbw/xeByyLOPChQuoVCo4c+bMqA9tYP3M/B2FQqGAZDKJnZ0dzM/PY3FxUXsTtVtQ17NqmLTqcZHziD25gUAAgUCgacxRqVTSOj2LMUeVSqVpzFEkErF0k7lhYcglqzG6ktuOqqrI5/N1y4AfPXqEp0+f1n3dV77yFQDA+++/P/RjkmUZ3/zmN/GTn/wEn/jEJ/Duu+/i1VdfxW9/+1tMT08P/edbEUMuOUarGbeyLKNSqdgu4Kqqiu3tbcTjcbjdbiwsLODUqVOQZRnJZHLUh2cIq+/JLRQKSCQS2N3dxfz8PK5du9Z0QWfnkGvV5cp2+10l++rUeMrlciEUCiEUCtVdICqKglKppFV+V1ZWIEmS1tW1sfJrp336vWLIHZxd3z+syuyl3/rX/69+9auOXzs3N4d0Oo1Hjx4BAFKpFObm5nr6eRcuXMDa2poW5lVVRSaTwdzcHD744AOsrq5qS51feuklnD9/Hu+//z7+8i//ssdH5gzOPfvSsdEq3IplyT6fT2syZQeqqmJjYwOJRAKBQACLi4t13fvsUv3shlX35EqShEQigb29PSwsLHTc82zVJb/dsHLF1KrHRc7ST3dlMWqkscGMoihHjjnS/3HCHkxFURwd4s3AzsrGM+NGaalU6nmv62uvvYbvfOc7eO2115DL5fD222/jpz/9aU9/x+zsLO7fv4+33noLT548wY9//GOcP38ely9fxsbGBtbW1vD73/8e165dQywWQzwex+LiYk8/w0l4diLbUlVV65QsLoob99x6PB6USqVRHWLXFEXB2toakskkIpEIbt682dQxFLBu9a0fbrfbUjcg8vk8EomENuD9xo0bR1Yp7FzJtWpAt3L4JmcxcoSQ2+1GJBJpakInZvyKyu/m5iYkSaobTSKqv+Fw2FaVUVZyB8emU8ZRFMW0lUBiRm4vP+8LX/gC3n33XVy5cgUulwtf//rXcevWLQDAO++8g3feeQff/e53ATzroPyzn/0M6+vr+NSnPoXx8XHEYjEAwJtvvoknT57gW9/6FiYmJvD9738fAHD69Gn88z//M/76r/9auzb5p3/6p56rxU7CkEu208uMW6/Xa6kg1UhRFCwvLyOVSuHEiRO4e/euLTv19sPj8aBSqYz6MJDP5xGPx3FwcIBoNIqbN292feFm95BrxTBp1eMi5zFjTm6nGb/6uZxra2soFArweDx1y53HxsZazvi1As4ZHhxDrnHMfC5zuVxdw6lueDwefPvb3275uVdffRWvvvqq9v9vvvlm279ncXGx7dLoz3/+8/j85z/f03E5GUMu2UYv4Vbwer2WXN4ryzKy2SwymQymp6fx4osvdpyvpidCgN0vLka9J/fw8BDxeBz5fB4LCwt9dau2c2Xdysdu1eMiZxnlebTdXM5qtapVfff29rC8vIxCoQC/319X9bXCmCNWcgfHkGscs5pOAc/G87RabUfWwpBLlqcoirYsGXgW8rp9Y7VaJbdarSKTySCbzeK5557Dyy+/jGAw2NPfIfbl2n0v1Kj25B4cHCAej6NQKCAajeL06dN9XyjavZJrxWO3+80bsg9VVS0X0nw+H06ePFnXi0FV1boZv/oxR4FAoKnTs1ljjhhyB8eQaxwzQ+7+/n7TDSqyHntfJZOjiWZSg8y4tUrIrVQqSKVSWF1dxblz5/DKK6/0PbvM4/GYejIfFrMDYi6XQzweR7FYHDjcCnYPuVasmDLk9s6K/452YJcVMfoxR1NTU9rHVVVFuVzWxhyJpoXlchmhUKip8mv0vEyG3MHVajU+hwaRZdnSy5XJfPa+SibHETNuBw23ggiEo1IqlZBMJrG5uYkLFy5gaWlp4HDqlA7LZj2O/f19xONxlMtlRKNRQ2cm2znkWnm5MvXODmHNauz++ne5XAgGgwgGg00zfovFolb51Y85apzxOzY21veMX4bcwbG7snHMXOG2v7/PkGsDDLlkCSLcVqvVpjFAgxjVnlz9jNWLFy9iaWnJsDcyp4TcYQfEvb09xONxVKtVRKNRzMzMGB4E7Bxy+63kGvF7SWQFZnZjNZPL5dLGHM3MzGgfVxRFC7/5fB67u7uQJAm1Wq1lp+ejAgND7uC4XNk4Zu/J1W8pIGtiyKWR6jTj1ghmL1c+PDxEIpHAwcEBLl261HHGar+cEnKH9Tj29vYQi8VQq9UQjUYxPT09tAtZu4dcJ7yOiAbhxJDbjtvt1oLs7Oys9nEx5kg/4zefzwNA3XLnsbExhMNhLZQx5A6OIdc4ZobcXC6H8+fPm/KzqH8MuTQSww63glkhJJfLIZFIoFAo4NKlS7h169bQ3vydEnKN7q68u7uLWCwGVVURjUZx6tSpoV/AWrV5Uzf6Xa4syzJ2d3cxNjaGQCBwrEICOYtd9uQOW6cxR2LG7+HhIdbX11EoFLSwLDpAu91uy445sjqGXOOYXcll4ynrY8glU6mqqnVKFhfYdl7+uLu7i0QigWq1ioWFBUP3e7Zj1bFIvTKiu7Kqqlq4BYDLly9jamrKtNeT2+22RGOzfvS6XFmWZa0zeCQSQalUQqVSQTAY1Co94r/97vEjMhNDbmderxcTExNNo1Kq1SokScLHH3+MfD6P7e1tFItFeL3epspvKBTic9xBrVYzvCHYcVWr1RAIBEz5WblcjsuVbYAhl0zRz4xbo4hqrlF3mVVVxfb2NhKJBACYVjUUWMl99m+ws7ODWCwGj8eDK1eu1HUdNYudmzd1W4XWz3R+7rnn8PDhQ+37RYMbMdczm81CkiQoitLU2XVsbIyVHrIUhtz++Hw+nDhxAj6fD9FoVAsWYsxRPp/Hzs4OMpkMisUiAoFA055frgJ5ht2VjWP2cmU2nrI+hlwaqlbh1uwTutiXO+jdUlVVtRENgUAAzz///Eju5I26Y7RR+qnkihsMsVgMXq8Xi4uLI72bauc9uUcF9Fqthkwmg0wmg9OnT+Phw4cIBALazE6gvsFN4/eKZY75fL5umaO+6huJRBAMBnmxSyPBkDuYxjnDfr8ffr+/5YxfcSNsa2sLyWQS5XIZwWCw6UaYWTN+rYLdlY1jdshlJdf6GHJpKBRF0ZYlAxhJuBUGDbmKomB9fR2JRAJjY2O4efNm0/ItMzmpktttQFRVFVtbW4jH4/D7/bh27Zol7qLaOeS2W65cq9WQzWaRTqcxOzurhdtetNvjV61WtYtdfaWn8WLXrtXxUTpOwcAojSGNetNNd2r9jN/GMUelUkmr/K6trUGSJFQqFYTD4abKr1O3QHBPrnFYyaVGDLlkKNFMyogZt0bpt8OyoihYWVlBMpnEiRMncPfuXUQikSEcYW88Ho9WSbOzbl4Xqqpic3MT8XgcgUAA169ft1SzB7uHXP2xK4qCbDaLVCqF2dlZvPzyywgGg4b+TJ/Ph5MnTzZVesrlslb1XVtbQ7VaxS9/+UvtYldUfcfGxnhB2AJvCvSHldzBDLINyOVyIRQKIRQKYXp6uu7vbDfjNxwON834NSvUDAtDrnFkWTbluVRVFYeHhyMtdlB37H12IEsQM26tFm6FXiufsixjeXkZ6XQa09PTePHFF5uWY46SUyq5nYil4fF4HOFweOTV83bsHHLFcmVFUbC8vIxUKoXp6emhhNtOXC4XgsEggsGgdrGby+Xw4MGDukrP9vY2JEkCUD/WJBKJsLMr9YVLRQczjEq4fsyRnqIo2pgj/flAVdWWM37t8u/KkGucWq1m2k0PVVX572YDDLnUN7PGAA2q20putVpFJpPB8vIyTp8+bfrFfrecFnL11RRVVbG+vo54PI6xsTHcunXLkuFWsHPIVVUV+Xwe//3f/41Tp07hpZdeQigUGvVhacT+3UgkgtOnT2sfl2VZq/LkcjmsrKygWCzC5/M1VX3Z3IaOwteHPbQ7H+j3/0uShM3NTUiSBJfL1dT8LhwOW+5mGEOuccxarlytVh27fN5pGHKpZ3YJt8JRIbdSqSCVSmF1dRXnzp3Do0ePLN3S30khV78vdG1tDYlEApFIBHfu3Gnaz2lFdgy5iqJgdXUVsVgMbrfbcisVgM7jjbxeLyYnJ+uWrYvmNqLKs7m5iXw+j3K5jFAoxBFH1BKXK9tfpxm/+pthq6urKBQK2pgj/Z9RrgRhyDWOWXvsc7kcJiYmeO6wAYZc6prdwq3QrhtxqVRCMpnE5uYmLly4gKWlJVvs73HKnFzgWUgUS8MnJiYss++5W92O4bECRVG0GwknTpzA4uIiNjY2LBdwgd5n+Oqb2+hHSYkRRyL8thpxpA+/Vqvy0HAx5PbP6vvAW90MA+qb3+3t7WF5eRmFQgF+v7/pfGBG53cjxxseZ2a+Htl0yj6sf0VPI6eqqtYpWZxI7BBuhcZKbqFQQCKRwO7uLubm5rC0tGSrO6lOqOSKamKxWMTOzg7u37/ftAfLDuxQyVVVFWtra4jH45icnNSe6/39/b4vDIb9u99ryO3094gRRzMzM9rHG5c4bmxstBxxJKo8djnXUW8Ycvtn1+euXfM7sRJEjDlKpVIolUpa53d9ADZyzBErucYwc399LpezVANMao8hl9pqNePWTuFW8Hq9WvfWRCKBXC6H+fl5XL9+3ZZ3UO08J1ffsfrkyZOIRCJYXFy0ZDWxG1YOufr9zePj47h3715dlXyQIKm/2TUMwz7HdDPiaHd3VxtxFAgE6vb6igtdsje7BjUrcFIFstNKEHHtIG6GJRIJbRtEqxm/veIYK2OY1VkZAPb39xlybYIhl5q0Crd2PglXKhWsrq5ifX0dCwsLuHnzpq0fjx0rufoOvlNTU9o+0HfffdeyIbEbokOxlYjO1LFYDJFIpO0ScKsvtR7F83rUiCNJkrR5ntVqtW7EkVNGmhwnDBj9c1LIbadV53egfhtE45gjfQ8A8Yc9AIaPM3KpFb4bk0ZRFG1ZMgDbh9vd3V0kEgkUCgWEQiG8+OKLjrhrb6eQW6vVtD23rTr42umxtGKlSq6YKRyLxRAOh49s3mXFgC4YtVzZCO0udMU8TzHft3HEkb7TsxmNbZxwbjMbK7n9O843CNptg9CfE8RqENEDQNwQYw+A4TA75LKSaw8MuaQ1k1pdXUWtVsO5c+ds+8avqiq2t7eRSCQAANFoFC6XC9ls1raPqZEdgmGtVkM2m0U6ncbMzAwePHjQchyTlUJiP6xw/KqqYmtrC7FYDKFQqOuxS1YKko2sfGyCfp5npxFHoqurfsSR+C9HHI0WQ27/FEXhc9eg3Yxf0QNAv+dX3BCTZVkbmSfGHHGPbu/MXK7MSq59MOQeU6qq1i1LBv58IrbjG5eoYsXjcfj9fjz//PPaksODgwPLh8JeWLkCJ8systksMpkMZmdnj5w1bIfA3skoQ64+3AaDQdy8ebOnmcJcrjwc7bq6VioVrcKztbWFZDLZNOJIhN9elzcyrPXHyq9/qzsOy5WN0q4HQLFYxAcffIBQKITDw0Osr69rDfAaq76jHHNkB7VazdRK7vPPP2/Kz6LBMOQeM53GAPl8Pts1NFIUBevr60gkEhgbG8ONGzeaLi6PmpNLg5NlGZlMBtlsFqdPn8bDhw8RCASO/D4rVEIHMYrjF6sVYrEY/H5/y9d8Nwa5WTLsSqsTA5vf78fU1FTHEUcrKyvI5/Pa8kZ91ZcVnuFw4mvNDAy5xvD7/Th79mzdx6rVqlb13d/fx/LyMorFIrxeb9N+X3Z/f8bM5coHBwd1fRvIuhhyj4luZtz6fD5Uq9VRHWJPRJfeVCqFycnJjvNVnRhyRcgY9ZubLMtIp9PIZrM4c+ZM1+FWcLvdtq7kmvn8q6qKnZ0dxGIxeL1eXLt2baAlU1ZeEmzlYzNSPyOO9Ht9xUUu9ccK51C7YsgdXLvxQT6fDydOnGg6v+tXg+zs7NR1f2+s/B63rRBsPEWtMOQ6XDfhVrBDGBR7PTOZDE6dOoUXXnjhyPEzdnhcvRLLfEfVybVarSKdTmN5eRlnz57FK6+80tf4BI/HY+tKLmDOsloRbt1uNxYXFw25i2zl5crHJeS202nEkaj66kcciREoqqpqF7lGzvJ0Kobc/jHkDq7XGbntVoOUy2Wt8ruxsQFJklAul7UZv41jjpz4mpdluePWKCMx5NoHQ65DqaqqdUrWz7TsdHLzer2WreRWq1VkMhksLy9jdna2bSOjVuy+JLaVUYXcarWKVCqFlZUVnDt3ru9wK9h9T+6w7e7uIhaLAQCuXLlSd3EzqH6XK5t1gXScQ247rSo8qqoikUigWq1CVdW6EUdivy9HHLV2nDsED4ohd3C9htxW9N3fT506pX1cVVWUSiXtpljjeaGx8mv3MUdGPJfdYsi1D77bOUyrGbdHhVvBintyK5UKUqkUVldXcfbsWTx69GigUOUUHo8Hsiz3tDR4EJVKBel0GisrKzh//jweP35syJuiE25ADCP07e3tIRaLQVEUXL58ue7ixShWrpY6sdIwLC6XC16vF36/HxcuXNA+3jjOpN2II9HR9TgGFlZy+8eQO7hhBjOXy4VQKIRQKNRy9Jmo/C4vLyOfz6NWq9X1AbDbTTGz9+Qy5NqDPV691BVZlrXKbT8zbq20rLdUKiGZTGJzc9OQUCXClFPelM2qgFYqFSSTSaytreHChQuGhVvB4/FYdvVAL4y6WN7f38fTp09Rq9W0yu2wLsK5XNk5Wj1X7caZyLKs7fdtNeJIv+fX6fv6GHL756T301Gp1WqmP4ftzguKotT1ARA3xVRVrQu9Vm2CZ1bIVVUVBwcHnJNrEwy5DiIudPo9aVrhwrJQKCCZTGJnZwdzc3NYWloy5GQqKp9OqQIPO+SWy2WkUimsr6/jwoULWFpaGsobiBMqueIxDPI6zeVyePr0KarVKi5fvozp6emhX3xb4fe9HSsfm1V1+3rxer2YmJhoGjfVOOIolUqhVCppSxv1nZ7tvrRRYMjtH0Pu4AZ93zCS2+3Wbm7p1Wo1reorSRI2NzchSRJcLlfTft9Rrggxs5Jbq9Uccw50OoZcBzEiMIjqjtknqnw+j0QigVwuh/n5eVy7ds3QYxBVaobczvQV9Lm5OTx+/HiobxxO2JM7SMjN5XKIxWIol8u4cuWKKeFWsPLFvZWPzal6GXFUq9Wagq8VqztHURSFr7U+MeQOzsx9pP3yeDwtb4rJsqydF/QrQrxeb1Pl14wxR2aFXFmWLf9vRn/GkEt1xL5cs8JgLpdDIpGAJElYWFjAzZs3h/LG6fV6bR+m9Ix+PPpwe/HiRcMq6EdxUiW3FwcHB4jFYiiVSrh8+TJmZmZsdbFtRqWVldzRO2rEkbjIFdUd/YgjMy9w+8XXWP9YBR/cKCckDMrr9WJycrJp2W6lUtGqvnt7e8hmsygWi/D7/U2V32AwaNhryKwbBgcHB5iYmOBr3ybs+dtFLRnxS2dWxXNvbw/xeByVSgXRaBSzs7NDPWlYab+xEYyqgBaLRSSTSWxtbWF+ft60cCvYfU4u0FvIPTw8RCwWQ6FQwOXLl4f+urcrLle2tm5GHOkvcMUcT32nZ6uMMrHCMdiRlZba2lWtVjOteaRZ/H4//H5/3Zg7VVXrwq9+O4QYc6Sv/PZzbjAr5LKzsr0w5FIdn883tEZAqqpiZ2cH8XgcABCNRnHq1ClTLjIYcuvp9z7Pz89jcXFxJBcsTpiT200Dp3w+j1gshnw+j8uXL+P06dO8uO6AIdee2o04EnM88/k81tfXkc/n60Yc6Ss8Zla2WI3sn6Iotq1CWoUdlisbQczxDgQCTdshxJgjMeNXFD/05wb9jN+jfs6w5XK5pqXbZF08QzmIkZVcI6mqis3NTSQSCfh8Pjz//PN1d/nMIBpPOUW/IbdQKCCRSGB3dxeXLl0yfO9zr5y0J7eVfD6PeDyOw8NDRKNR3LlzhxfVXe4cCKwAACAASURBVGDIdY52czz1o0zy+Tx2dna0bq76i1ux33cY5ynOye0f9+QObhTdla2k3ZijVr0AJEmCLMsIh8NNI9Dcbrdp76us5NoLQy7VMbKSqygK1tfXkUgkMDY2huvXr4+s7brT9uT2OnpHkiQkEgns7e1hYWEB169ft8Sbq1P35EqShHg8joODAywsLOD27duWDbesZtEo6EeZzM7Oah8X3Vzz+TwODw+xtramNbRprPoOuqePr/3+MeQOjku+W2vXC0CMORKV393dXUiShFqtBlmW8fTp07obZMN4bhly7YUhl+oYUclVFAUrKytIpVKYnJzE3bt3m9rSm82Jy5WLxeKRX6fvWn3p0iXcuHHDUhcmTqvkFgoFxONx7O/vD7WRmlFExdRqF/qs5B5f7bq5thtxFAwG6/b69jLiyIqvfbtgyB3ccVmubJR2Y47y+Tw+/vhjjI+P1zXCE2OOjFwVksvlOCPXRhhyHcSo5cr9VnJrtRqy2SwymQympqbwwgsvIBwOD3xMRvB6vSiXy6M+DMMcFQ7FMtmDgwNEo1HLhi2nVHJLpRJ+97vfYXd3FwsLC5a7mdCO2+22ZJhkyKVG7UYclUol5PP5pmWNjUsaW1V2GHL7x5A7OIZcY6iqikAggOeee67u47Iso1AoaKtC1tfXIUkSPB5P0/khFAp19Xre399nJddGGHIdZtCLQ5/P11WFUE+WZaTTaSwvL2N2dhYPHjxAMBjs+xiG4bjsyT08PEQ8Hkc+n7f8MlnA/t2Vi8Uicrkcdnd3ceXKFcssA+/WIOeLYQYEhtzeHNewpt/T17isUSxpbDXiSFzc2vncM2oMuYNjyDVGuxm5Xq+35aoQ0QVejDlaXl5GsViEz+erq/yK8Ks/t+ZyOSwsLHR9bIqi4Ktf/Sp+/vOfw+Vy4Wtf+xreeOONll/7la98Be+88w7S6TTef/993L17t6vPPX36FF/84hexvb2NyclJ/OAHP8CNGze6PkYnY8ilOr1UciuVCtLpNFZWVnD27Fk8evTItPm6vXLicmX9BdrBwQHi8TgKhQKi0ahtuvfatbtyqVRCIpHA9vY2AoEALl682HQX2Q666Qzd7vuIrMrtdncccSQubsvlMn7961/XjTgaZIzJccKQOziGXGP0Om+4XRf4arWqbYnY2dlBJpPBv//7v+Pf/u3fcPnyZVy9ehXZbBbz8/Nd31h866238PHHH+NPf/oTcrkc7t27h09+8pMtQ+hnP/tZfOMb38DS0lJPn3v99dfx5S9/GU+ePMGPfvQjPHnyBO+++27Xz4eTMeQ6jBGV3KPCYKlUQiqVwsbGBs6fP4/Hjx93vQdqVJzYeKpWqyGXyyEej6NYLNoq3Ap2W64swu3W1hYuXbqEq1ev4o9//OOoD6tvXK5Mx0njxe329jYePnwIWZa1Jc9ijIkVRhxZGUPu4I57d2WjyLI88M0Cl8vVckvEvXv38NnPfhYffPABfve73+Hp06d4//338Y//+I+Yn5/HzZs3cePGDdy8eRM3b96sa6IHAG+//Ta+9KUvwePxYGpqCp/73Ofwwx/+EN/85jebjuETn/hE2+Nr97nNzU289957+MUvfgEA+MxnPoM33ngDsVgMly9f7uepcBSeralOp4qnmK26vb2Nixcv4vHjx7Z5w3daJbdYLGJ/fx8fffQRotEoZmdnbRVuBbscc7lcRiKRwObmZtNcYbsFdT2rhkmrHhc5j9vt1mZ4dhpxtLu7i3w+D1VVm6q+wxpxZGUMuYPjCCtjtFuubAS3242FhQUsLCzg05/+ND7++GP8wz/8Ax48eIBUKoWPPvoIv/vd7/C9730PH330Eebm5vDOO+9o35/JZHDx4kXt/+fn5/HrX//asOPLZrM4c+aM9vhdLhfm5uaQyWQYcsGQSw1ajRASHXr39/ctMVu1H04JuXt7e4jH4yiXy/D5fHj06JFtgqIdlctlJJNJbGxs4OLFi1haWmq6Y2z3kGvFY2fIJbO0O39aYcSRlTHkGsOprw8zDTPkNhIjhET4/Zu/+Rs8ffpU+/zy8rI28/f999835ZioPYZchxn0hKkPg2KfpyRJthiH0ondR9Xs7e0hFouhVqshGo1icnIS/+///T/HvEFarXFOpVJBMpnE+vo65ubmOq5asHPItepyZQCWPS463jqNOBLht9WIIxF+exlxZGVWO2fbDc9vxpFl2bRmp7lcDidPntT+/1e/+lXHr5+bm0M6ncajR48AAKlUCnNzc4Ydz4ULF7C2tqYFfVVVkclkDP0ZdsaQS3XEqJ333nsPlUoFCwsLttvn2YpdK7m7u7uIxWJQVRXRaBSnTp3Sqm92fDytiJBohQYclUoFqVQKa2truHDhQldL8q1aDe2GVSumdj/f0PHj9/vh9/vrLoD1I44kSaobcRQOh+vm+7YacWRlVjln2xUr4cYxq4GXqqpaJbdbr732Gr7zne/gtddeQy6Xw9tvv42f/vSnhh3T7Ows7t+/j7feegtPnjzBj3/8Y5w/f55Llf8PQ67D9HtxqKoqdnZ2tIYbFy9exPT0tGMuNu00qkZVVS3culwuRKNRTE1N1f1bWLkC1ysrhNxqtYpUKoWVlZWuw61g538LqwZ0q4Zvol50GnEk5nd2GnE0NjaGcDhsyfdhRVEseVx2wc7KxjFzubIsyz1NEfnCF76Ad999F1euXIHL5cLXv/513Lp1CwDwzjvv4J133sF3v/tdAM+6JP/sZz/D+vo6PvWpT2F8fByxWOzIz7355pt48uQJvvWtb2FiYgLf//73DX7U9sWQe8ypqorNzU0kEgn4fD5cuXIF//u//+uogAvYozIkbjTEYjF4PB5cuXKlrsufU4kbEKNYwletVrUxWOfOneurU7jb7e567JbVWDWgM+SSk7ndbq2Kqye6PDfO7/T7/ZYbccRK5GDYWdk4ZoXcfl7zHo8H3/72t1t+7tVXX8Wrr76q/f+bb77Z9u/p9LnFxcUjl00fVwy5DtPtm56qqlhbW0MymUQ4HMb169cxOTkJ4M9Le52wb0hPVK2s9saiqiq2t7cRi8Xg8/mwuLhYt+StHREE7BDgOxnFrFxZlpFOp7G8vIyzZ8/ilVde6fv1buc9uf2GSbu/5pzGCecBevbe22p+Z6VS0cKvGHFUqVQQDofr9vqaOeLIiu+ldjLq1UtOYlbIPTg4wPj4OM+1NsKQe8woioLV1VUkk0lMTEzg9u3bGB8fr/sar9eLarXquJArZuVa5Y1ZVVVsbW0hHo/D7/fj2rVrPe31EBVQu4xxasfMpeSyLCOTySCTyeDs2bN49OhRT0uPWjmOIXfYrHpc5Bx2eX25XC7LjjjixX7/uFzZOGZdB+VyOa0YRPZg76tj6lqtVkM2m0Umk8HU1BReeOEFhMPhll/r8/kc09RIzyoVarFEPB6PIxgM1lXReyFCu91DrhmVXFmWtdf/c889h1deeWXgcCvYOeRa9dgZcok662fEUWP4dfKII6tjyDWOLMumPJcMufZj76tjatL4hiUqV9lsFrOzs3jw4MGRrdZFJddpRt1hWVVVbalZOBzGzZs3m8ZQ9MLuY5GEYVZya7WaVrl97rnnDKncNrJqUOyGVcOkVY+LnMOpS7y7GXG0s7ODdDqtjThqXPJs9DmSmjHkGkdVVVNW6PXaWZlGjyHXoSqVitZQp9dlmU6t5Ho8npE8LlVVsb6+jng8jrGxMdy6dWugcCs4JeQOo5IrVi6k02nMzs7i4cOHCAQChv4MwaodirvRT5gU+5kLhQLGx8e1C2MjL9gYcmnYzLowtopOI45E+G014khf/RW/4/zdHBxDrjHMfC2ykms/DLkOo6oq/vCHP2BjYwPnz5/vq1vsqCuew2L24xLNvRKJBCKRCO7cudO0/3kQowrtRjMyrCuKgmw2i1QqhdnZWbz88stDHxJv90put8euv3Fw+vRpTE5OQpIkbG9vI5/Pw+VyadUg8WeQ5ZC8kKZhcmoltxf6EUfT09Pax/UjjiRJwtbWFiRJ0n7Hw+EwVFWFJEkIhULH6maBUazUH8TOzLxZwEqu/TDkOozb7cbk5CQuX77c915Nn8/n2OXKZlQ+FUXRwu3ExATu3r3bNCrCCE6p5BoREhVFwfLyMlKpFKanp00Jt4KdQ243I4QURcHKygqSySRmZmbw8OFDbUuD/iJNjD8RTXAymQyKxSKCwWBd8B0bGzvyxhsruTRsDLntdRpxJEkScrkcFEXBH//4RxSLRfh8vrqqrxVGHFkduysbw+yQy0quvTDkOtDZs2cHukD0er0ol8sGHpE1DLuSq+9cPTk5ifv372NsbGxoP89JIbffx6EPYKdOncJLL72EUChk8BF2ZueQ2ylMipUI8XgcJ0+erHtuWz3eduNPSqWSFn6z2SwkSYKiKHUXxJFIpK4ixJBLw8aQ2zuv14vJyUmEQiFsbGzg/v37LUccJRIJlMtlhEKhuptbkUjE9o0SjcLlysYwa3wQ8GyE0Llz50z5WWQMnm2oic/nQz6fH/VhGG5YIVcftE6ePDn0cCs4JeT2sydX3FBIJBKYmprCiy++2LZb+LB1Uw21qlbLlUWDtFgshvHx8YFez/rlkDMzM9rH9R1gc7kcVlZW6ipCYilfpVJhExwaCobc/imKoj137UYcqaqKQqFQN+JIf4NLv9d3bGzs2C3drdVqI5/04ARmhtz9/X3cvHnTlJ9FxmDIdaBBqyBO3ZPr8XhQqVQM+/v0S2RHEbScEnJ7qeTql4KfOHFipOFWsHMlVx/QVVXF9vY2nj59imAwaPgecr1WHWD1FaHV1VXk83l88MEHqFarWhMc8SccDrMKosPA1jt9UKPeKIpyZCh1uVwdRxxJknSsRxyxkmsMM0Mu9+TaD0MuNXFqyPV6vSgWiwP/PbVaDcvLy0in0yNbIguYt8d42Dwez5F7wPVLZ81YCt4LO4dccUNsd3cXT58+hdvtxo0bN0ay70hfEapUKigUCohGo3VNcPL5PDY2NiBJUt1FsfgTCAQce1FMxrLr6gsr6CbktjPIiCPxXyes7mDINUatVjN1uTJDrr0w5DrQoBd5Tm48NUh413eXnZmZ6Wrm8DB1Ew7toFMlVz9+aXx8HPfu3RtKE69B2DnklstlrK2twe/348qVK5iamhr1IQGoX43SrgmO/qJ4a2sLyWQS5XK55egT7gOkVnhDpD+DhNx2uhlxtLa2hnw+f+SIIztgd2VjyLLM7srUFt/5qYmTK7n9PC5ZlpHNZpHJZEwbS9MNj8djSGV61FrtydXvC41EIkPrUG0EO4bcw8NDPH36FAcHB5iensaNGzcsd8F/VKWt3UVxsVjUqr47Ozt14430ld9QKGS5x0zm4RLv/g0j5LbSz4gj/e/42NiYZUccsbuyMcxuPMWQay8MuQ7ESm5rvc6VlWUZmUwG2WwWp0+fxsOHDxEIBIZ4hL1xyp5c/eMQ4TYejyMcDg91X6hR7BRyJUnC06dPkc/nceXKFS0gWu1iv9/jcblcCIfDCIfDdfsAxeiTfD6Pvb09ZLNZbbxR45JnNoM5HlRVtWT4sQOzQm47R404yufz2N/fx/LyMgqFAvx+f1PVd9RbG7hc2RiyLJtSdFBVlZVcG2LIpSZ2umjvRbeVXFmWkU6nsby8jOeee85y4VZwSsgVy5U3NzcRi8UQCoVw+/Zty4dboVWHYqspFouIxWLY399HNBrFnTt34HK5kE6nLblqw+gRQmL0iX6vceNSyJWVFeTz+brxRuK/4XCYgchhWMnt36hDbjvtfs8bRxxJklQ34kj/+27WTS6GXGOYWckVrxmyD4bc/8/emwdJkpZnno+7h8eZkZH3UVl5VB51Zd1U15VFi5aQGKHZRgu0odlZFluJY5lhgIE11lZmO2ZrhslsZxBrrGBlDMxoRssItSTEqAfQjEDqFqKppmm66IPurowz48iIzMi43eN092//yPKoiMzIzLjDPfL7mbW1VV7h6Rnu/j3f+77PQzmQflsEHGXUVCqVyuL2xIkTuH37tqYNLvpB5BJCkE6nsb29DUmScOHChX2GJFpHyxFChUIBbrcbOzs7OHXqFFZXV6sWp1rNo+3GcR3UCinLcrkVstL9VY032muA00/3yONEvz3fuolWRW4tDos4UkcbRFHcl+Hd6YgjKnLbQ7fOI71f6BMqcvuQdlyIqiDsJ8OWgyq5pVIJPp8PoVAIMzMzuHPnjqbFrYqeRa4aV+NyucAwTDmPVa9o7eFXLBbh9XoRiUQwPz+PtbW1mgsBrQr0Xp5PjuNgt9urOglqVYPcbve+eCN1QUwXr9qHLlqbR08i9yAqRxsq2bvJFYlEIIoiOI7bV/VtZa6fitz20K1KriAIGBgYoPcMndE/CobSVgwGA0qlUl+J3L0uvsViERsbGwiFQjh58iTW1tZ0NY+nR5FLCEEsFoPL5YLBYMC5c+fAcRzeeuutXh9aS2hFKEqSVN6wmZ2dxdra2qHXsJZbrbVyToGDq0F7DXC2t7chimLVzKC6IO7nzE89QnNym6cfRO5B1NrkAnY3w9XrPBaLwe/375vrbyTiqJ/PYTfplshNJpM9idajtEb/KBhKmXY8uHme1+SsXiuo50WtcoXD4bIQ0JO4VdFbTq4qblmWxZkzZ8qmR9lsVrNCSy/Isgy/3w+/348TJ07gzp07db2nj3O7cjs4yABHXRALgoCdnR34fD7k8/nyDGCl+G3HAo1WJRuHnrPmOY7njud5DA8PNxRxtNfpeW/l9ridw07QLZGbSqV0N0pFoSKXcgBqJbefKBQKkCQJP/7xjzE3N4e7d+/qulKtl0puPB6H0+kEwzA1s1gPy8nVC6oo6/aiRVEUBAIB+Hw+TE5ONjxHruV2ZS0eV70ctCCujDeKx+MQBAGEkCrhS+ONuoOe31+9hlYhdzkq4kgVvzs7O+UoM1X4yrIMURQ1G3GkF7o1VkedlfWJflf4lI7ST5XcfD4Pr9eL7e1tcByHmzdv9oVDntZFbiKRgMvlgqIoWF5ermrzrKRWTq7eUB3JuzVjpSgKNjc34fF4MDo62nR2s1bFpFaPqxXqiTeqjD0xmUz7xK8eO060DN1IaA4qcg+nssNjcnKy/HH1Ws9kMiCE4MGDB8jlcuB5fl/Lc68jjvSCLMtdeS+mUinarqxDqMjtQ9plPKV3kVspbufn53H37l28+OKLvT6stqHVqKdkMgmn0wlZlsuV28Pek/1Qye2WyCWEIBKJwOVyYWhoCNevX99nnNIIWp7JPS4cFHtSKBTKVd9QKARRFCFJ0r5c31b+/scZmpPbPIqi6LoLqleo17rVakUoFMK1a9fKpnbqRtf29ja8Xm/PI470RDc2A2glV5/Qu1Sf0molhOd53bYr53I5eL1eRKNRLCws4O7du2Xx0Q/iXaukUik4nU6USiWsrKxgdHS0roePVltmG6HTGw6EEESjUTidTthsNly9enXfHGgzNHufYBimowuLfqzkNgLDMDCbzTCbzXXFGymKAqvVikKhUBa/NN7ocI7jXGm7oJXc1qisPlaa2lWO8hwWcaQ6ulfmeB9Hp+ZumsdRkatPqMil1ESPM7nZbBZerxexWAwLCws4c+bMvhu/3sya6qHXi7VUKgWXy4VisYjl5WWMjY01dDz9sNDsVEVUdaN2Op0wGo24ePFiW80vtLrBcNxF7kEc5Pz64MEDcBwHhmGwtbUFj8eDYrFY0+jqOC6Ga9Hr+6aeoSK3NeqJD6on4kiNM+tExJEe6JbpFLC7zpmenu7Ka1HaBxW5fUqri0SDwYBsNtvGI+oc2WwWHo8H8Xgcp06dwrlz5w58APdbJVedy+1F61g6nYbL5UI+n8fy8jLGx8f7+oF6GJ2o5CYSCayvr4NlWZw7d64ju8habVemIrcx1AXu1NRU+WOKolQZXUWj0XK80d6W5+MYb0QjhJqHitzWaGW0pdGII3W2v/Kab8ScUMt0M2s4lUrh3LlzXXktSvugIpdSEz0YT4miCI/Hg0QigcXFRZw/f/7IBy8Vua2TyWTgcrmQzWaxvLyMiYmJtiwW9VxZaWdFVG37liSp3PbdKaiY7F9UMWuz2arMb0qlUnn+LxaLYWNjoyreqHIx3M9zl3q+3/QaKnJboxPi7CBH98rZ/nA4DFEUUSqVqiKO1PuE3q73blZy0+k0NZ7SIfp6R1O6hpbblQVBgMfjQSqVwuLiIlZXV+t+4HIc11cit5vt14IgwOVyQRAELC8vY3Jysm2LxG67E7ebdlRyBUGA0+lELpfrWmWctisfP3iex9DQUFVngJr3qS6GA4FAVbxRpfDtl8gTKnKbh4rc1uhWBfKg2f5aEUeiKAJAWfDq4XrvtsilM7n6g4rcPqXVh7cWK7mCIMDtdiOTyWBxcREXLlxo+Obbr5XcTlJ53peWlnD58uW2Lw5Vh+XjKHKz2SxcLhfS6XTbNw+OolJMRlJ5/CKcgZCXMDdqwfkpO0x8b/4eVOQ2RquCrTLvc3x8vPxxNctTEASkUimEQiHkcjkYjUbdt0DS91fzUJHbGr1+1h0VcSSKYtX1rtWIo26K3GQySUWuDqEil1ITLVVyM5kM3G43BEHA0tISLl261PTNVUu/VzvopMgVRRFutxvpdBqLi4stnfej0HtWbjMiN5/Pw+VyIR6PY2lpqalNm1ZRZ3J3hAL+7kEUJp6FycDhtVAa6ZyEx1fqc8juxHFREdJ7OI7D4OBgldmZGnlS2QIpCEJVvFHl/7Uqhmglt3lo/FJrdCvbtVEOijOrjDiKRqM1I47Ua76bEUeSJHVtsyCdTle1glP0ARW5fUo/VHLT6TTcbjey2SyWlpbaUuEyGAzI5XJtOsLe0wmRm81m4Xa7kUwmm66YN4res3IbEbmFQgEejwfb29s4depUXbPknUJtV/buZMEyDIatu9U4M29GIJFFKufAkLU3uYxU5GqTysiTynlxtQVSFb+q66vBYNhX9dVCFQjoD2f3XiDLMj13LdDrSm4jHBVxpIrfYDDY9YijbvqRpFIpKnJ1CBW5lJr0UnSkUim43W7kcrm2iVsV2q58MJUu1Y3OOrfKcajklkoleL1ehMNhzM3NVeU39wq1YirJCjj20TXGACAAlB4JTbqA1h+VLZCVqFVfURTLVaC98UbqYrib1wOtRjYPPXetoWf/CZXKiKO9Iw57I46y2ew+V/d2RBx1q11ZFfRms7njr0VpL1Tk9imtLhLV7+9mS1cymYTb7UahUOiY8U6/GU+14/fJ5XJwu91lcduLymInIni6yWHHL0kSNjY2EAgEMDs7i7W1Nc24WKrtyvOjVriiInIlGSaOxY5QxKjViCFLb6q4tF25fzAajRgZGdlXBdprfCMIAhiG2Zfr26msT9qu3Dx0Jrc1ZFnW3Qx7vdQTcRSPxw+MOLLZbDAajXVdm5IkdUV4qvcK+p7XH9pYaVE0iVpd6/SOYyKRgNvtRqlUwtLSUkddZbvpRtwNWqnk5vN5uN1uxGKxnrfNdsNAq5PUypuVZRl+vx9+vx/T09O4c+eO5hY2arvyCYcZt06N4NVQCslSCdMOM67PD4FleyMCqMjtbxiGKc/xTUxMlD8uSVLNhbDZbN5X9W119k9RFM1sNukNKnJbQ0/tyu3iqIgjURSrIo72RprVijjqViU3l8t1bLON0lnoHZ5yIDzPo1QqdexmnEgk4HK5IMsylpaWMDY21vGbCG1X3hW3Ho8HOzs7WFhYwLlz53q+YOmnmVxFURAMBuH1ejExMYFbt27BZDL1+Ahro4pJhmFwenIAi2NWyAqpy1W5k9cqXUwcTwwGw5HxRqFQCIIgQFGUqvbHRuNOaCW3eajIbY3jKHJrcVjEUS6XK1/zsVgMoijuizQrFApdeR8mk0makatTqMjtU9rx8O6UIIzH43C5XCCEYGlpCaOj3XNwPc7typWGRwsLCzhz5oxmHrT9MJMryzJCoRDcbjdGRkZw48YNWCyWXh/aoeytmBo4FgZtvCVoJbdB+lWw1RNvlE6nsbm5iWw2C57nq4TvQfFGVOQ2DxW5raFVd2WtoM7v2my2QyOOUqkU0un0vkgzm80Gs9nctus7lUpRkatTqMilHEg743YIIWVxyzAMlpaWMDIy0vVFRj9WcguFwqFfUygU4PV6sbW1hfn5eU0YHu1Fz5VcQghEUUQsFsPY2BiuX78Oq9Xa68Oqi1ZmoVUR2olrmLYrU46i3ngjtf1RdXxV/1MUhYrcJqEbBK1BK7nNsTfiKJPJ4Pz58+A4bp+5nRpxtDfWrJkxB5qRq1+oyO1T2vEAakeMECEEsVgMLpcLHMdhZWWlyoCk2+h99nMvh80YF4tFeL1eRCIRzM3NacrwaC96rOQSQhCNRuFyuaAoCk6cOIGzZ8/2+rAaQqtiUqvHpVXoudql3nij7e1tJJNJcByHWCxWJX61Em+kdeg5ap5+cFfWAupMLs/zNc3tKiOO1DEHWZarcn3riTiilVz9os0VL6UttLpQbKWSSwjBzs4OXC4XeJ7HmTNnNJEx1m8P5lqivVgswufzIRwOa87N9yD05q4ci8XgdDphMBiwurqKVCrVtq6HbqJVMdlv1ymlt9SKN3K5XDCbzbDZbBAEAdFoFD6fD/l8vire6CDTGwqlWWgltz0cdh5biTjieR6JRALnzp2DwWBAKpVqqJKrKAo+9alP4Xvf+x4YhsGnP/1pfOITn6j5tZ/85CfxzDPPYGNjA/fv38eVK1eO/Fw+n8dv/dZv4Y033oDFYsHExAT+8A//EMvLy3Uf43GB3rUpB9JMJVetbrndbhiNRpw7d05zbR6VZjt6p3Imt1QqwefzIRQK6Ubcquilwp5MJuF0OqEoStXGTSaT0ZVIV9GqyAVodZLSWQghMBqNNR1fa5neAKhpdNUPzxFKd6Eitz00k9d8WMSRWvV1u9343d/9XYRCIYyNjWFytZh4dwAAIABJREFUchIWiwXf//73ceHCBUxNTR163X/jG9/AG2+8gfX1daRSKVy9ehVPPPEEVldX933t+9//fnzuc5/D3bt3G/rcRz/6Ufz6r/86GIbBl7/8ZXz4wx/Gc88919C5OA7oYwVM6QmNVHIJIdje3obb7YbZbMb58+c1296hCsNWIyi0AMdxKJVKcLlcCAaDOHnyJNbW1nT3u7Esq+lKaDqdhtPpRLFYxMrKyj6zNL1VottBJwWylsU3pT84aKOzsgK0N95IXQQnEgkEAoFyvNFe8au3+28jHLf7XCegIrd12v184Hm+7Ox+8uRJPP/881AUBV6vF1/+8pexvb2NP/7jP8Zrr72GnZ0drKys4OLFi7h48SIuXbqEmzdvln/W008/jY985CPgOA4jIyP4wAc+gG9+85v4/Oc/v+91H3/88QOP6aDPmc1mvPvd7y7/+9atW/jCF77Qwm/fv1CR28e0ulDkeR75fP7QryGEYGtrC263G1arFRcuXKgyAtEi6hyr3hcikiQhFAohkUhgaGhIl+JWheO4I99rvUAQBLhcLoiiiOXlZUxMTNRcGB9HkdtJqMilNAMhBKmcBIYBHJbD74WNdvPsNb1Rf4aa81kr3mjv3F8/OOoSQqhAaxHqrtw63dgoYFkWS0tLsNlseN/73ocPfehDAHbXXk6nE6+99hpef/113L9/v0rk+v1+zM/Pl/+9sLCAF154oWPH+aUvfQnvec97Ovbz9QwVuZQDOcyJmBCCSCQCt9uNgYEBXLp0aV/7h1bRu8OyJEnY2NhAMBjE+Pg4bDYbVlZWen1YLaE1d+VsNgu3241kMomlpSVMT08fuiCmIrf9UJFLaQSxIOHv1mMIJnIAgPlRK96xMgqrsfZCuB3uygflfFbO/WUyGYTD4ap4o0rxazQaddXyTF2pW6eZNltKNbIsd20ca6/x1Nvf/nY4nc6qr/mzP/szAMD9+/e7ckwqv/d7vweXy4W//du/7err6gUqcvuYVh9EPM/vayElhCAcDsPj8WBgYACXL1/WjbhV0avIlSQJgUAAfr8fU1NTuH37NgDgxRdf7PGRtY5W3JXz+Tw8Hg92dnawuLiI1dXVuhYjDMNo4vj7BbqIpjTKT3xJBBI5nHCYAQDenSwGTBweXx6t+fWd9GU4aO6vMt5I7YCqjDeqjDvRarWUZuRStIAkSV27RtLpdNXc/r179w79+rm5OWxsbJTXaD6fD3Nzc20/ri984Qv4y7/8S/zgBz/QTWxht6Eil3IglWJQUZSyuHU4HLhy5UqVU6WeqDRr0gOyLMPv91eJW6PRCGD376KlCmiz9LqSWywW4fF4sLW1hYWFBZw9e7ahhRzLsrquPDa64O+0CKUit3GO8zmTFAJXNIuJARPYh+dhfMAIVzSLty/VzmPvhfmg0WjcF3WiKEqV0VU0GoUoimVH6Mqqr9ls7vnfmYrc1ugX08teo8YHdYNGc3KfeuopfO1rX8NTTz2FVCqFp59+Gt/5znfaekxf/OIX8c1vfhM/+MEPNGfuqiWoyO1j2lHJLRaLCAaD8Hq9cDgcuHbtGmw2W5uOsDfopZIryzICgQA2NjYwOTmJW7duwWQyVX1Nv1QQe1XJVR2pNzc3MTs7i7t37za1O6znduW9buPZooyNWBYFScbMkAXjdtMRP4FC6S0cA1iMLEqyAqNhV4AVZQIrzx74HNSK2FCjS2w2GyYnJ8sfL5VK5ZiTWCyGjY0NTcQbUZHbGtR0qj10U+Sm0+mGhOQHP/hB/PSnP8XKygoYhsFnPvMZXLx4EQDwzDPP4JlnnsHXv/51AMDHPvYxfPe730UkEsG73vUu2O12uFyuQz8XDAbx2c9+FouLi3jiiScAACaTCT/5yU/a/JvrHypyKTVRFAVbW1vIZDJIJpN429ve1jftEKrxlFZRFAWBQAA+nw8TExO4efMmzGZzza/VwiKtHXRbJEqSBL/fj0AggBMnTuDOnTstmXbpWeRWVqFTuRK+9XIIiWwJDMOAYRi869w4zp/QtpnccUfPXQTtgGEYXJt14Nn1HeQlBYQAuZKMXzs3duD3aEXkViIpBP54DpmChGELj5PDQzXjjVSXZ7/fD0EQQAjZJ3ytVmtHfj8qcluDitz20G2RW3kdHgXHcfjKV75S83NPPvkknnzyyfK/v/rVrx74cw763MmTJ4/9Pb9eqMilVKEoCoLBIHw+H0ZGRsDzPC5cuNDrw2orWq3kVp77sbGxQ8XtXrS4YGuEbuXkKooCv9+PjY2Nfa3fraBnkVvpZPzzQBKpvIS5kd0NLbEg4e+dO1ieGChXyCgULXJ+agBWI4cHEQEMA5ybsmNuxHLo92jpnikpBH/9i204oyJYAATAhN2IiQEjzDyHs5MDGLebyvFG4+Pjj773YbyRKIpIJpMIBoPIZrMwmUxVwlc1umoFKnJbgzort4duzeQSQiAIgu47GI8rVOT2MY08wGVZRjAYxMbGBkZHR/HYY4/BYrHg2Wef7eAR9oZG8n+7gaIoCIVC8Hq9Vee+XlSB2M2WtXbTaZFYeY4b3UCoB72LXPXYw6kC7KZH7yObyYBEtgShIGHE8GhxnM1m4fF4YDAYyotoi8WiKdFAOV4wDINTo1acGq2v40hrG4P+eA7OqIjZITNYhoE3lsV3X4/i0gk7bCYOr4QyeN+VKUw79t+36ok3CofDEAQBkiTty/VtJN6IitzWUBSFVnLbQDfXPAzD0Pe8TtHvqpjSFirnPsfHx3Hjxo2qxb9qCNRPN2WO45DL5Xp9GFAUBZubm/B4PBgZGWlY3Kr0g8jtVCVXdQN3u90YGhpq+hwfhZ5FbmW78uywBS944+WM0Uy+BKuRg928+94qFApwu93Y2dnB3NwcCCFIJBIIBALI5/Mwm80YGBgAb7YiJfMwma2YG7ViwKTf9yalP9GayE3mSuAYBizDQFIIfPEcbEYWA2YDpgZN2M4U8HIghd+oIXJrcVC8kaIo5XZnQRAQiUQgimLVhtVh8UZU5LZGv62neoUkSW3dqD6IfD6/zwuFoh/oyqOPOewBXhlHc9jcJ8/zXbVq7wa9nsmtdKoeGhrC9evXW5p37larbydpt0gkhGB7exsulws2m63jhml6FrmV7cqXTzrg2RHhT2TBgIGBZfDuC5OAImPd7UI4HC67T8uyXJWZSQhBPp9HMJrEX7yyhbiQR7EkwcQB71wawOKkA3a7HQMDAzCZTJoSGJTjh9byXkesPBSFQFYISjJBSVLAsQys/K6gtPAcEtnWO5BYlq0r3sjj8aBYLO4zupIkiYrcFqAitz10ayY3mUzC4XBo6l5BqR8qco8ZlYY7Bzn2VqLOr/bTTlavZnIrq4rtdKruB5Hbrt+BEIKdnR24XC6YTCZcunSpKznOenG53hEKEAoyxgaM5epq5bEPmA34wPWTCCRyKMkKJgZ4pKJh/PhNP2ZmZrC2tlZeWOz9ezEMA4vFAmc6A6NtENdOTAAAopkC3HkJKwYDdnZ24PP5UCgUarrE0sUfpVscVclVCMFrmxn8PJCGQgguzwzi8slBcGxnFruzwxasTg/gFxHh4esDIxYD7GYDCCGIZ4tYWxw54qc0Tz3xRjs7O0ilUiCEoFgsVl2/Wog30gNU5LaHboncVCpFI3p0DBW5xwRJkrCxsYFgMIipqakjxa0Kz/Oaml9tB90WuYQQRCIRuN1u2O32tlcVe12ZbgftEInxeBxOpxMsy+LcuXNdfTBpvZIrKwQ/eHMbLwdSYAAYOBb/6PwELswMVlVyAcBoYHFq1IJQKITXX/ZifHy8IYOuQDKHYcsjp+qxASOCKYKxyROwGncXd4QQZLPZfdmgHMeVF82KoqBQKNRsmaRQWuUokftKMI3/9mYUwxYeDMPgb96KoigruHWqfpfVRuBYBu88N47VE4NI5yX86tkxvOhLIpgsACBYHLXh8snuupzXijcKh8PIZDKYmJiAIAiIxWLw+/3I5XLlcYXK//Q8RtMJqMhtD906j+l0GoODNF1Ar9C7Tx/DMAxKpVJZ3J44caJhN1mtOhG3AsdxXfmdCCHY2tqCy+XCwMAArly5goGBgba/Tj9UclsRMalUCk6nE5Ik4fTp01WViG6hdZHrjor46UYSs0NmGDgWYkHCf/3FFuZHrVUzuZXvWYfD0dQM85TdhI14DpaHgjaVlzBi5WHmH7U4MgxzaDaoIAiQZRmvvPIKSqUSrFZredFst9sbMso5LtCNgMY4SuS+5E9h1GYsG7EZWAYv+VN4bH6oY9VclmEwM2TGzMN/n5kcQFQogmcZjA1oY7OHEAKDwYChoaGqjUR1XEG9fgOBAERRhKIo+4yuLBbLsb1+qbtye+h2uzJFn1CR28cQQvDSSy9hbGwMd+7caSo6QGtOxO2g05VPVSi43W7YbDZcvny5oy2z/SBygcYX6ZlMBi6XC7lcDisrKxgbG+vZInBvNVRrBOJZmAwsDNzu4spmMiCWLWE7UygfeywWw/r6Osxmc0sbMrdODSOUKsCf2DV3M3Asnjw7DraOvw3P8xgeHsbw8DACgQCuX78OAFVV362tLYiiCJ7naxrlUCj1cJTILUkKzPyjShHHMpBkgm5e5TzH4kSdRlPd4iDjKXVcwWKxVMUbybJcNrpKpVIIhULI5XIwGo37xO9xuH6pu3J7oO3KlHqgIrePYRgGt2/fbulnqMZT/USnqtOq2ZHb7YbFYunaPGi/iFygPsdTURThcrmQyWSwvLyMycnJnlc4GIbp+TEchsPKoyQ/qjQrCgEhBDYjh6gk4fXXXwfHcW1p854cNOGDN2awEc9BJgSzQ2aM2JpfvLIsW14EV1IsFpHJZKriUWRZPpZVIy1vsGiVo+41F2cG8bwnjpmHIjOSzuPanAOGDlVx9UKj7socx2FwcLCq5VOd6a0Vb1TZtaHO6vfT9av3JAStQEUupR7oldbntNpG2Y+V3HaLQkIIotEoXC4XzGYzLly40NUZjm61X3ca9b160C53LpeD2+1GPB7H0tISLl26pGlhqSXOTtnx8kYS/ocV3WxJwekxIzbdb0AQBCwvL2N+fr6h86lWgGt9j91swIUTrW3wHFUdNxqNGB0dxejoaPljlfEo6XS6qmq0t+rL8/yBP5tyPDjs/X5zYQgFScFroTQIgMsnB/H2pe6PQmgNRVFaFhcMw8BkMsFkMu27fmt1bajxRpUbWHp1aJdlua+MPHtFt6KsUqkUhoc7M4dP6TxU5FIOhed5iKLY68NoK+1qLa108jUajVhdXe3J7Ea/VHLV32OvyC0UCvB4PIhGozh16hTOnz+vyZ19LVfTBkwG/A83ZvGLzTTCSRGsuAN7bgvTp1fAMIwmIxKauU5rxaMQQlAoFMoL51AoBEEQoCjKPuFrsVg0dx4oneGoSq7RwOKdZ8fw9uUREEKqWpePM50UF4d1baibV9FoFF6vF4VCoVz1VcWvzWbTfJWUGk+1j27cq1OpFObn5zv+OpTOoO27AaVlWr0J9KPxFHB4Feoo1PlFl8sFg8HQdSffvfRbJVelWCzC6/UiEolgfn4ea2trml4ctPKe6gZGVsFQKYp8JoJTp07h5MnLYFkW29vbmjTNatdmFMMwMJvNMJvNGBsbK39cnRXMZDJIJBIIBALI5/MwmUzlPF+9LJwpjVPvtWoyaG9DrZd0q4JWidFohNForKqoEUKq4o1isVh5Q35v1VdLm1dU5LZONzOuqbuyvqFPbsqh9GOEEPCoatjo4lUVtyzL4syZM5poY+E4DoVCodeH0TIsy0KWZUiSBJ/Ph2AwiNnZ2apsVi1zVLt1r6iMD5udncXdu3erjlHrplmd4qBZwUqHWL/fD0HYzS3dW/WluaD6ppsL5X6iFyK3FgzDwGq1wmq1YmJiovxxSZLKVV9182pvvJEqgHsxskDdlVunW/O4AG1X1jvaXzlSekq/VnLV36veG6WawcowDFZWVnoSU3MQ/ZCTC+yKxEAggK2tLUxPT2NtbU1Xc5NaE7mKoiAYDMLr9WJqagp37typeT4rI4S0RC/E90EOsZIkVVWMNjY2UCgUYLFY9pnkaOXvTzkcLXddaBmtiNyDMBgMcDgcVaND6uaVKn4rRxYqW50HBgY6Hk+mpWeEXum2yKXGU/qFitw+px3tyv1Yya1XvCcSCTidThBCsLy8XGWSoRX0PpOrirFkMgme53Hr1i1dGnNopSJKCEE4HIbb7cbIyAhu3rwJs/ngGBKtHPdetHRcB+WCqu2SmUwG0WgUoihWzRWqbc9GozYyTimUVtG6yK1F5eZVrZEF9RoOh8PIZrNV8WSq+G3XNUzblVunm+eQVnL1DRW5lEPpxwgh4Og51kQiAZfLBVmWy5VbrS5S9SpyFUXB5uYmPB5P2SV3bm5OlwIXaN3JvFVUIzSn0wmr1Ypr167BZrMd+X0Mw/T1TG6nOKhdslQqlau+29vb8Hg8KBaLHY1GoVXJ5jjsnMkKwS/CGbwZETBoNuDqrANTg/q8N7WTfmrzPireSBTFcuZ9qVTadw1brdaGxRYVua1DK7mUeqEit8+hxlO1OajFN5VKwel0olQqYWVlBaOjo5p/oOtN5BJCEIlE4Ha7MTg4iOvXr8NqteL111/X1e8BAEJBAggwYDb0VOQmEgmsr6+D47i6XL5jQhHemAiOZUBk7TpDa/W4DoPneQwPD1ft/h8UjVJZMVL/MxqbzxSm1M9R763vvxXFj1wJWI0sijLBy4EUfvv2LKYdB3dFHAcIIX0t0uqJNxJFEdvb2/s6N9TNq8Pm9anIbZ1uiVxCCARBqHLrp+gLKnIph6L1akqz7BXvqVQKLpcLxWIRy8vLGBsb07y4VdGLyFXzhNVK45UrV6qiInpdCW2EXFHGf3k1jFdCaRACXJoZxIzS/YpoJpOB0+lEoVDA6dOn62qnX98S8J9eDKAkKSAMIOcy+KfXbZhu8LU7fX3o5fqrh8OiUVThGw6HIQgCJEmqcoa12+2wWCy6axHVM+m8hJ94k5gZMoHnds97KJXHi74k3nN5qsdH137iYhE/2UhiK13A4pgN1+ccsBprC7F+quQ2wkHXcGXnRjQahc/nQz6frzmvr26uU5HbGt2s5Pb7pk6/Q0Uu5UjUdsZ+WmSp7crpdBoulwv5fB7Ly8sYHx/X3QNcDxFCsVgM6+vrMBqNuHjxYk1Lfr2IdQD4wVtR/MyfxMkhCwDgfiCFMCvh8mp3RG42m4XL5UI6ncbKygomJibqet/KCsF/eTUCM8+WK1K/8KXxvDeNyyudPurG6NcNtkqMRiNGRkaqjOwURak5J2g0GvdVffVkzKY1DrteskUZMiFlgQsAFgOLRK7//CnSeQn/7l4A6ZwEm5HD+raI9S0B//PtWXDs/nPUb2uBVqnVubE33igej5dd2tVoPHVeX0vxRnqhWxsFxWKR3mN1DhW5fU47bp7qXG4/tdHJsgyfzwcAWF5erlskaBEti0PVuAsAzp49e6iBg14quYQQvOxPYtJuhuHhInhq0ARnQEZR6uzfoVAowOPxIBqNYnFxERcuXGhowZkryoiJBcwOW8ofc5g5bKaKnTjcljgOIrcWLMvCbrdXtcipc4KZTGafO+zAwADy+TyMRmPZXEev9zKtMDZgxIjViB2hiLEBI2SFIJWX8fjKwNHfrDPeCGeQykmYe3hPGLby8May2IjnsDhm3ff1VOQezWHxRvfu3YPZbEYikUAwGEQ2m4XJZKIbWA3QrUpuKpWCw+Gg91MdQ0Uu5UjU1t5+ELmCIMDlciGRSGB4eBiXL1/W/Q1MiyI3nU7D6XSiWCzi9OnTdRl3qTm5WodhGJgMLCTlkQCTFAITxwKkMyJdkiR4vV5sbm5ifn4ea2trTe1km3kWRUnB370VhYFjMTNkQaEg4+zE8Z4z1DqVc4K13GGdTicEQcCbb76JfD5ftWi22+3lVklKfRhYBu+9MoU/vx9GIJkDCHB5xo5rs4fPuusRsSij8s7MMAxYhkGuWPteTEVu83AcB5ZlMTMzU/4YIQSFQqFc9Q2FQhBFcd/YQjfijfSCJEmHJga0C2o6pX/oU6/PaVclV+8xQoIgwO12I5PJYGlpCWNjY8hms7oXuIC2KqDqJoIoilhZWWmo/ZvjuIZ+j3SuhB+8FcUb4QxGbEa88+w4Tk92p9Ly9uVR/NWrYUgPjzeZLeHKlBFoc+VRlmUEAgFsbGzgxIkTWFtba0msvBpKI5WXkJMUkJKM7UABE1YGt2b3V2x6zXGt5DaC6g6rVoxGR0fLmaDqotnv95dbJfdWiw4zyOln6nlfzY1Y8Ml3LCCSLsBsYDFu709n5VOjVjyLGAqSDJOBQyYvwcAxODlcW0RQkds8tc4dwzAwm80wm837NrBUo6u98UZ7xe9R8UbZooxAIgczz2F22AxW59d8tyu5FP1CRe4xoNXFop4dlkVRhNvtRjqdxuLiIi5dugSGYbC1taXb32kvWlikVs6ILi0tYWpqquHjYlkWxWJ9bbOKQvDHLwTgjWUxPsAjksrh3/94A//8l05hdqTzgu324gjMPIt7njgIgHeeHYdZCLVts4EQglAoBI/Hg/Hx8bZlB//IFcPskAWnJwYQzxahKATpjACroffvob1QkdsclZmg4+Pj5Y9LkgRRFJHJZBCLxbCxsYFCoQCz2VyeD1QNcvrdaKXeyCWeY6ta+/uRxTErfu3cGP7uQQwyKcLCc3j/1Wk4LLXbZesVuUJh9/k6YKLLTJVGZkk5jts3tgBUm9VVxhvVMrriOA7ObRF/8lIIuaIMAmB5zIp/euPkgcZieqBbIjeZTFKRq3Po3YdyJHqs5KqiK5VKYWlpCRcvXqxa1OhZuB9EL7Iy8/k83G43YrFYUzOilTRSyQ0mc9iIZzE/sluJspkMCCby+Jk/2RWRy7IM3jY/jLfNP5oxfuONSMsilxCC7e1tOJ3OqnileskWZby0kYB3R8SJIQtuLgxjsGKxWpIVcCwDC89hxmGBrBAIgljVeq0VqMhtLwaDAQ6Ho2rRttcgZ2dnB4Ig7ItFsdvtR1aL9ATNFa7m8eVRXJt1IJ2XMGLlYeYPFkBHidxsUcYzr23hlWAaBLtt3u+5NKVrUdUu2mGYdJBZXeV1HI1GIYoiFDD4zz4GLMdjfNACnuexHhVxz5vAr5wZO+RVtE23jKdou7L+oSKXciR6EoTZbBZutxvJZBKnTp06UHRpcY61FVSB2K0KTLFYhMfjwdbWFk6dOoVz58613MLWyN9EUgiwZ43KsUBJ7p0oarVtPB6P48GDBzAajbh8+XLD2XwlWcEf/XgD69sCBowG3A+k8bI/iX/xxFJ5gXl9fgh/9UoEZgMLjmUQSuWxMmaGldfegp+KkPppVrQdZJCzNxbF6/WiWCzCarXuqxbpsXWVitz9DJgMdVddDzt3338ripf8Scw4zGAAvOxPwWRg8d4rjYaU9R+yLHfkemFZFjabDTabDZOTk+WPB+MClJAHI2aCbC6LYqqIbE7Ccz9P4SRiVW3PeprZp+3KlHrRz7ua0jTtaFfWeiU3l8vB7XYjHo9jcXERq6urhz5M9CTc60EViJ0WuaVSCT6fD5ubm5ibm8Pdu3fb9pqNiMSTQxaM2oyIpIqYGDQiV5RRlAkunezdA4ll2aaus3Q6jfX1dciyfKQD9WG4oyLcURELI1YwDIMxQuCP5/CLzTQeW9j9mWtLoxCLMp53xyHJBJdmBvHYBIEiN+6u3A2RQCu5vaFWLIpaLVIdnre2tpDNZsFxXLnaWzkjqGWoyO0MCiF42Z/CpP1RvvDkoAn3g2k8eWkKhhqRRMeJbm5EA8CwzQyb2QSzlYfDsPv3UJJ5rE5bMDJihSAICAQCu1Xfh07tlcJXq/nc3RS5tJKrb6jIpRwJz/PI5XK9PoyaVLbLnjp1CufPn6/rptyPIreTDtiSJGFjYwPBYBAzMzMtGyDVopFKrtHA4kO35vCX9zfhi2UxYDLgvVemcXrC1tZjaoRGK7mqK64oijh9+jTGxsZaWngLBQkM80h8MgwDhtnNwVQxcCzefWEK7zw7AUkhsBq5h26ehaZft1PQdmVtUVktqqRyRjASiUAQBJRKJc07w1KR234YYNd5XibAwykJSSEwciyOub4F0L02WxWbyYB3nB7Ff3sjCp5jID+857/j7CTGB81VM/uqU7sgCEilUgiFQsjlclX53Oo13etNLEmSunIe0+k0pqdpB4KeoSL3GNDqw1yLldx8Pg+Px4OdnR0sLCw03C7bjyK3E+3Xle6+U1NTuH37dscecI2KxGmHGf/sl05BLMgw8Wy5ctAr6j1+dWMmHo9jaWkJ09PTbVlwzw5bwTIMskUZViOHgrR7LAuj+2d6jQYW6l9Rq2JSq8dFqeagGUF1wVzpDFu5YO5lHiit5DbHUdcjwzC4uzyCZ17dgqQQMACSuRL+8cVJ3Tv6toNui1wA+OXTozg5ZMZbEQEDZgMuzwxibGD/M1x1ah8cHCx/TM3nVjexwuEwBEGoijeq/H83N7G68Vq0kqt/qMilHAnP85oRhIVCAR6PB9vb21hYWMCZM2eaemj040xuO38fRVEQCoXg9Xrb6u57GM3k5DIMgwGzNm5jR4ncUqkEj8eDSCTS1MbMUUwOmvCbl6fxzKthxMTdRfyvnZ/A4tjhxlUMw2gmgmovVOTqE5Zl9znDVi6YM5kMQqEQBEGAoijlhbLa8myxWDoqQqnIbY56ztvdpRGYDSxe8CYfOs+P4bF5KhSA3ohchmFwZnIAZ5qI16vM5x4dHS1/vHITSxRFbG1tQRRFGAyGfVVfk8nU1mutm8+EVCrV9PgQRRtoY3VI6Sj9UMktFArwer3Y2trC/Px8y7Og/VYlapfIJYQgHA7D7XZjeHgYjz32GCyW7kRoNJqTqzVYlq15nciyjI2NDQQCAZw8ebIjrd4qa8ujuDgziO1MASM2I0ZzbEh6AAAgAElEQVRsR1fdm50l7jRUhPQXBy2YK9skk8kkgsEgcrkcTCbTvqpvu64bRVHa9v6SFQJZITAatNOK3SnqiQ9iGQY3FoZxY4GKg730QuR2glqbWMCj0QVRFMuGdYVCoaZhXbPnoZvnkFZy9Q8VuZQj6WUlt1gswuv1IhKJtN3oCOifHf1WRS4hBFtbW3C5XLDb7bh27dq+2btO00wlV0vsreSq1XCPx4PJycmOtnpXMmjhq2KDjkKrGz5aPS5KezmoTTKfz5fbJAOBAARBAIB9VV+z2dzwPbwd931CCP7eFcffvrUDsShjdXoA770yjWFr99uvu0W9GbmU2nTKXVkrHBZvpG5kVcaUVc7t22y2ujo4umU6BVCR2w9QkUs5kl7MrxaLRfh8PoTDYczOznak+mUwGCDLsq6s8w+iWZFLCMHOzg6cTifMZnNT0TXtoh8quYqigBCCSCQCl8uF4eFh3Lhxo2vV8GbQarsyFbnHF4ZhYLFYYLFYqsxxJEkqL5bj8Tg2NjZQKBRgNpurMn2PqhS1Q+T+PJjGt+6HMWozYnzAiFdDGYhFGf/ilxb6YuO0FlTktka/VHIbodKwrjKmTJKk8iZWPB6H3+9HLperupZV8Vs5t98t0ylg13iKilx9o//VPeVI9NSuXBlR0+nWTtWRuB9ErirYGyEej8PpdILjOKyurvY8D64f5qRFUcS9e/dgsVhw9epVDAw0PgfVbdR2ZUIIgsk8ktkSTg6bMWztrYMmFbmUvRgMBjgcjqp7FSEEuVyuvGCOxWLlStHedmd1PrAdIvcFXwJW46Ns2ZkhM9zRLLYyRUwNdta/oFdQkdsaiqL03JlYKxgMBgwNDVWJyL0dHMFgcN/cvvr+6/R7kRCCdDrd83URpTX0v7qndJxuzOyVSqVyRE2nxa1KPzksq4K9HpLJJJxOJxRFwcrKSlVrUS9p1F1ZSySTSXg8HpRKJVy7dk0zD8ZMXsKLvgQi6TxWJgZw5aRj3+wgwzCQZAX/8Z4fP/ElwIABxwIfuH4Sd5dHD/jJFC3RL2MXzcAwDKxWK6xWa1WlqFQqlRfL6nxgsViExWKByWRCoVBAJpNp2hWWYxig8rlIdudzA4kcbEYOdo0Y4lVCCMEbYQE/86fAcwxunho+0piukl6J3GxRhisqwsAyWB636Xb++ThWchvhoA6Oyrn9nZ2d8mYyz/P7NrLauYmgKEpfFEGOM/Svdwxox+KnXbvfe1HzVwOBQDl/tVuREs1UP7VKPSI3k8nA6XQin89jZWWl5VzWdqPVttnDEAQBTqcTuVwO09PTyOVymhG4Ql7C7//Aic1kHkYDi+fWd3B9fggfvVvdTskwDB7Eiri3FcfJIQs4loFYlPCnLwVxftpel3lVJ+hlJVdSCHJFGQMmTlPXCKV+eJ7H8PBwlTuqOh8YjUaRTqfh8XggiiI4jqtZ9T2M26eG8XpYQCpXgtHA4s1IBmJBxn98IQCeY/HkpSk8cVpbm0Q/dMXxZy+HYeRYKITgni+Jj63NYfVEfSMqvRC5np0s/u3zfogFCYTsush//O3zNWNwtA4Vuc1RObfPcRwsFguWl5f3xRuJoohSqbTP6MpqtTZ83rvZFk3pHFTkUupCrXq2S4DuFbd37tzpehtPv1VyC4VCzc+Jogin0wlBELCysoKJiQlNLty1eEwHkcvl4HK5kEwmsbKygsnJScTjcYii2OtDK/PSRgLhZB5zI7tmHrJCcN+fgmcni6XxR6ZiLMvCn5Jg5Ezg2N2/gc1oQEIsIZDIHSpyO/k365XI/Ykvgb96ZQupvISTQ2b81vUTOFUja5iiP9T5QFmWkclkcPHiRQCoWixvbW3B7XaXF8uqwZW6WFZF3oUTdvyPj53A99/aQSRdQL6k4MIJOwbNPHIlGX/58zCWx62YHdbGPH5JVvBf34hixMqXW6xjYhF//ca2ZkWuQgie/tkmJEnBySHL7khFKo/v/mIbH7p5smvH0S6oyG0ddcTssHijbDZbvp63t7fLG1mVRldHxRulUik4HA5drUso+6Eil1IX6lxuqyJXkiT4/X4EAgFMT0/3RNyq9JvI3VuVrhRiS0tLuHz5clM3bEIIttIFMAwwYW9v5p3eKBaL5ZzmU6dOYXV1tbzo01q7dVQoguOY8t+LYxkwDJDMVc/XMwyDIRMDT/7RscsKAQEwdIRLcyfbZHshcj07Wfx/L4ZgNxlwYtCE7UwBX/2HDfyrd5+G1UgXp/3C3vftQa6w2WwWmUwGmUwG4XAY2Wy2qkVyeXAAV39lAT/2pvBn9yMYNO9eLxaeg0IA705WMyK3KCkQChKmB83lj1l4DjGxfr+NbotcoSAjmMzj5NDuMTMMgxGrEQ8iQteOoZ1Qkds6R5mFVs7iV1JrfKFQKMBisZS/PhAI4MyZMxgeHm7YWVlRFHzqU5/C9773PTAMg09/+tP4xCc+UfNrP/nJT+KZZ57BxsYG7t+/jytXrtT1OZU/+qM/wm//9m/j29/+Nn7zN3+z7mM8jlCRewxoxyK01RghWZbh9/vh9/sxNTXVtTiVw2hkjlXrVIrcQqEAt9uNnZ2dfUKsUeJiEV/7kQ+u6G6F8vyUHb+zNt9QRE0jdKotvlUkSYLP50MoFMLc3BzW1tb2LVa0JnKXxm34/pvbkBUCjmWQK8pgGOxbdDMMgzPDHIKKGf54DkaOQV5S8NjCMOZGtLFA7xavbaYBAgw+nKecsJsQSubhjIq4PDN4xHdT9EI9Obm1FsuEkH0tkk6nE76YhHQaSDB5mIym8iLcZtLOEstq5LA0ZoU3lsP0Q2OsHbGItcX682y7fW+28CwcZgPEglyecRYLEhZG9Xlf6vcIoW4gSRLMZvPRX7iHWuMLe03rfv/3fx+vvfYaCCFYWFhAOp3Gt771LVy6dAmLi4uHblB84xvfwBtvvIH19XWkUilcvXoVTzzxBFZXV/d97fvf/3587nOfw927dxv6HAD4fD587Wtfw61btxo+B8cR7dyBKR2l1apIsw7LsiwjEAhgY2MDk5OTuHXr1pGzTt2i32ZyS6USHjx4gEgkgvn5+ZpCrFH+9KUgXNsiZobNIAR4fTON//xKGP/Trbk2HXk1alauVsweFEVBIBCAz+crdx4c1M2gNZF7aWYQd5ZG8YInDoYBWIbB+66ewIS9+vpjGAZWHvhff3UZP/HGsZUu4PTkAK7ODvV0s6EXlVwDy6DyFQkhICAwsNradKG0RrNi7aAWydV8EZ6/cSKYyMGYzyGTL2GIl5HbzOJN0V7V8tyrexvDMPit6yfwb3/kRzCVBwhwatSK37gwcfQ3P0RRlK5WInmOxXsuT+I//XQTqXyp/LF3r9Z/zFqi2+evH2lnIsZe07o///M/BwAkEgn86Z/+Kb797W/j2WefxZe+9CW43W7MzMzg0qVL5f8qPWSefvppfOQjHwHHcRgZGcEHPvABfPOb38TnP//5fa/7+OOPH3hMh31OURR8+MMfxh/8wR/gs5/9bIu//fFAGytJiuZptJIryzKCwSB8Ph8mJiZw8+bNpnbfOkm/tCtLkoRwOIxoNIrl5eW2OVMXSjJeDaUxOWgCyzDAw3bln24k8MGbsx0RQFrJyiWEIBwOw+VyYWxsrK73r9aMswwciw/dmsWvnBlDPFvCzJAZYwP7N5hU93SHhcevnZ+s++czDNNREdwLkXtt1oHvv7WD7UwBAyYD4tkSJuwmrFTMMFP0T7srkgNmIz7zq6fxI3cC3lgWp0atWFscgplVIAgCMpkMAoEARFGEoij7TK4sFktXNpSmBs3439+1DH88BwPHYnbYvHtvr5N6KuDt5ubCMMYHTHhtMwMjx+DqrEO3EU20Xbl1uhH7ODw8jOnpaVy9ehVf/vKXAezeMwKBAF599VW89tpr+OpXv4rbt2+Xv8fv92N+fr7874WFBbzwwgttPa4vfvGLWFtbw9ve9ra2/tx+horcY0I7Krn1CEJFUcritl5x0CsOM2vSA7Isl827xsbG4HA4sLi42Lafb+BYWHkORVkpRzYUZQWDZr5jCx21ktsrCCGIRqNwOp0YGBjA9evXYbXWZzqktUousHvdz45YMXtISpTWxLlKL0TutMOMf/74Ar7z+hbCqQIem3fgN1YndBtZQqlNJ9puHRa+ZlXUbDZjbGys/G9JkspxKIlEAoFAALlcrmo2UP2vE4KI59gq47lG6FWE0OKYtaGoI61CRW7rdEPkAruxgJVJCXfu3IHT6az6mpmZGQDA/fv3O348r7/+Or71rW/hhz/8Ycdfq5+gIpdSFzzPH9qurCgKQqEQvF4vRkdH8dhjj8Fi0fbcjF4ruZUttJOTk7h9+zZkWcbPf/7ztr4OxzL4R6sTePqlEPIlGQoBckUFv33nRFtfp+o1e1jJTSQSePDgAQwGAy5evIjBwcZmMLUocmuxlS7gr1+PwL2TxfK4Db+8MtSzqB4tsjJhw7/85fZtFlG0Ry/n/g0GAxwOR9UCeu9sYCwWgyiKYBim7Airtjwf5gjbaXolcvsFev5ap1vRPnuNp+7du3fo18/NzWFjY6Nc3fX5fJiba99Y1z/8wz/A5/NhZWUFABCJRPDRj34U4XAYH//4x9v2Ov0GFbnHhFYfigaDoWbVU1EUbG5uwuPxYGRkRBfiVkVvIrfyXI+OjlZVyYvFYkcqoL96bgJDViP+wbUDA8Pg7StjuDrbuRzYXlRyM5kM1tfXUSqVcPr06SqH1UbQgsiNCUV857UI3oxksDBqxW9cnKoymhLyEv7136wjLpZgNxvw7PoOXgkk8e5J7YnzXubk6g0tmrVpGa2dr72zgSqSJO1zhC0Wi/uqvjabrSsLfyrSWkdL7zs90i3PjlQqheXl5bq//qmnnsLXvvY1PPXUU0ilUnj66afxne98p23H8/GPf7xKzL7jHe/Apz/9aequfARU5FLqgud5CMIj235FURAOh+HxeDA0NNRQW6dW0IvxFCEEkUgELpfrwHNdK0KoHTAMgxsLw7ixUL8DZyt0s5KbzWbhcrmQTqdx+vRpjI+Pt7QAUWdbe0W+JOPffN+JcCoPh8WAF30JvL6Zxv/5j89hdGDXyfx+MIWYWMTs8O77x2HhEYiJ8CQbf+/IsoxkMomBgYG25WdXQkUupVNoTeQehMFgwNDQUFVFiRBSlQMajUbLOaB7252NRmNbf08qcpuH3svaQ7faldPpdJUT81F88IMfxE9/+lOsrKyAYRh85jOfKedwP/PMM3jmmWfw9a9/HQDwsY99DN/97ncRiUTwrne9C3a7HS6X68jPURqHilxKXahVT9WQx+12w+Fw4Nq1a7DZ9GnKovVKLiEE29vbcLlcsNlsuHr16r7sNxUtVBHrhRCCcKoAWVEwM2QBW+Fc241KbmXE0tLSEi5evNiWhWCv/wZvhDOIpHYzJRmGwaCZRzCRw0sbCbxrdddQqlCSgT1rLQVAQap/AUYIQSgUgsfjgcViQT6fhyzLsNls5ZZKu90Os9nc0nmlIpfSKfQicmuhtjDbbDZMTj4yiquMNtra2oLb7UapVILVai2LXrvdDqvV2rRQVRRFM873ekPP7zkt0a2NlnQ6XTVScBQcx+ErX/lKzc89+eSTePLJJ8v//upXv3rgzznsc5U899xzdR/bcYberY4Jrd5cOY5DJpPB888/D7vdrmtxq6LVnFxCCGKxGJxOJ4xGY13zoXp5eKZzJfy/f+/FL8IZMAAWRq34xBOL5VibTlZyS6USfD4fNjc3MT8/j7t377b1YdlrA6eCpOxzPCYAcqXdTQNCCKxGDrmSglSuBIeFRyYvgedYzNTeO6mCEIKdnR2sr6+XTbk4jgPDMJBlGaIoIpPJ7DPTqRS+Nputq5UgWSFIZHdbs03UPIrykH4UHEajESMjI1XjFoqiVFV9I5EIstkseJ6vWfU9ClrJbR5qOtU+unHt7p3JpegTKnIph0IIwdbWFtbX1yFJEm7cuHFgNVFvaLFdOZFIYH19HSzL4ty5cw3fZLW+ePuLlzfx2mYaJx1mMAzgi4n4Dz/243Pv2jVT6EQlV5Zl+P1++P1+zMzMtC1iaS+9Pu9nJgfAcwyS2RIcFgOyRRksw+DijAOZvIQv/Z0bb0UyyBYl3A/kMDNkwdiAEb+zNodi4PVDf3YqlcKDBw/AMEx504UQgmKxCGB3c2JwcLBqM6bSTCeTySAajUIQBBgMhqrcULvdXrPdudVNg7ciAv7ohQC2MkVYeRbvvTqNXzk92vO/E6X3aP0+2S5Yli1fZ5UUCoWy8A2HwxAEodyNUSl8rVZr1XmiIrd5qMhtnW5GWFGR2x9QkXtMaPTGoIpbt9sNm82GCxcu4K233uobgQtoq105lUrB6XRCkiSsrKxgdHS04Z+hVkG1/CB90ZfAmM1YblGetJvwi3AaYkGCzWRoayW30qhrfHwct2/frqta0Qq9XDiP2Iz4Z7+0iP9wbwOhVB4WnsMHb81iadyGP3kxgDfCGZwcNmNmyIxwqoAhiwH/13tXYTEa8Ky/dltwNpvF+vo6stksTp8+XRWFchQHmekUi0VkMpnyAnt9fb0qO1QVwEDzc2xCQcIf/L0PMiE44TAhW1LwJy+GcNJhxtmp/rmHUZrjuIjcgzCZTDCZTFXPGVmWkc1mkclkkEqlEAqFkMvlYDQay9dmPp+H3W7v4ZHrFypyW6db87jA7pqskZlcijahIpdShToH6na7YbFYcOnSJdjtdiiKcmiEkB7RwsyfIAhwOp3I5XJYXl5uyfxINZ/S8oPUYTEglZNgNe4eY0FSYOG5cg5pOyq56gaNy+WCw+HoquN3r99PV2Yd+DcnLiAuFuGw8DDzu+f5Z/4khq082IfvrWmHCaFkHkJBhsW4/zFQLBbhdrsRjUaxvLyM6enptokCo9GI0dHRfQtstd05Ho9jY2MD2WwWBoMBxWKx4XbnB1sickUZ00O77uM2I4d0toT7wRQVuZRjL3JrwXEc7HZ7lYglhFRVfTOZDNLpNDwez752Z4vFQs/pIWj92awHuiVyCSG0ktsnUJFLAbB7UUejUbhcLpjNZly4cKGq9bDXpjqdpBcLnkpn3+XlZUxOTrZlblpr7dd7ec/lafzhD70oyQpYhkG2JOMDb5sBz+0Kl1YrubFYDOvr6zCZTLh8+XLXqw7qxkkvF3s8x2Jy0Fz1sQm7CQ+2BNjNu7f8gqTAZGBhM1U/AmRZhs/nQzAYxNzcHNbW1rqyMKvV7hwMBiGKIhwOBwRBwPb2NkRRLM8TVrY87213NhlYEFRf2wSkLPr7ESow6qfX16heYBgGZrMZZrMZY2NjyGazmJqaKl+TgiBUzeCbzeaq69Jms1GjKgCRdB7BbREsoe+5VuhmJVeW5Y6kBlC6C737HBMOeqCrZjIulwtGoxGrq6uHOsr12+JAFYbdunHm83m4XC7E4/G2OvsC+hC5txdHYOY5PPsgipJM8PaVUdxZfGSU0mwlN5VKldtem5llbhdaELm1+O8uTeHNv3FiM5UDx7Aoygred/VEuaJOCEEwGITb7cbU1BTu3LnT8wc8y7LgeR6Tk5NVLrKVlaVQKARBEPa1O88NWnHCYUIwmceQlYdYkGEycLi1QHfmKf33HOsW6kwux3FwOBxVawVCCPL5fLniG4vFIIoiAOyr+rbqvK4XSrKCrz/vxz1fElJJgoGU8L+NZ7B6grZ8N0O3quF09rx/oCL3mFLp4MvzfF3CQDVq6qed2W79ToVCAR6PB9vb2zh16hTOnz/f9puoHkQuwzC4NjeEa3O132uNOl6Login04lsNouVlRWMjY31dPGkdjxo7QF5fnoQ/8e7z+K59R1ki1I5+1jt4CiVSojH47hx40ZDrd2dPNcHjRMcNE+oCt9YLAZB2MBdex4vFw0IZItYGLLgyUuTmLR3diabog8IIZq7RvXAYfc2hmFgsVhgsVgwPj5e/rgkSVXX5sbGBvL5fFW0kVr17bd23h86Y/iRO4FphwlSEdgRJHzlhxv4v99/nrq9N0G3KrmpVAqDg4PHYiOm3+kftUI5lHLLHiGIx+NwOp3gOA5nz56te7jeYDCgVCr1nciVJAkmk6kjP79UKsHr9SIcDmNubg53797t2INcq5FIjVBvJVetiCcSCSwvL2NqakoTDyQtt/UvjduwNP4o9iuZTOLBgwfgOA4GgwGXLl3q4dHtp5GZ+YMqS48/jE/JZDIQkpu4F3LW1e6sN3o9C643aCW3OZrZwDMYDBgaGqraRCeEVEUbRaNRiKJY5QatXp9Go1G3f6ufBdKwGFlwLIMiIXCYOQhFCb5YFmcmqTdAo3RT5DaSkUvRLv2jVihHoopbhmFw5syZhp3jeJ7XvYjaS6ccliVJwsbGBgKBAGZnZzsWW1OJHiq5R3HUTG6xWITX60UkEulYRbwVtCxyVURRxPr6OnK5HM6cOYPR0VE899xzTS38VXGlxUUowzCw2Wyw2Ww1250zmUxVu/PeWCOTyaTJ34vSOv0iclO5EggBhqzd2aRpV5fKQddmqVQqC1813aFUKtWs+mrpvn8QozYjSvLuPZIQAoUAhACDZrr0bgYqcimNQq+0YwIhBJFIBMvLy03F0wCPKrn9RLurn5WZrNPT07hz507HY2tU+kHkHlTJVTcNgsFg1zYNmkHLIrdQKMDtdmNnZ2efY7IWZ4k75X5eq91ZkqSyu7PaUlkoFGCxWMri1263w2q16mJxTTkcrb3XGyVblPHvfhzAC74ECAEunxzE/3J3Dg5LZ8Vup0cxeJ7H8PBw1Qa8oihVVd+tra0qA7rK/7r1rK2XXz07hnveBCLpAuRSCXmJ4Imz45h2mI/+Zso+JEnqStcNdVbuH7S3SqR0BIZhcOHChZYW4P1ayW2HMFQUBcFgED6fD+Pj47h161bHWqAPol2/SzMksyUkskXMDFnKcUDNsLeSq55Xr9eLqamprmTdtoIWRa4kSfD5fAiFQpifn8fdu3f3LVS1OEvczYgvg8Gwr91ZURTkcrlypm8kEkE2mwXP81XCd2BgQJMbLpSD0bvI/fOXw3jeHcfk4G4r788DKfz7ewH8y19e7Ojr9uIeUdnCXMnevG1BECBJEmw2W1VHhsVi6dl9bW7Egn/16yv4/ls78GxGcfmEDf/9zbmeHEs/IMtyV+IAaSW3f6BPZkrddKq1t5e0+jsRQrC5uQm3242RkZEjM1llhWArXcCg2YCBNrcs9aKSSwjBn7wYxF+9GoGiEAxaDPjEOxYPNJY6CrWSSwhBOByG2+3G8PAwbt68CbNZ+7vfWhK5lRsEalfBQbvgWsiM3kuvj4ll2XJLpQohpGpxHQwGIQgCCCH7Zglpu7N20bvI/ZE7jmEbD8PD6LVxuxE/86eRK8mwdDAmS0sbYbXythVFgSiK5XGEzc1N5HI5GI3GfVXfbs3hz41Y8Dt3ZuFyFXZfl9PG+dMjtF2Z0ihU5FLqhuf5vmtXblbkEkKwtbUFl8uFwcFBXL9+HVar9dDveSuSwf/zrAeRdB48y+I9l6fwTx47qesIoZ9uJPGtn29izGaEkWOQzkv4/R+48If/5DIGm2idY1kW+Xwe9+7dg9VqxbVr16pEhtbRgsglhGB7extOpxNDQ0N1bRA0Kyg7KUS1KEIYhim3O4+NjZU/XtnuvLOzA6/Xi2KxWDVLSNudtYPeRa6ZZ1GQHt1nZIWA5xhwHf6dtCRya8GyLOx2e1U+OiHkyNgx9T+LxdKx90W34m/6mW6KXNqu3B9QkXuMaPXmTWdyUY5ccblcsFgsuHz5ctUD9SByRRn/+m+cyBVlTA+aUJAU/MXLm1gYteLOUnMz0nvhOA7FYrEtP6teXvIlYGCYchyCw8Ijki7grS0BNxYaMzZLJBJ48803kcvlcP36dV3upDIM01ORm0gk8ODBA/z/7L15dCPneeb7FAr7wp0El27uZJPsjb2pye6WbFm25SWRPY4lX4+txBlHcSbx2B772vGdzMzJmaM4mblnbjK5ztw4ljPJuTpxlGQc3bas2I5jy0lkaVqyuqW21E0sBEGQBEmQxFKFvZb7B1WlAgmQWApAAfx+53SskCBQKBSqvqfe531eg8FQ9LEJaEOc50Nr1eVCFLI7K3sJJbuzVFVSBl2psXBrZNFWaxpd5L7vVA/+/MUVCG++j1iSwwfPOitqFSmGRtxvFEXBbDbDbDbn3JjieV6+MRUOhxEIBJBMJmE2m3NuTNlsNlW+n0TkVk6tRG4sFsPx48er/jqE6kNELqFoDAYDEolEvTdDVfR6fdHvSZorrNfrcfLkyZJEmHuTRSzFobdlt0/XbKBhoDn8ZHFHVZFbazt5q9UAQSFERFGEKAI2Y/EXc4Zh4Ha7kU6nMTw8jOXl5YYUuED9xCLLsnC5XEin0zhx4gQ6OjpK+vt6W4PzocVtKoV8vYR77c6BQAAsywIAsTvXkEYUa0reM90NI63D9++EwPEiHjrtxHtmug//QxVo5P2mhKZptLS0oKWlRf6ZKIpIpVLyjanl5eV930/pn9lsLmlfEJFbObXah5FIRHMj9QjlQUTuEUKNSm4z9uQeZvGNRCJwu90QBKGs0UvArqjdHSEgQvfm58ALgMOk3lewHnblt0924bs/20AwlobVoAOT5jHltGOqt4jqdjIJt9uNWCyG8fFxOJ1OZDIZLC0tVX/Dq4ROp6upMEulUvB6vdjZ2cHExAScTmdZ33MtCkotblOlHGR3Vs4MVdqdlRVfYndWh0YXuRRF4YETXXjgRNfhDyYUDUVRsFgssFgs6O5+66aB8vsppa+nUqmc9HVptFEhEUZEbuUQuzKhVIjIJRRNM9qVDxLusVgMbrcbmUwGExMT6OzsLHthNN5twwmnHXfWGbSYDUhmeehpCu+c7qlk83Ooh8gdaLPgPz00jadfDWItksKDx1vx0Jk+0LrC+ymTycDr9SIUCmF0dBSnTp2SF+6NPqfSRW4AACAASURBVAapVpVcjuPg8/mwtraG4eFhTE9PVyR+yrFZV1skNKPILYRer0dbW1vOwkppd2YYBsFgsKDduVr7Kc0JeCPIQARwss8htyU0Oo0ucgm1Jd/3UxRFJJNJ+fsZCoUQj8dzHBzS99RoNILneXKDqkJqaVcmIrc5ICKXUDTNOEIon8WXZVl4PB7E43GMj4+jp6en4gWRTkfhyw9O4ls3g3h5OYzxHjs+NNuHsW71QpXqJRBHumz4tw+MH/o45SibwcFBXL16dd+d7UJzchuFaotcQRAQCASwtLSE/v5+1eYF17oCTTgc5WK5t7cXQG6IDsMwst05nU6D53m0t7fnLKwrOW+tRJL4nb/zYCu+2+ffbjXgt94zgaGO6o/wqDZE5JYOOT/kQlEUrFYrrFYrenreulmdzWbzujI4jpNbcaSqLxG9pVOL7y2p5DYPROQeIUjw1H6UldxEIgGv14tIJIKxsTH09fWpekJtsRjwiSuD+MSV6szJ02oVVBAELC8vw+/3o7+//8BRNo0utqolcqU0b7fbjY6ODtVHKmmxaqrFbao3hUJ0bt26he7ubgiCUNDuXOrM0P/xQgBb8Qy67btzqUNsBl9/fhmP//yJqry3WkJEbuloPVlZKxgMBrS3t+e0NQmCgBdffBEtLS2Ix+PY2NhAPB6HXq/f58rQ8hz4elLLawGp5DYPROQSiqYZK7l6vR6ZTAZvvPEGtra2MDo6ipMnT1btYh5Pc9DrKJiqMMtQayJXOUO4q6sLc3NzMJlM9d6sqlINkbuzs4OFhQWYTCacO3cuJ8hILeqdCp2PUkVulhfwk8UwXJtxDLabce94J6wlBKA1MtLoFGWIjmR3ZhhGnhmaSCRgMplyhG++9FhBFPGzNRZtFoMsBtutBrg248hwQtVTfKsNEbmlQ0Ru+Ug3b/v6+sCLwO3VGFhTBoOtBvSYdlOeg8EgWJYFx3Gw2Ww5lmfSi1+7nmZRFEklt4kgIvcIUbnltrGtpHvJZDLw+XxgWRbHjh3D1NRUwQtJYCeB5XASx9stGOw4eB5uPnbiGXz1uUW8tBSGgdbhPSd78MtXhlQdDF9MiFYtUM5pLXaGcLOgpshlGAYulwvZbBZTU1NlBZ4VS7kV9GrPyS32uXlBxFe+58HNQAw6ChBE4Lt3tvA7P3/iyAjdvRRKd06n03K6s5QeS1HUvrEp3XYjIsmsLGiTWQEdVgMMdOOLQyJyS4eI3MrJ8CK+8l0Pbq/FAAqACHzwbC9+8fJb7i5BEBCPxwv24iv/FXJENSO16scFdteGajqlCPWDiFxC0UiLgkZfIGSzWSwtLWFtbQ3Hjh2D0WjE0NBQ3seKoohvPO/H068GdxfPAvDQ2T48dm2opH3wf/3Ag5uBKLpsBnCCiKdvBdFuNeDhC8fUeluqVHJTWR4v+yOIZzicHWhFb2tpJ/qdnR24XK6S57QqkaqKjbigUkPkplIpeDweRCIRTExMqNITfhiNbg2+vRbDrZUYehxG6N58L0tbCbywGMYDUySBVkJpd1amxyr7CDc2NsCyLM5a07i+SSEW10Gn04GmaTx25VhDn/slGv0aVg+qeU5e2GDxFy+tYjmcwqk+Bz52z4A8bq+Z+GfvDl5dfes8leUFPP3qOt420Sn3ukuuDOW1c+/osdXVVbAsC0EQ5Kqv5M6wWCxNeWzXSuQKgtCU+++oQkTuEUKNLy5N0xAEoSGj8KXgh0AgkNMbury8XPBv3ggyePrVXUFqoHXI8gKuvxbE3Gg7zgwUN8t1J57BrUAU3XYjaB0FPQ3YTSK+90ZIVZFbaaV9i03jy3/7BoLRFCgK0FEUvvDOMbxt8vD5i7FYDC6XCzzPlz1mSUI6xhpR5FIUVfZnkM1m4fP5EAwGMTIygpmZmZrtg0a3K6/HMqAAeTwXRVEQAazFUtXbQI1Ryfk9Xx/hRUHAhaUQnnNtIZ1OY6qFh27jLl6Omvf1ETba9YCI3NKp1jl5LZrCf3zGhSwvwGqk8Y/eHSxssvjDh0/CXIW2nnognVsXNljQOko+TxloHSiKgn87cWCgW6HRYzzPy1XfSCSCQCCAZDIJs9m8r+pbqypoteB5vibvgWVZOBwOcn5oEhr7qCfUHIPBgGw221CLGmXwUW9vL+bn5/eFOxRa9CxssBBEUbYVG2gdBBFYWGfzityVcBL/7NkGL4iYH+vAaJcNOooCRUnBCW9Vw9W2/VV6Uv6rn65iNZKE02ECRVFg0xy++pwP9wx3wFLA8hmPx+HxeMCyLCYmJtDd3a2KLV5rgqtYytl25fE5MDCgWmJyKWgx8KsUkTvWtWuHz/ICDLQOvCCCooAJFdPLjxo6nQ7nR504P+qUfyaKIlKplFz19fv9YFk2xxotVaG0HKBDRG7pVEvk/ti9gzQnoMexe7xYDDqE2AxursQwP1K9Fo1aIhUGhlotEARRPv54QYQgiiU7piRomkZLS0tOL/7e76iUwA5gn/A1m80N8z3gOK4m685IJILW1uIKGATtQ0TuEaNSW+JBc2W1hiAIWF1dhc/nQ1dXV8FE2oOq0112IyhQ8kVJFEVQALod+61Ur61G8R+v30GaEyAC+ObLK/jNd0/g3okuXB3rxI/dW2i37NqVE1kBD53prcK7Ln8B99pKDDajXv5bu0mPTSaNtWhq36ijVCoFr9eL7e1tjI+P48yZM6pdLLUWoFUKpYhcURSxvr4Ot9tdUjDXejSFp18NwhuK4+yxVjx0phctlsp6s7RoVy5lm8a7rfj50058+/bGblVaFHF1tB0Xh0h4iJpQFAWLxQKLxXKg3dnr9SKbzcJms+VUfK1WqyYW1UTklo4oilURueksD+W3nKIoUAAyXGPe6MyHFJr0tolOfP/OFvw7SQAARQH3jnVgolu9zIpC31GO4xCPx8EwDLa3t+H3+5FKpWCxWPb142uxiFEru3I0Gs25aUBobIjIJZREI4wREkURwWAQXq8XbW1tuHTpEiyWwlYgSbjnO7FfHm7HaLcV3s34m3ZlEaPdVszlucP8jX/2gxdE9LwpgGOpLL7+vB9Xxjrxb+4fRZvVgOdcW7CZ9PjY5WN4z0nnvueoFElklXORGuu2YTmchMO8e1pIZXkYaEp+P0CupXZ4eBjT09OqL3waOeCsWJG7vb2NhYUFWCwWXLhwATZbcRXHbTaDf/vXtxFOZmHS6/DaahQv+nbw+w+frijETIt25VKgKAqfmDuGt010Ymk7gf5WM044bUdGyNT7BkWhsSmSlTIajWJ1dRWJRAJmszlH+NbD7kxEbunwPF+VfXbPcBuu395AIsPDYtAhluJgoHU4M9A8QkMSuXaTHr/7gSn8ZDGMYDSFSacNFwbbanIs6vV6tLa25lQpRVFEMpmUb1Btb2/vc2ZI/0wmU12/M7UUuSRZuXkgIveIUWnFRstjhKRUX4/HA5vNhvPnzxclHmiaBsdxeatoJgON3/3gSfzgziYWNlhM9tjxrumevL1C/p0EbKa3vlI2ox4hJo1EhofDrMev3TeCX7tvpLI3WcR7KTdq/yMXB/CyP4INJg2IInQUhU9cGYTDvJva7Pf7EQgEcOzYsapaaqXKeiNymO2XYRgsLCyA53nMzMyUfDH90UIIkUQWPW+GsrSY9VgMxXEzEMU9w+Vb+xq9kis9frTLitGuo5HkrXWUATp9fX0Acq2UUkVJWlQrhW+17c5E5JZOtSq5M30OPHZ1EE/eWMUmk0GPw4TfeNsQ2q3NkxysvCZbjTTeqZEwPIqiYLVaYbVa0dPTI/9c6cxQzt22WCw531ObzVaz3IhailxiV24eiMgllIQWK7miKGJrawsejwcmkwlnzpwpKdX3MAu23aTHB2f7D32eqV4Hbq/GYLLvLs5iKQ7H2i2wm2pXpajE6jvYYcUfffQM/tG9jVgqiwuD7ZjptSEQCMDn86GnpydvP7PaNFsldzWSxIueECJbGxgyp3Bm5kTZvcs7icw+ax8oCpFEZd/JRu/JJTQGh9mdGYbBxsYGPB4POI7LqSQ5HA7VkmOJyC2daoYBvvdkD95xogvRZBYdNiP0uub6bGo141UtCjkzksmknPC8sbGBeDwOvV6/73tajTUCx3EHOvLUglRymwsico8YlV7YtVbJ3dnZgdvthk6nw/T0dFknJ7Xmyz52bRj/x9OvY4vdFSImvQ6ffvtoTRdTlb6XLrsJHzrXD1EUsbGxgZ/85FW0t7cfavlWk0av5Cq3/QevB/G7311ANsvBYDTC2WrBfz3XUvYxMXu8DX97KygHLCUzPCgAJ/tLH9WkpFy7stynXoVjnIjco0O+RTXP80gkEmAYBtFoFCsrK3JyrFRNKreHkIjc0ql24r1Jr8tpjWkmeJ5vyGkBSnQ6HWw22z53XCaTkau+6+vr8g0qabSRsh+/kn1Qq3RlInKbCyJyCSWhlUpuNBqF2+0Gx3GYnJxER0dH2c+lVpjWWLcNT3z8HG74wxAE4OJQGzpstU0YVSO0aWtrCy6XCxaLBefOnYPdbldp64qjGdKVeZ6HZ3EJ//nvfDDoDeh50/4UYjJ48n8F8MV3T5T1/JeG2vAvZvvx9K3g7pgnHYVPv30EA22V3YDQoqAkIuRoQ9N03nmhqVRKriZJdmeapnMqSXa7/cBqEhG5pdOoY920QKOOXSwGo9GIjo6OnDWYsh+fYRgEg0EkEgkYDIZ948cMhuJs6bW0K/f3H+7cIzQGROQSSsJgMCCVqt/sSYZh4PF4kEwmMTExga6urooXK1JPrhq0WAx451TP4Q+sEvneiyCIuP5aEE+/GgQniHjvSSceuTCwL6goEonA5XIBQFn9omrRyOnKFEUhkUjg+eefR9bcDujNaLe/FdhhNdG4vRqr6Pl/9d5hfOBsLzZiaQx1WtFaYbIyoE27MlB5oJInFMezr2+CSXG4d7wT18ba5RmVhMZDaXdW9hAqq0nBYBAsy+bYnaVFtWR3JiK3dNQSuaIo4u/vbuEvf7qGaJLDldF2/MqV46qcx7RKo9mVK0XZjy8hiqL8PWUYBqurq2BZFoIg5K367v1+1lLknjx5suqvQ6gNROQeMSq9sNdrhJA0j5VhGIyPj8PpdKq2SGmksUiHkU8g/s+bq/jjf1qCWU9DRwF/+rwf0WQWv/62UQC7w8/dbjeSySQmJyfR2dlZ1wVgo1Zyt7a2cOfOHWSzWczNzQF6E8wvv4QUJ8DyZlBZMsPjwmDlNw+cLWY4W8qbrZiPWlZy3wgy+JFrGzodhXdMduKEM79ToNJtur0aw299ewFZXoSOAp73hvHIhT58Yu542c+pZbQo2pJZHi8shrEdz+Jknx3TvfaqbGe+ahLP83I1KRKJIBAIIJlMwmKxIJ1OY319Ha2trZodmaI11BK5zy+G8Qc/9MGo10Gvo/D3d7ewHkvjv3xwSpPHsBocNZGbD4qiYDKZYDKZ0NnZKf9c+T3dm8KuFL7ZbLYmIjcWi5HgqSaCiFxCSRgMhpralZPJJLxeL8LhMEZHR1WdxyqhVk+uFsgncv/6lTVYDbSc/KyndXjm9gb+5XknVvw+hMNhTExMqHrjoBIarZIbi8WwsLAAURQxPj6OQCAAq3U34feTVwbx//zjEtg0BwqA3azHo5e1J7JK6ckNMWnQOqosK/5zri38nz/wQRBFACKeub2Bf/fgOK6O7W83qFTk/sXLa+AFoPPN7cxwAr51ax2/MNsnj8kiVI9oMosvfOsOViMpuXL6yPk+/PJ8bY5/mqbR0tKSM/NSGpnyyiuvIJ1Ow+fzIR6Py3ZnpY2y2gF7jYZaIvfbtzdA6yjY37weGfU6vB5kEAinMNhRm9yHWkNEbmEKfU+lFHaWZREIBBCLxXDr1q197gyz2azquiUWi5Ge3CaCXOmPGI1SyU2n01hcXEQoFMLIyAhmZmaq1g+k1+uRTCar8ty1Jp9ATGUF0Iq0SkoUEU+mcOOllzE9MVrVfVsOjZKunEgk4Ha7wbIsJicn0dXVhWQyieXlZfkxH5ztxwmnAy8thWEz63HfeCe6NRiuUozI3WYzePzvFvDqShQUgKtjnfjCAyMoNjxcEEU88ZMA9DRgN+1aE5kUh2+8ECgocishGE3DpH/ruDbQFJi0iEgyS0RuDfj27Q0Ewkl0Wg2gKApZXsBfvRLEe092o1dFF0IpSCNTdDodRkdH5fNePrszz/Ow2Ww5wletdOdGRBAEVSppGU6AchdSACACnKC9dgm14Hme3DQpgXwp7C+88AIuXLggz/Xd3t6G3+9HKpWCxWLZN9e33JsKJHiquSBXekJJVLuSm8lk4PP5sL6+jqGhIVy9erXqd0Cb3a58/4kuPPPaOmgdhWwmjW02gwvHHXjgbRc1eXdZ63blTCaDxcVFbG5u7nMX5Nv26T4HpvsqSz+uNsXcWPgv33fjViCCdqsRIoB/8myjzULj1+8dLOo1MpyAnUSuwDQbdNiIpSG8OZd5L5VUci8NteLbtzdgMehAURRiKQ5ddiP6WusjsKqJFvup726wMOgo+bthoHWgKR5L28m6iVyJvT25h9mdw+Fwjt1576xQLZ5H1UatSu67p7vxh88tIc0J0OsoRJJZDHVYMNzZnFVcoDnSleuNIAgwGAwwGo05dmLJnSHdpFLO3t4rfE0m06E3qaLRaE7KO6GxISL3iKHVSi7HcVhaWsLKygqOHz+Oq1ev1qT/Aig9eGqbzeCHCyFEk1lcGm7HmYHyR8KoTT6R+ytXBrGyuYP/5Y+BpmnMjffg3713SrMLMzWDwNSE53n4/X4EAgH5GN27D7Uu0AtxWCWXTXN42R9Gm9UouwLsJho/dG0XLXLNBhpjXTZ4Q3G023YruWyKx0yfPa/ArdSu/LFLA7izzmJxOwEdRcGs1+GL7xxtuhmcWuWE046X/FFZUGZ5AbyIhrGkHmR3lsJzQqEQWJaFXq/PEb4Oh6Po1NhGQRAEVa5zD850Y4NJ4+lXN8CmBcz02fGFB0abOhCumdOVa0m+409yZ1it1pwwOmn2NsuyCIVC8Pl8yGQyOVVfafa2cq1ZisgVBAGf/exn8eyzz4KiKHzuc5/Dpz/96byP/cxnPoPr16/D7/fj5s2bmJ2dLep36XQaX/jCF/C9730PZrMZZ8+exZNPPlnU9hGIyCWUiNoChOd5LC8vY3l5GX19fbh69WrNFwel9OQGdhL49F++hliKAy+K+IsbK/jlK4N4dK64hX61UVqvRVFEMBiEx+PBvzrTiS8+OA290Yguu/bsskq01pMriiJWV1exuLiInp4ezM/PF7SeNbLIPUhQ6nUU9LQOgiACb4pEXhRhM5Z2CfnM24fxW99eQCSx6wZpterx6/cNl7VNh9FmNeC/PXwSbwQZJLMCTvU7YDWShWat+LlTTvzItY1g9K1K/S/M9qJfI5X0cgRboQW1MjU2GAzC7XaD5/mcKpLD4VC9f7CWiKKoilDTURQ+MXccH704gDQnoOUItA6QntzK4Hm+5O9NvtnbgiAgmUzKI8g2NzfxB3/wB3jllVcwOTmJmZkZ0DSNSCQi52ocxJNPPok33ngDLpcL0WgU586dw/333583nfnDH/4wvvSlL+HatWsl/e7LX/4yKIqCy+UCRVFYX18vaT8cdZr/7EJQFbUu0IIgYGVlBT6fD06nE3NzczCZ6iO+SqlOP3kjgGgyK4fupDkBf/5iAD9/pg9t1vrfuZduQmxubsLtdsNut+PChQv7BrhrGa0IRVEU5ZnBdrsdFy9ePPTCp5VtL5XDRgiZDTTef9qJv70ZhMWgg4jdY/+XLveV9DoTPTb82aNn8Upgt6/33PHWA4VnpTZcWkfh9EDL4Q8kqE671YCvPnIK/+zdkdOVT/dr27ZfLgfZnRmGQTgcxvLystw/KFV9HQ4HbDZbQ1hZ1arkSpj0upye+WaGiNzK4HleFWefTqeDzWbLWQ/92Z/9GdbW1vDyyy/j1q1bYFkW73vf+7C9vY3p6WmcPXtW/jc1NZVThHnqqafw2GOPgaZpdHR04CMf+Qi++c1v4vHHH9/32vfdd1/B7Sr0u3g8jm984xtYWVmRv3u9vb3lvv0jCRG5Rww1LlJS/145J21BELC2tobFxUV0dnbi8uXLMJvre2e/FJG7sMHmXJhNeh2SWR7rsZQmRG4ymUQwGEQ8Hsfp06dzrHaNghYqudFoFAsLC6AoqqT9WEpKsZYoZrt/7d4RtFsMePb1TRhoCh+a7cP7T/WAL9HZYTXSuJYnaCrfNhEaG6uRxrunu+u9GXXhILuzVEmS7M4Gg2FfaqzW7M5q9eQeRYjIrYxqz8jt7+/HQw89hHe84x14+umncevWLWQyGdy9exevvvoqbt26hT//8z/H3bt38Td/8ze4fPkyAGB5eRlDQ0Py8wwPD+PFF19Ubbu8Xi86Ojrwla98BT/4wQ9gsVjw27/923jggQdUe41mh4jcI0ilNkCDwQCO40o6aYuiiPX1dXi9XrS0tBRVFasVpViwzwy0wreVgNW422eWyvIw0Doca6tvnxnDMHC5XEgkEnLVsVGpZzU0kUjI+1FKTC6FRhVmxZwTjHodHp3LtebzPI9q3Y5o1H1JIBRCaXd2Op3yz9PptNw/uLq6CpZlIQhC1cellAIRueVDRG5lVFvkSkQiETnUymg04lOf+hTcbnfOY97//vcDAG7evFn17eE4Dn6/HzMzM/i93/s93Lx5E+9617vw+uuv55w/CIUhIpdQMnq9Htlstih7sSiKCIVCcLvdsFqtmJ2dhd1ur8FWFk8pldyPXz6OG0thbDJpALvjDz73wBjsdeorSiQS8Hg8iMVimJiYgNFohM/nq8u2qEU9KrmZTAZerxehUAjj4+Po6+s7UiLrMLtyPkRRBMdx8g0vZcI0ofYcpeO12TCZTDCZTOjs7JR/xvO8LHx3dnbkcSlWqzVH+NbK7kxEbvkQkVsZtRK50Wg0J7n5hRdeOPDxg4OD8Pv9mJ+fBwAsLS1hcFC9fJbBwUHodDp87GMfAwCcO3cOIyMjuH37NhG5RUJE7hFErUruYWxvb8PlcsFoNGraOlvKAr/HYcKf/uJ5/MS7jViKw4XBNgx11r4inU6n4fV6sbW1hbGxMZw+fRoURYFhmJoIRF4Q8WP3Fm4shdHbYsbPnXaqFmhVy0ouz/Nyqvfg4KAqI6saUWyUck6QHicdZ3s/L+ncoNPtju6hKIosjquMFkcIESqDpmm0trbuG5eSSCTkkKuNjQ3E43HZ7qxMeFbb7kxEbvmQfVcZtbpJEIlESpqR+/DDD+PrX/86Hn74YUSjUTz11FN45plnVNuerq4uPPDAA/je976H973vffD5fPD5fJienlbtNZodInIJJXNY5TMcDssWj6mpqYaZObZ3dmIhrEYa75zuOfRx1SCbzWJpaQlra2sYGhrCtWvXci6etaqCfuW7C/j+G6E39xnwP19Zxdc/fg69KiSnFjOztVIEQcDq6qocfHblyhVVF4XFHktaodheYlEUIQiC/FiapuU77IIgyL8XRTHnvyURTYQvod408g0BiqLk4Jx8dmeGYfbZnZXCtxK7MxFq5UMquZVRr0ruYTz66KN46aWXMDExAYqi8PnPfx6nT58GAFy/fh3Xr1/HE088AQD41Kc+he985ztYX1/Hgw8+CIfDAY/Hc+jv/viP/xif/OQn8Zu/+ZvQ6XT42te+hoGBAZXfefNCRC6hZCS78l5isRjcbjcymQwmJyfR0dHRMAt9mqY1PctOOWqpv7+/4BzhUsYhlcvSdgLffyMEu4mWZ6aGk1n89Sur+Df3j1X8/NJnUQ0k+7zL5UJLSwsuXboEi0XdfmpJ0DXKsQ8c7mbYK24lobr3OQDkfIekx/M8nyN8AVLxJdSHRvtuFsNBdmeGYbC9vZ1jd1YK32LtzkTklo90g49QHrUUuaVUcmmaxh/90R/l/d1DDz2Ehx56SP7/v/a1rxV8noN+Nzo6ih/96EdFbxMhFyJyjyCVXuD32pVZloXb7UYikcDExAS6u7sbbhEhhU9pTeQq06i7u7sPHbVUi0ruaiQJvQ6ywAUAmqLgDcVVef5qvYdIJIKFhQXQNI2zZ8/C4ajOOBPJvttIi5pCduVixO1BSPtAuS+k55Ke96CKL4GgNs0ocvORz+68d06o0u6sFL4Oh2OfqGi0cxqheeA4ruBsejWJxWIlVXIJ2oeIXELJSJVcZejR2NgYent7G3bxUIsKaCmIooiNjQ14PJ6S0qhrYfU94bRDEIEMJ8Co360ACqKIC4PF3wE9CLV7cuPxOFwuF5LJJE6cOJFT7agGjTgrd6/I3Ws7LlXcHkQ+4Qvk2p05jpNnA2YyGXn7SMAVoVKOisjNR745oaIoIpPJ7LM7i6Ioi1673Q6O447sfquERrbHawWO41R3XOUjGo2iu/tojjxrVojIPYKocaEKBoNYWVnB6OgoTp061fALzlISlquNFNhlMplKrjjWYhHSZTfhN94+iq8+t4gML0AQgSmnAx8616/K86tVyZXCuba3tzE+Pl6zmzCNKHKlbVaGSinFba32m2Qn93q96Orqwj333AO9Xp+3z1f5d8TuTCiWoyxy80FRVF67M8dxiMfjst05nU7jxo0bsNlsORVfq9VKvncHQPpxK4fn+ZrZlScmJqr+OoTaQUQuoWgymQwWFxextrYGm82G+fn5prm4lTIrt1pEo1G4XC4IglBxYFe1F3KPXBjA/Eg7XluNoctuxMWh9hz7ciVUmv7NcRyWlpawurqKoaEhTE1N1fQ4bUSRKwVPVWJNrpRIJCLf3Jmdnc2pNu3t8z0o4Eq57UT4EvZCRG5x6PX6HLvz9vY2Ll++jHQ6Ldud19fXkUgkYDQa9830rYUoaQSIzbtyatWTS+zKzQc5Cx1BSr3AKxN9BwcHcfr0aaytrTXVibueldx4PA632414PI7JyUl0dXVVtAiTKmLVXsgd77DieEftbw9Y4QAAIABJREFUxycVQhAErKyswOfzoa+vT/XE5GJpNJErHSvRaBS3bt1CS0sLWlpa4HA4ipqFXSnJZFLu6ZcC6w6CBFwRKoGI3PLR6/XQ6/V57c6S8A0EAmBZFgD2CV+TyXTk9j2p5FZOLYOnGmUaCKE4iMglFITjOPj9fgQCARw7dkxO9I3FYnWveqpNPURuKpWCx+NBOBzG2NgY+vr6VFkASFXpWgQ1aAFRFLG5uQm32422tjZcvnwZZnPlo4zKpVFErjJUymQy4dq1a3Jf3vr6OtxuNziOkxepDocDLS0tFY0hUcJxHHw+HzY2NjA6OlrR8V9MwJX034Wsznv/vtE4auKhXIjIVRel3bmrq0v+OcdxYFkWLMsiFArB5/Mhk8nAarXmCN9mtzsTkVs5tRK5pc7JJWgfInIJ++B5HoFAAH6/H729vbhy5UqOYCo0QqiRqWXwVDabxeLiItbX1zEyMoKZmRlVL/K1mpVbTST77GH7JRwOY2FhAQaDoaqJyaVQ7MzZepHP4itVN9vb23PuZCvHkOzs7MhjSGw2myx8HQ4HbDZb0cJBmlHs9/vR39+P+fn5qiwCiwm4UlZ894rfQn+vRUi4TfEQkVsb9Ho92trackSDIAhIJBLyOSUYDObYnZUJz81idyYit3JqtQ9jsRgRuU1Gc5xFCCVR6AIvLT59Pt+B42r2jhBqBmpRyeV5Hn6/H8vLyzh+/HjBWbeV0gwiV5qVW0hgsCwLl8uFdDqNEydOHGpxrSWHzZytF+WEShUaQ5JIJMAwDGKxGFZXV5FIJGA2m+Vqr7RY3fv5bW1twe12y4nh9ai4F7I77+3zlfaT8u+I3bnxISK3dNQ6n+l0OlnE9vb2ys+dTqdl4bvX7iydSxwOB4xGY8N9dkTkVk4te3KJXbm5ICKXAFEUEQwG4fV60d7ejkuXLh0Y166lJGK1oGkaqVSqKs+t7BXNVxlXG62NQyoHSajvvbApLd4TExNwOp2aW/Ro0a5c6bxbJcqFal9fn/z80vxNhmH2zd80Go3Y2dkBTdM4deqUJiruSooVvkq7s/ImARG+jQMRuaVTzX1GURTMZjPMZnNeuzPDMPvszsqKr9btzkTkqkO1v7OiKCIejxc1qpHQOBCRewSRThbKWawOhwPnz5/PCZQ46O+1WKmqhGoId1EUsb6+Do/Hg/b29pr1ijZDJXevUJT6N9fW1jA8PKy6xVtNtCRy1RS3B0FRFKxWK6xWK5xOp/zzWCwGj8eDUCgEq9WKVCqF1157LafiK4lgrUECrpoTInJLpx4JwQfZnaWbaUq7s7Lia7PZNGN35nmenAcqoFZrTem8QD6r5kIbZwFCTZFmUbrdblgslrJ6GYvtmWwU1Kx+iqIo2zKtVivOnTsHu92uynMXQzOIXOk9CIKAQCCApaUl9Pf3V83irSZaELm1EreF4Hkey8vL8hin2dlZ+VyRzWZlq/Pa2hoYhoEgCPICVZnsrDUxUkzAVb6Kr/Q3zRBw1egQkVs6WrnWK10kEnvtzsvLy2BZFhRFyY+tp91ZEARSya2AWs3ITaVSqoUqErSDtleLhKqxtbWFkydPlj0TTOrL1WIFphzUquRGIhEsLCxAp9NVtH8roRlELkVR2NzcxOrqKjo6OuqemFwK9RS5hUKlavn66+vr8Hq96OnpweXLl/eNcTIYDOjo6Mjpo+Z5Xq7ObG5uwuv1IpPJ7Et2tlgsmluEHKWAq2aAiNzS0YrIzUchu3M2m81Jd15cXEQ2m82xOzscDlit1qoeD8SuXBkcx9Vk/0UiETIjtwkhIvcIQlEUZmZmKrKBSAnLROTuwjAM3G430uk0Jicn0dnZqeLWlYY0QqhR2dnZQTQaBc/zNa+Cq0E9RG45oVJqEw6H4XK5YLFYcP78+ZJ6m2iazmtNjMfjiMViiEQiCAQCSCaTsFgsOVZnm82myQV4qQFXUhsIsTtXFyJyS0fLIrcQBoNhX1r8Xrvz2tqaHJqnrPiqaXeuVSWyWanljFySrNx8kG/eEaXSvtpmS1guVxgmk0l4PB5Eo1GMj49rIgipUSu5DMPA5XIhm82ipaUFo6OjDSdwgdqPEKq3NTmRSMDtdiOVSuHEiROqLRR0Op0sZCVEUcxJdg4Gg4jH4zCZTPuSnbVYPSkn4Er6OyJ81YGI3NIRBKEp9lkhu3MqlZKrvn6/HyzL5jxWOqfkmzZxGDzPl/V3hF1qKXJbWlqq/jqE2kJELqEsmi1hudSe3EwmA6/Xi1AohNHRUZw8eVIzi89GE7lSYnIkEsHExAR6enrw6u2fIdugx1etKrn1FrfZbBY+nw+bm5sYGxtDb29v1V+foijYbDbYbLacESSpVEquzoRCIbAsC71enzPL1+Fw7LNOa4GDAq729vkC+QOugOqnjzYLROSWjiiKmrxppAYURcFiscBisaC7u1v+udLuvLGxAa/Xi2w2C5vNliN8D7M7E7tyZdTKrhyNRolduQkhIveIUulF3mAwIJvNqrQ19adY0c5xHJaWlrC6uorBwUFcvXpVcxcwmqYb4rORRFIwGMTIyAhmZmYQjKXxq0/ewo2lHdiM2/iVe1P45fnBhlqUVlvk1lvcSiOx/H4/jh07hvn5+bp+B5SL1J6eHvnnmUwGsVgMDMNgZWUFDMNAFMV9yc5arLIc1OerFL2S/TKZTILneWSzWRJwdQhE5JZOs1RyS6GQ3Tkej4NlWUSj0ZwZ4Urhq3SSkHTlyiB2ZUIlEJFLKItmq+QeJkwEQcDy8jL8fj/6+/tx5coVTVaFAO1XcpX7cmBgQE5MFgQRv/4Xr2I5nIReB6Q4Af/9xz70OEz4udO99d7sotHpdFX5bmghVEpKDW9ra8M999yjSYEoYTQa0dXVtW/2plTxXV9fh9vtBsdx+5KdtZqyqQyqksZqbWxsYHx8HFarlQRcFQERuaWjRk/uFpvB9+6EkMzyeNt4JyZ6Dh9XqDWULRTKGeGS3ZlhGGxvb+fYnROJBKxWK1paWpomw6SW1KqnmYjc5oSIXEJZSMFTzY4oilhbW4PX60VXVxfm5uY0vbAH1B2HpCZS8q7b7c67L99YZ7ASScFIUxCEXQGXFUT81curDSdy1ZzttzdUCqh99Vbql6YoCmfOnGnIXmlg97uxtzrD87y8QN3a2oLP50M6nYbNZstJdq52CmuxiKKIYDCIxcVF9PX15a2kk4CrwhCRWzqVity76yx+9Zu3keUFiCLwxPMB/NZ7xvHzp52H/7HGOczu7HK5EIlEsLGxIdudlenOWkyM1xK1rOQqrwuE5oCI3COKGnblZDKp0tZoA6maK4mUUCgEl8sFh8OBixcvlpQWW0+0WMnd3t7GwsICLBYLLly4AJvt4Lv4FACIovRfOaxFUvjhQgi0jsK7prvRZdfWTQc17cpqW5M9oTj+7IVlrIRTuHeiAx+9eAxWY2GrcSqVgtfrRSwWw8TERE5VtFmgaRqtra05/ViSDTgWiyEWi+XYEpVWZ7vdXlOBKI0ok75HFosl7+NKCbgC8vf5NqvwJSK3dCoVuf/tOR+SWR4m/ZuzsnkB//UfFvHgdDeM+uY8ziS7s9FoxPj4OGw2m2x3Zhhmn91ZKXxtNpvm2qDqBcdxNVl7RaNRjIyMVP11CLWFiFxCWTRjJVeyYEt3Xw0GA86cOdNwiXtaErkMw2BhYQE8z2NmZuZAO9BMrwPH2sxYDidBUwAviKB1Ojx8YUB+zD+6t/C5v74NCgAFCr//Dx488fFzOHNMO4ERaojcavTdLm7F8ej/eAVpfvc5Xw8yeN4TxjcePbvvuXmex9LSEoLBIIaGhjA9Pd20oicfhVJYk8mknOy8sbEBlmVhNBpzKr4Oh0P1BWoqlYLb7UY8HseJEyfKqjiUEnDVzBVfInJLp1KRu7ARB617a5/rdRTiGR4bTBrH2/PfqGkWlMFThRLjpeA8lmVz7M7KHl+Hw3Ek7c61sivHYrGGW+sRDoeI3COKGpXcZurJlbh58yZEUcTk5CQ6OjrqvTlloYU5uclkEm63G7FYDJOTk+ju7j70mNPpKPz3f3kWv/3tu7ixtAOrQYfH7h3Bz71paRMEEf/pOwvgBREGenfBlcoK+Mp3XfjLX7lU9fdULJWI3GqGSj15YwUZXoDxzX0niiJeW4vh9hqDMwMt8s8kK6zT6cTc3ByZ8fgmFEXBarXCarXC6dw9JkVRRDqdlvt8/X4/GIbJWcxK4recHn6e5+H3+7G2toaRkRGcOnVKVYF2UMCV8lhUjjSSxC9N0w0ZcEVEbunkE7nXX1vHnzwfQDSZxZXRdnzxnWPosucXYSecNry8HIX+TaHLCSJsRhpOh7ZcONXgsHTlQsF52WxWFr4bGxvweDxyfoAy5KrZ7c61TFcmduXmg6xeCGXRTJVcac5nIpHAxMQEhoaGGvqiUc9KbjabxeLiItbX1zE2NoZTp06VtAAeaLPg64+egz+wikScwfTUkPy7aCqLDSYNI51bEVjYYFV9D5VSjsitRajUaiQFZaswRVHQU8AmkwYA7OzswOVywWazHWiFJbwFRVEwm80wm837+vGkZOe1tTUsLCxAEATY7fZ9yc75PmdRFLG5uQmPx4Pu7m5cvny5pkF3xdidlcd4I9mdicgtnb0i9x8WtvA73/WAF3cbSn64sI2l7ST+8l+dy7tvP3f/CB77i7d6cilQ+N8fGG1aq7KSctOVDQYDOjo6cm628zwvzwmPRCIIBAJIJpOwWCw54reZ7M4kXZlQCUTkHlFIJRdIp9Pwer3Y2trC+Pg4BEFAS0tLwy+A6iFyeZ7H8vIylpeXcezYMVy7dq2ii6zJQCO+Ryi2mA1otxoQTWZhoN+qCIx1aSulsxSRW8tQqbdPdOGV5ai8yOf43bEgJzoNuHXrFjKZDKampsiFXgUMBgM6OzvR2dkp/0xqhWAYBpubmzlzN5VWZ47j4HK5QNM0ZmdnD+1frxWl9PnW2u4cT3P4iS8MvU6H+ZE2mA2Fzz1E5JbOXpH7zZfXwCkcNaIowredwMJGHFO9+0PpTjjt+NZjF+R05bdPdGK8WxvHdbVRI5lagqbpvHbnZDIpz/Td2tpCPB4HTdP7xho1ot2ZBE8RKoGIXEJZNPIIIeV81uHhYUxNTUGn02FnZ0czvayVUEuRK9lbpYrT/Py8KhdSmqb3CUVaR+HLD07it/6/N5DlBegoCgaawpcenKj49dSEoqiiRG6t593+wrk+/GRxBz9Z3IGB3n2tXznnwLLrdYyNjcHpdJLFfxXR6/Voa2vLuYkgCEJOsvPdu3dzhG80untTwmq1arIyelCfr3TjptoBV7dXY/jXf/kzcMLuTSKrkcYTHzuD0a78YTVE5JbOXqGWyu6/vlAUhRRX+LzXZTfiY5cGCv6+manm8aZso9g7J1wSvsFgECzLgud52Gy2hrI7k0ouoRKIyCWURSPalZXVRuV8VolGFu5K8gnEarC1tQWXywWr1ap6+rROp8sr1N93yonRLiu+98YmDDoK7z3lxIgGK7kHjRCqtbiVMOp1+L8/choL6wxue1dgS4cwPdqO48fPNI21rdGQAq7C4TB2dnYwMjKCgYEBpFIp2e4cDAYRj8dhMplyKr52u12Tn1u+Pt9qBVyJooj/8IwL8QwPA737PNGkgMf/zo0/ffRswb/R8qJeiwiCkHOtfOiME+5QAoIggqIATgS6rHqc6ncc8CxHj3oea0ajMa/dOR6Pg2VZhMPhfXZn6byiJbtzLXpyRVEEy7I5FXJCc0BE7hGl0hOv2rNAq4kgCFhdXYXP50NPT0/BaqMWApvUQFo0VotYLIaFhQWIooiTJ0/mjF5Ri4OE+lSvA1O92r0YFbIr10vcKl8/FAphe9GDkx3tGBuba0j7WjMh3Shqb2/H5cuX5c/DZrPBZrOhr68PQG4CaywWQygUAsuy0Ov1OcLX4XBoMiislIArYHdhW0zAFZPm4d9JQmrtpCgKFES8tsYU3BYicktn7z77hdk+BMIp/NVP15AVRIx0WvG7H5iSg6UIuwiCoKljjaZptLS05KQIK+3ODMMgFArltTs7HI6a5gIot69WgluLbhlCZWjvakioGZWKIenvtXQSVyKKopxK2NraikuXLh0YptMslVwJtT8bKaCLZVlMTk6iq6urap+9lsYglcpekVuLUKnDkG5M6PV6nDlzJmc0DqH2xONxuFwu8DyP06dPH1pBKJTAmslk5IpvIBAAw+yKu73Jzlq9mVFKwJXyWiVVfc16CjYTjWSGh5RHJ4iA01H4/Wr5mqVV9tqVaR2FLzwwin997xDiaQ5ddiPZp3kQBEEzFdFCHGZ3ltwkbrdbtjsr+3yraXeuVSElnU5r9hxJqAwicgllI4nCetzdOwypQmKxWDA7O1vUol6v1yOVStVg66qPVGlX4+KTyWSwuLiIzc1NjI6O4syZM1Vf0Kgxa7ZeKLddFMWahEoVIpVKwePxgGEYTE5O5gQhEWqPlAcQCoUwPj6Onp6eio4Ho9GIrq4udHV15byGNNJofX0dbrdbHj2irPiazeZDXzvLC7gZiEJHUZg93gJ9DSodpQRcQRTxqSvH8If/uCz35NIUhc/eP1Lw+YnILZ1C4UlWIw2rUdsirp4cNj5Iyxxkd2YYZp/dWVnxtdlsqlRF1QztOohoNIrW1lZyXmhCiMg9wlRayZX6crUkcqPRKFwuF0RRxMzMTElBAnq9vmGrh3uRrNeV3J2UZnQGAgEcP34cV69eraltqFE/C0nk8jxfN2syx3FYWlrC+vo6hoeHcfLkSXIBryOiKGJ1dRVLS0vo7+/H3Nxc1b5LhUaPKAOufD4f0um0XJWRKr5Wq1U+TryhOD755C1Ek7vulg6rAd94dBbDner13hfLQQFXH7vnGIY6rfj27U3QOuBfnHHi3DEHMplM3j5fqf+XUDy1EhvNRiOL3HwcZHeWZvrubaVQjjYqda3I83zNQqeq0XZFqD9E5BLKRktjhFiWhdvtRjKZlCtWpS7qm8muXIndV1qQLy4uHtjDXE1qFZ6lNlKVKJFI4ObNm/KCoKWlBSaTqSavv7a2Bp/Ph97eXszNzWmyR/MoEQ6HsbCwALvdjosXL8JsNtd8G2iaRmtra85CThAEuSoTi8WwsrKCZDIJs9mMlpYWfPmHO9hmM/Js5U02g//w7bv4fz9xvubbnw9ln+/9U07cP+XcF3Al/bfyZi7P8zkJ6ES8HQ4RueXRbCI3H0q7s9PplH+eyWRk4RsMBuFyueRZ4cpe34McJbUInQJIsnIzQ1Y/hLLRQsKyZMcMh8MYHx9Hb29v2RWrZgmeAsoTuaIoyjZvaUGuZmJyKTRaJVcZnqPT6XDt2rWcmagej0e2jEpVM0n4qlVh3d7ehtvtrquYIrxFMpmUb7xpcf6wTqcrOHNzKxyFeysIAKDe/D+CIOKV5Si2d8Joa23RzOI9nubwVz9dw6urMZzqd+CRC/1oMedWjCRnhd/vx/r6OqampnLaCIDd/VEoIOuoQ0RueRwFkVsIo9G4b1a45ChhWRY7Ozvw+/1IpVKwWq054leyO9dqfFAkEiGV3CaFiNwjTKWL63pWcqU+0Y2NDYyMjGBmZqbii3Cz2ZVLeS/RaBQLCwugKAqnT5/OsSPVg0ap5Cr7A6WFoGSN3DsTtZBlVCl8HQ5HyUEeUogRx3GYnp4mF+s6w/M8lpaWEAwGMTo6ir6+voaxiktVmQGzBTaTG4k0D+Wm24w6LPuXcCcezxHJ0rFb69aVVJbHI0/8FGvRFNKcgB+7t/HXr6zhbz91T06vqHQDqLOzE3NzczAYDHn7fPMJX7Xm+TYyROSWB8/zZL8pyOcoEUURiURCFr+bm5uIx+MwGAzyGjMcDsNut1ft/EIquc0LEbmEsqlHJZfjOPj9fqysrOD48eO4du2aandKj6JdOZFIwOVyIZFIyInJWqARRMHekUDSgrgQB1lGY7EYwuGwfGf7oF5JCelGz87ODsbGxioOMSJUhjLN3el0NrRVnNZR+NVrQ/ijHy8hw+0e30a9Dr9x/yjOnTsO4C07IsMwWF1dBcMwEARhX7JzNW36378TQvBNgQsAaU5AiMngOz/bwMPn++XzG8dx+1LFSwm42hscd9SELxG55dEI6cr1hqIoeWSa0u6cTqexsrKCcDiM1dVVsCxbst25WEhPbvPSmFdggio0UiVXEAQEAgEsLS2ht7cXV65cUf2uXjOJ3MOq0plMBl6vV0551WK1SatzmNWcd5vPMioIAhKJBGKxWE6vpMViQUtLC+x2O1iWxcbGBoaGhjA3N0cWoHVGGtFkMBhw/vz5utn81eSTVwbR12rGUz9dhY6i8L9dHMB7Zt4aMZLPjshxHFiWRSwWw+bmJrxeL7LZLGw2W06ys1pjR/zbCTlVWSLNCfBtxeH1ehEMBjE+Pg6n01nU6x0UcCVVeZVjjaTrRbNXfInILY+jbFeuFJPJJJ9Hx8bGAOTanbe3t3PszsqQq1LTnaPRKNrb26vyPgj1hYhcQtno9Xqk0+mqvoYoiggGg/B4POjs7MTly5er1mvYTCK3UCVXslKurKxgcHCwponJ5aClcR9qituD0Ol08sVa+drxeBwrKytwuVygaVquHCaTSblqptboBkJxpNNpeL1eRKPRphvRRFEU3n/Kifefch7+4DfR6/X7bPqCIMg2faVbQVqYKt0KpR67s8dbodvzFTTQFKyJdQiCOsFr+fp09wZc7a34ApAFr3SOaOTvJRG55UFEbmXs7ck9zO7MMAw2NjZku7Oy4nuQ3TkWi2FgYKDq74dQe4jIPcKoUcllWValrclFGYJks9lw4cIF2Gy2qryWRCPPZt3LXpErCAJWV1fh8/ngdDqrUglXGzVn/VZCrcTtQcRiMbhcLhgMBtxzzz2w2Ww5oxtisRg2NjbAsixMJlNOn6TdbicLLZURBAHLy8sIBAIYGhrC1NQUEQEF0Ol0eceOSMnODMMgGAwiHo/DbDbn2J0PO3avjXXggalu/P2dEPQ6IMuLONVF4xcfOIcWx+Gz0St5T8r/ldgreJXzspV/22gBV0TklgcRuZVRzBjEfHZnURSRyWRk4bvX7pxKpeD1enHp0iWMjo6W1JMrCAI++9nP4tlnnwVFUfjc5z6HT3/603kf+5nPfAbXr1+H3+/HzZs3MTs7W9Tvnn32Wfz7f//vIQgCOI7DF7/4RfzSL/1SUdtHyIWIXELZVKvyGQ6H5WrVqVOnSK9EGUgiVxRFhEIhuFwutLS04NKlS7BYLPXevKKQbjrUa3FVKFSqliSTSXg8HsTjcUxOTubMPs03ukEURaRSKVn4KmcWSkJDEhBk8VU60s03t9uNjo4OXL58uebjtZoBiqLk6kpfXx+Ag49d5U0bh8MhV3coisJ//sAJ3D8A3FrawtzUEN5xZqhu54xi+3ylc7M0q17rdmct3GxsRHie1/zNZC3DcVxZrR8URcFkMsFkMu1rp4jH43jttdfw3e9+F7//+7+PUCiEtrY2RCIRJBIJzM7OYnp6uuDn9uSTT+KNN96Ay+VCNBrFuXPncP/99+PkyZP7HvvhD38YX/rSl3Dt2rWifyeKIj7+8Y/jueeew5kzZ7C0tISpqSl86EMfymlrIhQHEbmEslE7eIphGLhcLmQymbpZ/+otrNSCpmmwLIsbN26ApmmcPXu24U6QklCvR3hPqaFSasNxHHw+HzY2NjA6OopTp04V9foURcFiscBisaCn563+yXQ6Lff4Li0tgWEY0DS9T/g2alBSLWBZFi6XC6Io7gsxIlTOQceuVPFdXl4GwzCgKAoOhwMURWFnZwcTvb147yX1QgjVpJyAK+nvtCJ8m+GaWA9IunJlqD0nV6/Xo7W1Fffeey/uvfdeALv5JI888gjOnTuHn/3sZ3jyySdx584ddHd3Y3Z2FrOzs3j3u9+NqakpAMBTTz2Fxx57DDRNo6OjAx/5yEfwzW9+E48//vi+17vvvvsKbstBv6MoCpFIBMCui6uzs7OqAX7NDFnRHGG0EjyVSCTg8XgQi8UwMTFR15RYaVZuI1dn4vE41tbWkE6ncebMmYbtE6zHrNx6W5MFQcDa2hqWlpbQ19eH+fl5VS7yJpMJ3d3d6O7uln+WyWQQi8X2iQdJ9NZrLIzWyGazWFxcxNbWFiYmJtDd3U2qWjVEqsgok98jkQju3r0LnufR2tqK7e1tbG5uwm6359y0USN5tRocFHC1t88XqH/AFRG55UHSlSujFje5jUYjWJbFRz/6UYyOjgJ4Kwvm1q1buHXrFnw+nyxyl5eXMTQ0JP/98PAwXnzxRdW2h6IoPPXUU/jQhz4Em82GcDiMb33rWw29Jq0nROQSyqZSu7IU2rK1tYXR0VGcPn267gsS6T014glF2p/b29vo7OwERVENK3CB2s7Krbe4BSDbYFtaWnDx4sWqBaxJGI1GdHV15YiHbDYr20VXVlbAMAxEUZRFryQgGvH7USqiKGJ1dRVLS0sYGBjA3NwcWbDWGY7jsLi4iFAotO+Gg5S8GovFcuZQ7012zjeOSwsc1OdbKOBKGWpV7YArLe4zrUN6citjb/BUtYjFYnJb3Pz8PNxud97H3bx5s+rbwnEcHn/8cXzrW9/Cfffdh5deegkPPfQQbt++rZkRj40EEblHGDUqueXYlSUr5traGoaGhjSV8HvY6B0twnEclpaWsLq6KofgbG1tIRQK1XvTKqIWlVwtiFvJBisIAk6ePJkT0FNrDAYDOjo6cnp/OY6ThW8wGMTCwgJ4ns+p9lZ7Hmqt2dnZgcvlgt1ur8kNB8LBiKKI9fV1eL1e9PX15b3hcNAcaoZhEI1GEQgE5HFcymRnLaeSK4OqJJo14KrZICK3MmohckVRBMMw8nnjhRdeOPDxg4OD8Pv9mJ+fBwAsLS1hcHBQte25desW1tbWZDvzpUuXcOzYMdy8eRPvete7VHudowI9eHR9AAAgAElEQVQRuUccKfiiHEpNI+Z5HoFAAH6/H/39/bh69armegAbaYyQIAhYWVmBz+dDX19fTmJyoRFCjUQ1K7l7++DqIW6lynskEsH4+LhmbbB6vR7t7e05cwR5npf7JDc3N+HxeMBxnDyyQar6mkwmTb6nQiSTSbhcLqTTaUxPT5PQOw3Asizu3r0LvV6PCxculBScl28OtTRyRDp+pVRyo9GYU/HVcjhbswZcNRtE5FZGrSq5pdjKH374YXz961/Hww8/jGg0iqeeegrPPPOMatty/PhxBINB3LlzB9PT0/B4PPB6vThx4oRqr3GU0JbCIDQkhyUvSn2Gi4uL6O7uxtzcnGarPo0gckVRxObmJtxuN9ra2vLODm4GkVutSm69q7c8z2N5eRkrKysNO36Gpul981AluyjDMDl2UaXwdTgcsFgsmhO+PM/D5/NhfX0dY2Nj6O3t1dw2HjWkXujt7W3ZmqwGypEjvb29AHbPCVLAlRTOxrJsjkjWeo96tQKuyr0JTiAit1Jqsf+y2WxJQvrRRx/FSy+9hImJCVAUhc9//vM4ffo0AOD69eu4fv06nnjiCQDApz71KXznO9/B+vo6HnzwQTgcDng8ngN/53Q68Sd/8id45JFH5ELSV7/6VVWrxUcJSiRnsCNNJpOp6CL2T//0T5ifn897klCKsZaWFoyPj5cVB19L7ty5g7a2NnmshdYIh8NYWFiAwWDA5ORkwcRkhmGwsLCAixcv1ngL1eP1119Hd3d3TtJqJdRb3EqWy8XFRXR1dWF0dFSzC2a1kOyiUrIzwzBIpVKw2Ww54qFefZJKG2xvby+Gh4c15y45akihL4uLixgYGMDQUP1GAmUyGbniKx2/Uo+68vjV6k3bfOQLuJL+5av4iqKIGzduyPZMQvHcuHEDs7OzRyLDoBo8//zzuHr1alVfIxQK4QMf+ABu375d1dch1AdyNT/iVGJXBt4aI7R3Ybi9vQ2XywWTydRQ42u0WsmV+jbT6TROnDiR0zOZj2ap5KphV663uAV202Cl78O5c+c0f7NHLZSVsIGBAQC7i+tEIiEL35WVFblPUtnja7VaqypuotEoFhYWYDKZSrbBEqoDwzC4e/cujEajJj4To9GIzs7OfbM2pYArpVVfGXDV0tKi+WTng/p8lQKYZVlQFIVsNluTgKtmgqRSl0+t6m/RaDTHkURoLojIJVTE3jFC0WgUbrcbPM9jamoqp4+vEdBa8FQqlYLH40E4HMbExAScTmdRC6dmELmVvoe9Nr16iFtpPFYymcTk5GTDfR+qgU6ng91uz5kzK/VJStWytbU1JBIJmM3mHOGgRkBQOp2WR5YVc8OIUH2y2Sy8Xi92dnZw4sQJTafC6/X6fVZ9QRBk4buzswO/349UKgWr1ZpjdbbZbJoUvsB+uzPP8/B6vXKS9d6bjvUea9QIELty+dQyWbmeYY+E6kJE7hGn0guuVMmNx+Nwu92Ix+OYnJxEV1eXZi/mB6HX65FOp+u9GTkJ1MPDw5iZmSlpASHN+21kyu3JzRcqVevFVzabhc/nw+bmJunxLAJln6TUKiCKIpLJpGwVlQKCTCZTjnCw2+1FLSQFQYDf78fKygqGh4cxPT1NFuV1RhRFrK2twefz4dixY5ibm2vIz0Sn08lhaxKiKMrJzgzDYHV1Vb5xo7Q62+12zb3nUCgEl8sFp9O5L8n6oD5fEnC1H3LeLw+O42pygyASiZCAwSaGiFxCReh0OiwuLiKZTGJsbAx9fX0NfVKvtzgUBAGBQABLS0sVJVDXcsZstSjnPdTbmiwIAlZXV+UE8fn5eXInv0woioLVaoXVaoXT6QSw+/mmUilZ+IZCIbAsC4PBkCN8lcm4oigiFArB4/Ggs7MTc3NzTd8L3QhIdnGLxdKUY5ooipIdC8obN6lUSnYsSMevXq/fl+xcj97wZDKJhYUFcByH2dlZ2Gy2fY8pJeAKIBVfQnnwPF+T7wCxKzc3ROQSykJKvtzc3ERPTw/Onz/fFBeuevXkiqKIjY0NuN1udHR05E1MLoVKe621gE6nK/qzqLe4FUURW1tbcuL1pUuXGiqMplGgKAoWiwUWiyUnkCydTss9vktLS2AYBjRNw2KxIJFIQK/X4+TJk+SOvQbIZDLweDyIRqNHzi6uPH6lGzcAcpKdl5eXwTAMKIral+xcrQAjQRDkxPdynCeFhK/0v3tF8FGo+AqC0NA3/OtNrezKkUiEiNwmhojcI06pJ2Ge5+H3+xEIBHDs2DEMDw/DYDA0zQWqHiJ3Z2dHDsA5d+5cTq/iUYamaWQymQMfU29xC+yG5bhcLgDA6dOnGyZkrZkwmUzo7u6Wx8xks1m4XC5sb2+jo6MDPM/j9u3boCgqp8dXyyNhmg1RFLGysgK/34/jx4835OisamEymWAymdDV1SX/LJvNylbnYDCIhYUF8DyfN9m5knNeJBKRpwpcvnxZte9DKQFXwK6okcQvTdMNH3BF+nEro1Yil1RymxsicglFIQgCVlZW4PP54HQ6MT8/D6PRiOXlZWSz2XpvnmrUMnhKEkfZbLYqIV1SUEijLhIO6snVQqiUMsBofHy8YfvQmwnJLr60tITjx4/v67uVhIOU6qwcCSP1VFazYnZUiUQiuHv3Lux2O3E5FInBYEBHR0dOpVuaRR2LxbC1tYXFxUVkMpmcZGeHw1HUSK5MJgO32w2GYTAzM1Mzl0MxdmdJ+JYyz1drNPK1VwvUUuROTk5W/XUI9YGI3CPOYRdCaY6kx+NBe3v7PhutwWBAIpGo9mbWjFpUcqXE5EgkgomJCfT09FRFHEnpxI16oc3Xk6uFUCnJzbC2toahoSESYKQRpLFlLS0tuOeee/IKqXzCgeM4WfjurZgpq75EmJWOUkhNTU2RikmF0DSN1tbWHEEqzaJmGAaRSASBQEAeybU32Vmn0+WEfQ0ODmri/FVKn2+j2J1JJbcyarX/YrEYOS81MUTkEvKi7DG0WCwFbbRanStbLtUMnpISd4PBIEZGRkpOTC4VSeQ2qh1z78iKeluTRVFEMBjE4uIinE6nqtY+QvkkEgm43W6k0+myKlJ6vR7t7e05Tgqe52WrqHIWqt1uz6n6VmoVbVYk54/f75fT4cl+qg7KWdT9/f0A3hrJpbQ7x+NxeRqCyWTC5OQkOjs7NScOJQ7q8+V5XvMBV0TkVkYtRwgRkdu8EJF7xMm38IhEInC5XKAo6tCwFumi2SxUw64shXr4/X4MDAyUnZhcKvVOiq4USaTXW9wCQDgchsvlgsViwYULF2CxWGr6+oT9SGO2NjY2VB/TRNP0vlmoklWUYRhsbW3B5/MhnU7nCF+HwwGLxXKkBV04HMbCwgIcDgcuX75MrN91QDmSq7e3V555u7m5iWPHjgEA1tbWsLCwAJqm9yU7a/XmXb4+370BV9J/F7I67/37akFEbmVwHAer1Vr11yE9uc0NEbkEGZZl4Xa7kUqlMDExkROCUQiDwdDQQmov5c5mzYdk9Xa73ejq6sLc3FxNLY+SSGxUKIpCJpNBOp2Wg0hqLR6UVcITJ06Qi6EGUFbU+/r6ajam6SCraCwWw87ODvx+P1KpFGw2W47wLaZHstFJp9NwuVxIJBKYnp4mSdYaYXNzE263W87S2PtdyWQyB/apS8JXq3b9UgOu9orfQn9fKUTkVgYJniKoARG5BCSTyZweUafTWfSCrNkquWotRLe3t+UZkBcuXMg7b7DaNKrIlRYmZrMZFEXhhRdegNFozLGJ2u32qi4gpBFZW1tbGPv/2Tvz4EjO+vw/o9ExM5pD9y2tjjm1u97Tu2vDLxgqoVJJqKIKKhxJKIokpOy1Y7ApY8AB29wEjLHxEdsLOKRCuQjYhMTkqtjBBNvrXa+v1ZwajaTVLY0003P2+ftj87a7NdKujpnpntH7qVJBrXdWLc073e/zfr/f5xkZ2dZnglI6SJeJyWTSRUVd2Sra29sL4PLmOpPJIJlMIpFIqGYklTO+jY2NVbGmSLb39PQ0BgcHceDAgar4uSodknkrCMKmmbcAUF9fj9bWVrS2tsp/RubUGYaRo+2U7fpkDZN7tB7Z6pwv6RZSvq4Y7c5U5O4OnufL8vtLJBJFN/2k6Acqcvc4oijiwoUL6O/vx/79+7d9U6+2Si5wWeju1BmRYRh5YzE6OqrpCWGlidz15iJ1dXU4cuQIgMtmXaTaEI1GkUqlUFdXV3Thq5wl7Ovrw6lTp+hGRQcQs7ZUKgWPx6PrTUlNTQ2sVqvKw4DMSCaTSTAMg9nZWWQyGZhMpgLhq9cZyY0g8WdNTU04ceIEbU3WAbvNvAU2n1PfqGvBYrGoKr56PrzZrsEV8PZ4zHaFbyWbPuoBQRBKXsmVJAnJZJJ2nVQxVOTucYxGI66//vodv76Y7b16gZhpbWfDls1mEQ6HkUwm4Xa70d7ervmDvpJE7tXmbk0mE0wmk5yDChRX+EqShKWlJZWLON2wa48gCJiamsLMzAwGBwexf/9+zT9XO0E5I9nd3Q3g8prLZrPyGl5YWEAqlUJDQ4OqVbTUXQs7IZfLIRQKIZfLYf/+/bDb7VpfEgWX56EDgUDRM28ByLO7yveadC2QNTwzMyMf3igrvlarVbeCr1QGV6Io6u5zW0mUq125ks05KVeHilyKbMe/09cCkG39q4HtmE+Rttb5+XmMjIzgwIEDunmYV4LI3Y2pVLGEbzKZRCgUQk1NDa655poNXcQp5UWSJNnVuK2trSqdrA0GAywWCywWCzo7OwFc/rmVa3hpaalgDRPxoMUGWhRFTE5OYmZmBkNDQ+jp6ama+34lo2XmLela2OjwhriTE2dnZdeC1Woti4jZCVsxuFpf8QUgC16DwVC2dttqpRwil7aUVz/6vMNQyspuRC7wdp5ptdwsthKLRCpMU1NT6Ovrwzvf+U7d/fylcIouFqVyTN6O8LVYLMhms+A4Dm63Gx0dHbv+/pTdQ1r+jUbjFWcJqxGDwQCz2Qyz2axaj/l8HslkEslkErFYDAzDqCprRPiWclNIfAZaWlqq8tChEpEkCTMzM4jFYhgYGNBFVNNGhzfA22uYYRhMTk6CYRgYDIaCwxu9dtBsxeBK+VxbW1tDc3MzWJYtqcFVtVIOkZtMJmG32zX/zFBKBxW5lF1TV1cHjuN0J/J2ypWid4izayQSQXt7O6677jrdPpT1WMldP/tUDsfk9cKX53mMj49jfn4edrsddXV1CAaDiEajZTW3oqhhWRbj4+NYXV2Fy+VSHVTsdRoaGtDe3q76nbAsK4uGqakpWTQoq2XFiIPJZrMIhUJgWRYHDx6EzWbb7Y9DKQIMw8Dv98NkMuH48eMwmUxaX9IV2WgNcxwnV3xnZ2fBMAxEUSyI5dJzHvX6dud4PI5AIIDW1lZ0d3ejpqampAZX1YokSSX/vaytrdF53CqHilzKrtlK5bOS2OznWV5eRigUgsViwfHjx8uS4bYbjEYjcrmc1pcBoNBUSosHuyRJmJ2dxcTEBLq6ugryijeq+JIWOyp8S4fS7GtgYAAej4du+rZAfX092traVFFvRDRsFgdDRMNWDuYEQcDk5CRmZ2eLnkNM2Tk8z8vO7x6PR+WKXGnU1dWhpaUFLS0t8p8JgiAL36WlJYyPj4NlWZWzsx5juTiOQygUAsMwOHDgQMGc+tUMrgAqfAm76SzcDolEgorcKoeKXMquHxTVFiO0vs03mUwiGAxCkiTs37+/Ym6Keqnklqo1eTvE43GEQiE0NjZuGj2z1VZnKnyLx8rKCkKhEBwOBzX7KgIbiQYSB5NMJjE3N4dgMChXy5RVX2UO6tLSEkKhkJzvrdfZyb0EMccLhULo7u7GyZMnq/K+YzQa0dTUpEomUOZRr62tbRjLRZydtTg8XVhYQCQSQX9/P3w+34bXcCWDq/VzvsDWDa6qkZ2mW2wXmpFb/dAnF2XXVFuMEKnkZjIZhMNhpFIpuN1utLW16erk+GpoLXL1IG7T6TTC4TA4joPP59v2AQUVvqUhnU4jFAqB53nqzltiNouDURoDRSIR8DwPs9mMXC6HmpoaeL1etLS0VNQ9r1rJZrMIBAIQRRFHjhzZU3PqgDqPmkBiucg6npubQzqdlt3JlQZXpboXk/dFkqQd5XZfac53M4Mr8nkk4nej11c65XJWpiK3+qEil0IrueswGAyYmZlBNBrF8PAwrrnmmorc6GklcvUgblmWRTQaxcrKCpxOJzo6Oop2DVT47hzSarm0tFT094WyddZXywRBkOfUW1tbYTAYEIlEkM/nVfORdrsdJpOJvmdlQulm7XQ60dnZSX/3/4cylqurqwuA2p2cYRjVvVjZ6rzbWXVJkjA9PY2pqamStPIrjaoIGxlckWvZ6HWVLHzL5UydSCToAWuVQ0UuZddUSyWXzKBNTk7CbrfjHe94R0WLknKLXC1MpdYjiiKmpqYwPT2N/v5+XHfddWV52FPhe2WU89A9PT04derUnvi59Q5pgQ2Hw+jo6MD111+vqqAo20Tj8TgmJyeRy+XQ2NioMgbS23xkNRCPxxEMBuXcbupmfXU2cydnWfaKs+pE+Cpb9jeDYRiMjY3BarXixIkTZRux2Kzdef1zlxhckdSMSmx3FgSBVnIpRYGKXMqer+SSGIZoNIqOjg64XC5ks9mK34SXK0JIL6ZSpO2ytbVVF/OdVPheZm1tDcFgUDZs07sL7F4hnU4jGAwCwKZRTco20d7eXgCXN9aZTAbJZBKJRGLD+Ui73Y7GxkYqfHcAy7IIhUJIp9NlzbytZurr69Ha2qoy6SKz6gzDYH5+HuFwGDzPFzg7k84FQRDkLhS9GH5tVfhWmsFVudqVk8kk9u3bV/LvQ9EOKnIpu6aurk43Lr7bQZIk2THZZrPJjsmLi4tgGEbry9s15ajk6qE1OZFIIBQKoba2Vve5qntJ+OZyOYTDYWQyGXg8HnpirhPIZn1xcVGOatrOZ7ampgZWqxVWq1X+MzIfSSKNZmdnkclkYDKZCoSvHjfVekCZebtv3z7s37+fHhKUkM1m1VOpFBiGwcrKCmKxGHK5HOrr65HL5eBwOHDgwAFdx2htx+BKrxXfconctbU1HD58uOTfh6IdVORSdk0lVnITiQSCwSAMBgMOHjyomsuolkikUopcPYjbbDaLSCSCdDoNl8uli5P1nVBtwlcQBMRiMczNzWFoaAgHDhygm3UdoHSB7erqKmrLuHI+sru7W/5+2WxWXscLCwtIpVKyMZCyTVTrTbXWkMxbs9mMa6+9dktts5TiYzQa4XA45Oo5y7IIBoNgGAYDAwNyTND6AxybzQar1arbdXwlgyvls1wvBlflrOTSw9fqhopcyq43oJU0k5vJZOSHFHFMXo/RaKyYn+dKlELk6kHc8jyPWCyG+fn5qhVRlSh8lS3jHR0dNHpGR6RSKQSDQdTU1ODo0aNlyfg2GAywWCywWCzo7OwEoDYGSiaTWFpaQiqVQl1dXYHw1eMBTrHheR7j4+NYWVnRTQss5fI6nZ+fx/j4OAYGBgqeMcoDHIZhsLCwgHQ6La9j5VrW8zreSrszedYD5Ys1EgShbMZTVORWN3QHQtk1lVD5ZFkW4+Pjsqtrd3f3psKoEn6erVBMkasHUyllO193d/eeE1EbCd98Po9kMqm58CVZ0pXQMr6XULpZu91u1drRgs2MgZTrOBaLgWEYGI1GeQ0T4VAtn3dyIBQOh6s687YSyWaz8Pv9MBgMm8YCbXSAA7y9jhmGweTkJBiGUc21E/GrZxOx7c75lqLdmef5snhqUJFb/VTHE4OyK4pRydVruzJpnbx06RIGBga25JhcLsOmUkMePruBvF7p2KhFS9bKyopqdpqaF12moaEB7e3tmglflmURiUSQSCTgdrtpJUonKCtRleBmvdE6ZllWFgxTU1NgGAYGg0E147vbKBgtUGar7sXMW71CnPkvXbq047imjdYxx3Fy58Ls7CyCwSBEUSwwuGpoaNBtR9J2hC+w+4ovz/Nl6Tah7crVDxW5FAC7E0R6rHyKooiZmRlMTEygs7MT119//ZY3Q3r8ebRAD63JqVQKoVAIoihi//79NNNuC5RD+IqiKOdE7tu3D16vV7fzaHsNhmEQCARQX1+/aSWqEqivr0dbW5tqpEQpGDaKgiGCQWtn9Y2gmbf6JZlMwu/3w2azFT2uqa6uDi0tLWhpaZH/TBAEudV5cXER4+Pj4DiuIJrLbDbrdo2U0uCqHDO5kiTRSu4egIpcyq7R0wwryX0MhUJwOBy49tprt73Jq6mpqYpKLnBZmIqiuC0BogdxS9rLV1dX4XQ6t+0AS1FTTOFLHMlJfqceBcVehOM4jI+PIx6Pb+o3UOlsJBhIFEwymcTc3JyqUqas+mpp5kQzb/WJIAgYHx/H8vIyvF6val2VEqPRiKamJpXAUmZSr66uYmpqasNoLovFotsDxZ0aXEmSBKPRKD/jy2U8xXEcNXmrcqjIpewavYgPksdpNBpx6NChHdv86+XnKQak9XorD0U9iFtBEOSWsX379sHj8ej2gV7pbFf4NjQ0IB6Py47keo7R2EtIkoS5uTlEo1H09vbi1KlTe+ozs1kUDBG+xAyNZKCuF76lvMcpM29pJ4q+WFlZQSAQQGdnpy5mopWzu4T10Vxzc3NIp9MFDuV6ddonbMfgShAEZDIZiKIInudLZnAlimJV7fUoG0NFLgXA7uc3SfVTixttOp1GKBRCNpstmkPlTiqgeoSYT12pcqAXU6mFhQWMj4+jra0Np06dotUODdhI+KZSKUQiESwtLcFkMoHjOLz11lu6cXXeyySTSQQCAZhMJjqrrmCjSpkyA3V5eRkTExPI5/Oq2Ui73Q6TybTr+x/NvNUv5OAhk8ng0KFDqrxnvbFZNBdxKGcYRnYor62tLXB21rNR20bClxw8tLW1yWK/VAZXyWQSdrudfi6rHP1+AigVBYkRKudGN5/Py/ELTqcTXV1dRbthbacCqmeu5LC8kamUFgJ3bW0NoVAIDQ0N1JlXRyg36r29vTh48KD8+daLq/NeheM4RCIRrK2tUcOvLbI+AxVQt4jG43FMTk4il8sVzEZaLJYt3xdp5q0+UXY8VPLBw2YO5UqjtunpaXleXelObrfbdTlewvO8fD87ePCgquNBWeEtpsFVIpFQ3Qso1QkVuRQAu2/Rra2tLdt8A8lJnZmZKZnpDZkzrvRq4mYiVw+tydlsFuFwWM4sLtc8FOXqrK6uIhgMwmq1blgh1NrVea+iPHjo6+uj7fy7RNki2tvbC+Dyppq0iCYSCUxPT284G9nY2Ki6Z9LMW/2SyWTg9/thNBqrtuNhM6M20r0wPz+PcDgst+0rD3GK0b2wU0j1tru7GydOnCi4n20057ve4Ir8f2U3olL4rn898HYll1LdUJFLKQqkkltKRFHEpUuXMDExge7u7m05Jm+XanFYXi9y9SBuOY5DLBbDwsIChoeHr5hZTCkv5OAhm83C6/Vuy3mSCt/SkkgkEAgEYLFYqnajrgdqampgtVpVbazrZyNnZ2eRyWRgMpnktsqlpaU9OROtZ5SxQC6XCx0dHXvqWVNXV7fhvPpGbfuke0FpcFXK3xXHcQiHw2AYZttt49sxuAJQIH5ramqwtrZGnZX3AFTkUgAUp5JbKlEoSRIWFxcRDofR1NSEkydPlnyDV00il+d5XYhbEus0OTmJnp4eXHfddVTc6ASSJz03N1fUgwcqfHePMovY6/WqNqyU8rDZbCTpeOB5HmazGTMzM1heXlZVyWw2GxW9GpBIJOD3++FwOKijtYLN2vbJIU4ymcTMzIx8iLO+e6EYa3lpaQnBYBB9fX1F7cTbap4vz/P4xS9+gampqaJ8X4p+oSKXUhRIu3KxIZuIurq6XTkmbxcyk1vpEJG7fu62nEiShOXlZUQiEdjtdjqnpiMkScL8/DzGx8fR2dmJU6dOldyshArfrSFJEi5duoTJyUkMDAzQLGIdIYoiYrEYZmdnVRVCpSlQMpmUTYHq6uoKhO9eWsvlhLSNx+Nxeii0RTbrXshms/JaXlhYQDqd3tVaJqZf2WwWR44cKYv/xnrhOz09jZtvvhk1NTV48MEHS/79KdpikHZjqUupGgRB2FXlMhKJoKGhAf39/UW5nlQqhVAohHw+D4/HU/Z5Tb/fj+bmZnR1dZX1+xYL8rGORqOYmZlBc3Mz7HY7HA5H0U5jtwLDMAiFQgAAt9tNY2d0RDKZRDAYRH19PVwuFywWi9aXpEIpfJPJ5J4SvmtrawgEArDZbHA6nfRQSEfE43EEAgG0trZiZGRkS4dCyrVMXHGNRqO8jolY0LMbbiWwtLSEUCiErq4uDA0N0UOhIiNJEvL5vLyGyX1ZOdtO1vP6yvnCwgLC4TAGBgbQ39+vSSfZk08+iW9/+9u455578Kd/+qd0fewBqMilALh8A9hNJTYWi0EURQwPD+/qOnK5HCKRCFZXV+FyudDZ2anJDE0oFILFYkFfX1/Zv/duUbYmS5IElmXlBxJ5KJE2JPK13kRltxDn67W1NbhcLrS1te2pWSg9k8/nEYlEkEwmK86Zt9qFbz6fRzgcRiqV2vZMNKW05PN5uQrl9Xp3bVqjdMMl/2swGFTtoRuJBUoh+XwewWAQ+XwePp9P17FA1QjHcaoDHIZhIIoibDYbzGYz1tbWAAD79+/XJD1hamoKp0+fhtVqxSOPPIKenp6yXwNFG6jIpQDYvcidmZlBOp2G2+3e0et5nsfExARmZ2cxODiI/v5+TU/ZotEoampqMDg4qNk1bJetzt2SljqlWEin07J7KPnaifGEIAiYnJzEzMwMBgcH0dvbS09LdQIxYZmenq6q96YahC8x1ZucnMTg4CD6+vrooZBOULaN79u3r6TvDcdxqgPJ9TEw5H/1GAOjBZIkYXZ2FhMTE/I9jX5u9AHHcfLzxmKxyMJa2Y4AACAASURBVHvMxsZGVfeC2Wwu2XsmiiJ++MMf4rvf/S6+/OUv4yMf+UhVPPMoW4eKXAoAyBW/nbKwsICVlRWMjo5u63WiKGJ6ehqxWAw9PT0YGhrSRcvW1NQUOI7DyMiI1pdyVYphKqV0DyVf2WwWFotFJRY2eyApZzs7OjowNDREKxA6gcxEh8NhtLS0YGRkpOrfm0oSvvF4HMFgEA6HA06nkwoYHZFMJmVHa5fLpUnbOM/zqmpvMpmEKIqwWq0q8bvXWtrT6TT8fj/q6urg8Xio27iOyOVy8Pv9kCQJo6Oj8nsjiqLs7EzWci6Xg8ViKXB23q0YnZycxOnTp+FwOPDwww/LhnGUvQUVuRQAuxe58Xgc09PTOHTo0Ja/H5nRIBtvPT2kZmdnwTAMPB6P1peyKcpg9FKYSkmShHQ6rRILuVxOPoklXyR2xmw2w+l06m62cy9DZtslSYLH49nTbXx6E765XE7OifZ6vSq3U4q28DyPSCQimxfpLcNbEIQC4UvyT9cL32qrbIqiKHcLud1udHR0aH1JlP9DWVnfqkv/+nguhmGQTqfR0NCgqvhu9d4sCALOnDmDBx54AF/96lfx4Q9/uOo+A5StQ0UuBcDuRW4ymUQ4HMaxY8eu+ndJ5cJkMsHlculy4724uIilpSXs379f60spgHxklY7JwO5joLaCKIqy8I3H41heXoYgCLDb7WhtbZXFwl6rKugNjuMQjUaxsrICp9OJ9vZ2+qDfAC2ErzK7k7ZY6gty+BqJRNDT04PBwcGKaW9U5p8SwZDP52G1WmXRa7fbYTKZKna9ra2tyaaQTqdTF11flMtks1mMjY3BaDTC5/Ptag+w3qWcYRj53kzWsiRJsNlsqgOoaDSKm2++GW1tbXjooYfQ2dlZjB+NUsFQkUuRyefzO35tJpPBG2+8gVOnTm36d4jTLsdx8Hg8urb2X1lZwaVLl7ZcmS4Xesi75TgOExMTWFxcxMjICDo6OgoqvhzHqTZWdrudtmGWAWUWcV9fHwYGBipmk64XSil8V1ZWEAqF0NTUBKfTWfVt45VEJpNBIBAAAHi93qroSFEeShKxQLpxlDO+O/FfKCeksr66ugqfz0cN2XSEcmbd6XSW1CxU6ez8q1/9Cvfffz8AyEZwv/3tb3HPPffgk5/8pK7XM6V8UJFLkWFZFjtdDhzH4eWXX8Y73/nOgv9G2vISiYQqU1DPJBIJjI+P4+jRo1pfCgB9iFulOQ4RUJtt9ElVgWyuEomE7LaoFAt0k188SIeE3W6nsTNFZrfCN5fLIRQKIZfLFcWZl1I8RFHExMQE5ubmKub5tBtEUVS1hxL/BWI8SO7RxXbc3ymLi4sIhUIVV1nfC2QyGVy8eBEmkwkej0eTg+xXX30Vd999N/L5PHp6ejA2NgaGYXDNNdfgyJEjOHLkCI4ePapJbBFFe6jIpcjsRuRKkoT/+Z//wQ033CD/Gan4zc3NYWhoCH19fRXzgEqn07h48SJOnDih6XXoQdxKkoSlpSVEIhE0NTVhZGRkRwJKaaBCNliiKKqEgt1upy1o2ySbzaoypelsZ3nYivC1WCy4dOkSZmZmtjyjRikfKysrCAaD28q8rUbWz0Umk0lkMhk5ak4pfMv1DM/n8wgEAuA4Dj6fT5PoGcrGSJIkOydrNRctCAIeffRRPPLII/jmN7+JD37wg/K9NZvN4s0338SFCxdw4cIFWQj/wR/8Qdmvk6ItVORSZDiOk8XUTnjuuefw7ne/W545m5ycRG9vLwYHBytu85DL5fDqq6/i+uuv1+T7l9pUaqskk0mEQiHU1NTA7XYXfX56fWRGMplETU2NSijYbDZduODqDZ7nEYvFMD8/j5GREXR1dVEBpTFK4bu8vAyGYVBbW4vW1lY0NTXJJip0PWuLMvPW5/PBZrNpfUm6Q5IkZLPZgrnIhoYGVauzzWYrqvCVJAkzMzOIxWIYGhpCT08Pva/piFQqhbGxMTQ2NsLtdmvSjRUOh3H69Gn09/fjgQceQHt7e9mvgVIZUJFLkSmGyHW73RgfH0dbW9uOK356gOd5/Pa3v8Xv/M7vlPX7rjeVArSp3uZyOYyPjyOZTMLlcqGtra1s35sEyysrvkajUZfxL1qgjGvq6uqqyEOkaiabzSIYDILnebmF70oVXyp8y4dyfpCafm2fzQyB6urqCoTvTtZzOp3G2NgYGhoa4PF4Knb/UI0QV+vZ2Vl4PJ6y7gkIgiDg4YcfxmOPPYZvfvOb+MAHPkA/v5QrQkUuRWY3IndlZQXnz59Ha2srvF5vxbcWSZKE559/Hu9+97vL+j21bk0WBAGxWAxzc3MYHBxET0+PLlrMN2oNraurKxC+erjWUpJIJBAMBtHQ0AC32w2z2az1JVH+D+Vn52qVdeV6JkYqVPiWlmQyCb/fL1egqBFe8dhsPa8XvpsdxpG56Pn5ebjdblqZ0xkMw+DixYtwOBxwuVyaHKqGQiHcdNNNGBoawve+9z1NRDal8qAilyLD8zwEQdjWaxiGQTAYhCAI4Hkehw8frniBSyDt16VGD+JWkiTMzc0hGo2is7MTQ0NDuq8O5nK5AuFLsvXIVzlnyEpJPp9HOBxGKpWC2+3WXW7nXobMrIfDYbS3t2N4eHhHnx0qfEsDx3EYHx/H6uoqPB4P/eyUCZZlVTO+DMPAYDCoZnxtNhvS6TT8fj9aWlr29Fy0HhFFEdFoFAsLC/D5fJp8dniex0MPPYQnnngC3/72t/H+97+fVm8pW4aKXIrMdkRuNptFOBxGMpmUT14vXLiAkZGRqjG+ef755/Gud72rZDdUPYhb4LIrbygUQmNjI5xOZ8VWB0krnVL4ptNp2TzFbrfD4XDoPi5DiSAImJqawszMDG2v1CGZTAbBYBCiKMLj8RR9Zp0K352jzLzt7e3Fvn37quLAq5JRejAkEgnE43EIgoDm5ma0tLTIa5pW2bUnkUhgbGwMLS0tcDqdmtxjAoEAbrrpJrhcLtx///1obW0t+zVQKhsqcikypBp7JTiOk0/2hoeHVe2sb7zxBnp7e6vmRvTCCy/g1KlTRTdW0IupVDqdRjgcBsuycLvdVZk9SMxTlMI3k8nAYrGoKr5ms1lX4lFZHWxra8Pw8DCNW9IRgiDI7ZXljp2hwvfqpNNpBAIB1NTUwOv1VuzBXbVCYoF6e3vR29srZ/kSASyKIqxWq6rqS+dzy4MgCBgfH8fy8jJGR0c12RfwPI/vf//7+MEPfoD77rsP73vf+3T1fKZUDlTkUmSuJHJJRWlqagp9fX0YHBws2ET5/X40Nzejq6urHJdbcl588UUcPny4aBskvZhKsSyLaDSKlZUVjIyMlDS8XY8o4zLIVzabRWNjo0r4mkwmTX4vqVQKwWAQBoOhJI7WlJ0jSRIWFxcRDofR2dmJ4eFhXYhJKnwvo5yL3guZt5VGLpdDIBCAIAjw+XywWCwb/j1BEFRtzslkEjzPbyh86ftbPNbW1jA2NiaPXWhxv/D7/bjxxhvh8/nw3e9+l44XUHYFFbkUGVEUwXGc6s8kScLs7CzGx8fR3t6OkZGRTVuJwuEwzGYz+vr6ynG5JeeVV16Bz+crisjQQ2uyKIqYnp7G1NQU+vv70d/fX/Wb3q0iiqJcTSBf+Xxe3lQphW+pIIcP8XhcdrSmGzj9QKqDBoMBHo9H994De0340sxb/aJ0td5pXrQgCEilUqrIOZZlYbVaZdGr5eFkJSMIAsLhMFZXVzE6OqrJyBnHcXjggQfw5JNP4v7778cf/uEf0veRsmuoyKXIrBe5y8vLCIVCsFgscLvdm566EiYmJgAAQ0NDJb3OcnHhwgUMDQ3tql1HD+KWtL5GIhG0tLRgeHiYzjxtAVEUkUqlVMKX4ziV8HU4HLv+XYqiKG8A+/v7MTAwQGcHdQTP85iYmMDi4iJcLhfa29srdvNVjcI3n88jGAwil8vRzFsdQnJVzWazHKlVLNYfTjIMg1wuh8bGRpW5VSX5MJSbeDwOv9+Prq4uDA0NafLsGRsbw4033ogDBw7gvvvuQ3Nzc9mvgVKdUJFLkSEiN5lMIhgMQpIkeDyeLZ/qXbp0CdlsFi6Xq8RXWh7eeOMN9PT07MiqXg/iFrhsHhEKhVBbWwuXy0VbX3cJqSYohS/P86pqr91u3/L87MrKCkKhEBwOR0XnSlcjSuOi7u7uDUc0qoFKFb6SJMmdKdSUTX+QufWFhYWy5qqKoiiPo5CqbzabhdlsVrU6NzY27un1wnEcwuEwGIbB6OioJodDHMfh/vvvx49//GM8+OCD+P3f//09/Z5Qig8VuRSZfD6P119/XY4p2W675Pz8POLxOEZHR0t4leWDOAtuZ8ZYL6ZSuVwOkUgEqVQKLperaszA9Ihyfox8iaKoEr02m00lfDOZDEKhEDiOg8fjgd1u1/AnoKwnlUohEAjAaDTC4/FctYul2tC78E0kEggEAjTzVqesrq7C7/ejra0NIyMjmh+QKH0YyL06k8nIzvtK4bsXumiWl5cRCAQ0dR1/6623cOONN+Lw4cP4zne+o4nB1eDgIBoaGmTflc997nP40Ic+VPbroJQOKnIpMoIgYHp6Gl1dXTsSZisrK5iZmcE111xTgqsrP6RVeyszxnoxleJ5HrFYDPPz8xgaGkJPTw89GdUAnudVopdhGACAzWYDy7JIp9NwuVw7mk2jlA6e5zE+Po6VlRW5NZlyGT0IX2XmrdfrpW2NOoNUB5PJJEZHR3V9eEec95UGVyRrXTnja7Vaq0b4chyHYDCITCaD/fv3a+IrwLIs7rvvPvzkJz/B97//fbz3ve/V7Bk4ODiIZ555BocPH9bk+1NKD3VmoMgYjUZ0d3fv+PW1tbUFxlWVTG1t7ZZyg/XQmkwMwiYmJtDV1YVTp05R4xUNqa2tRUtLi+wMSYxXotEorFYrHA4HotEoYrFYQcVX66rHXkSSJMzNzSEajaKnpwcnT56k78M6Ghoa0N7erhL+SuEbi8VKJnwlScL8/DzGx8fR29uLkydPVo3wqAaUruN9fX3wer26f38MBgMsFgssFgs6OzsBvJ21ToTv0tISUqkU6urqVDO+lXifJrFNAwMD2L9/vybC8o033sBNN92E48eP49y5c5oYXFH2FrSSS1HBsix2uiQymQzefPNNnDx5sshXpQ1TU1PgOA4jIyMb/nc9iFvg7blOm80Gp9NZUgdgyvZZW1tDMBiE2WyGy+VSRVKxLFtQ8a2rq1MJ32qqJOgRhmEQCARQX18Pt9tNM1V3SbErvjTzVt/kcjn4/X5IkgSfz1eV78/6NZ1KpWA0GguErx4PllmWRSAQAMuyGB0d1WT0gmVZfPvb38ZTTz2Fhx9+GL/7u7+riw6mwcFB2O12SJKEEydO4Bvf+Abt3qkyqMilqNiNyGVZFmfPnsU73/nOIl+VNszMzCCVSsHj8aj+XC/iNpVKIRwOg+d5uN1ueiqqM5Rz0R6PZ8utlcpKAtlUNTQ0qITvXpkdKyWk9TUej8Pj8dC59RJCRIKyNZQIX6VQUApfZeat2+2uaFfrakRp/DUyMrLjMadKhRxQKte0wWAoWNNbNSEsNkrjPC2N2V5//XXcdNNNOHnyJL71rW/pqoV9amoKAwMD4DgOd911F9588008++yzWl8WpYhQkUtRsRuRK4oifv3rX+OGG24o7kVpxMLCAlZWVmQjLaWplCiKqKmp0eShwbKsvDl3Op3o6OjYU5sLvSMIAiYnJzE7O1uUzQVpoVNWfNPptGyaohS+dB1cHWVrf19fH41s0ogrCd+amhosLy+jvb0dTqdTlxWyvQzDMPD7/XK8IDX+ugzHcQUHlJIkFQjfUv++crkcAoEARFHUrLqez+fxt3/7t/inf/onPPLII3jPe96j6+cTOUwj/hmU6oA+OSgqDAbDjkVuTU3Njl+rR2pra8HzPIDLG2OlqZQWApcYg01PT2NgYAAej4duznUEmUuLRCJob2/HyZMni3KKbzAYYDabYTabVbNj2WxW3kzNzs4ik8nIMRnki+ZDqkkmkwgEAjCZTDh+/Dht7deQjWZ8SXxdLpeD2WzG0tISVldXr1jxpZQPQRAQjUaxtLREux82oK6uTuXFAFw2syPCd25uDsFgEKIoynnrZF0XIz5O6S0wPDysmbHhhQsXcPr0aVx//fU4f/68LrOr0+k0OI6TXZ1/8pOf4MiRIxpfFaXYUJFLKSpEJFfDxpqIXEEQNDeVWlhYwPj4ONra2nDy5El6cq4zGIZBMBiE0WjE4cOHS+5aqTRNIRFXypiMZDIp51Y3NjaqhK/JZKqKz+d2YFkWkUgEiUQCHo9HtQmlaI+y9XW9K7yy4rve3IoK3/IRj8cRCATkAzz6+94atbW1aG5uVo2rKGPnyMEoz/MbCt+t3quz2Sz8fj9qampw7bXXapK5ns/n8Y1vfAPPPPMMHn30Udxwww26fdYsLCzgAx/4gFy8GB4ext///d9rfVmUIkPblSkqiKjbKb/5zW+KVsHSEiIYXnrpJbS1tcFut8PhcMBms5W1erq2toZQKIT6+nq4XC5NLP8pm0Nax1dXV+VsaT0hSRLS6bSq1TmXy8mbKfK1nc1UJSFJEmZmZhCLxdDf34/+/n7a/aAzEokE/H4/bDYbXC7Xlg7wdjLjS9kZLMsiHA4jlUphdHRUl1W5akAQBKRSKVW7M8uysFqtqkij9YeUxLl/cnISTqcTnZ2dmtzLX331VZw+fRq/8zu/g2984xt0r0LRBVTkUlTsVuS+9NJLuOaaazRx8CsG602lOI4rcL8lJkAOh6Nks5DZbBaRSATpdBput5tWnnSGKIryxmJgYKCixJMoikin00gkEvK65jhuQ+FbyRBX68bGRrhcror/eaoNjuMQiUSwtrZWlMxbKnyLizK2qb+/HwMDA1V5EKZnyL1auf/I5XJobGyEzWZDQ0MD5ufnYTKZ4PP5NOnwyuVy+PrXv45f/vKXePTRR/Gud72LrhOKbqAil6JCEAR5DnUnnD9/Hi6XS1cOelthq6ZS602AEomEPAtJRK/dbofZbN7RjZ7neUxMTGBhYUHTmRrK5iwvLyMUCqGpqQlOp7MqWsdFUVRVEJLJJHieV1UQ7HZ7RfyspPLEMMy2XK0p5UEpnkpt/EWF784gra8Gg4HGNukMInxjsRiWlpZgMpnA87zKj8Fms5XFiPDcuXM4ffo03vOe9+BrX/sard5SdAcVuRQVuxW5r7/+Ovr6+irKkGK3kUCktVlZGVO2hBLxe6VKkiiKmJ2dRSwWQ3d3NwYHB+nGS2ek02mEQiEIggCPx1P1bXvKuTHyJYqiSvRqGZGxHlJdJ7EQfX19FVNd3yuQzFuj0QiPx6OZ6ysVvhsjiqJsbqhl6ytlc9LpNC5evAiLxQKPx4O6ujqVHwNZ15lMRnbgJ+u6WNFzuVwOX/va1/Dss8/i0Ucfxf/7f/+PrhOKLqEil6JityJ3bGwMra2tsgusnill3q0oikilUnK1l1TGlALBbrejrq4Oy8vLCIfDsNvtGBkZoY6vOoPjOExMTGBpaWnPRzYpnULJF4AC4VvuyJfV1VUEg8FtzXVSyocgCHKHisvlQkdHh9aXpIIK38vO1n6/H1arFW63WzeHV5TLiKKIyclJzMzMwOv1XtX/gTjwK9d0KpVCQ0ODqkPHarVuS/iePXsWN998M37v934PX/3qVyt2NI2yN6Ail6JCFEVwHLfj14dCIVgsFvT19RXxqopLKcXtlSCVMSJ619bWwLIsamtr0dXVhc7OzqrfSFUSyjzVnp4e7Nu3j743G0CyIcm6ZhgGNTU1BcK3FL+7fD6PcDiMdDoNj8cjx0FQ9MPy8jKCwSA6OjowPDxcMZ+hvSJ8BUHA+Pg4lpeX4fV6qf+DDmEYBmNjY7DZbHC73Ts+RCTjVuuFb11dnWpNb7Sus9ksvvKVr+Df//3f8dhjj+Ed73jHnj3spVQOVORSVOxW5E5MTMBgMGBwcLB4F1UktBK368nn8xgfH8fa2hoGBwdRX18viwSykVLO9273pJWye0hlkJgW0er69mBZtsCwjQgEpfDd6bpWtlUODg6it7eXbrh0Ri6XQygUQj6fh8/ng9Vq1fqSdk21Cd+VlRUEAgF0dnZiaGioYq57ryCKIiYmJjA/Pw+fz1eyAwiyrsma/slPfoJ/+Zd/wejoKA4dOoT29nb83d/9Hf7oj/4IX/7yl+mMNqVioCKXokKSJLAsu+PXT09PI5/Pw+l0FvGqdsdWTaVKjSAImJqawqVLl7Bv375NZwbz+bxqvjeVSsmzNWTG12Kx0E19CchmswiHw8hms7QyWGSUGymyruvq6lTreiszY/F4HMFgEA6Ho2qMv6oJ5Wz0+szbaqQShS/LsgiFQshkMvD5fFXvL1CJJBIJjI2NoaWlBU6ns+zrZ2ZmBi+88AJ+9rOf4a233oIgCLDZbDh69Kj8deTIEfqMpOgaKnIpKnYrcufn57G6ugqfz1fEq9o5eqjeKt1E29vbMTw8vK15JzJbo5zvzWazaGxsVFXG1ufnUbaOIAiIxWKYm5ujrtZlQpKkDYWv8kBHGdFFKoO5XA4ejwcOh0PrH4Gyjp1k3lYj+XxeNbuuF+ErSRLm5uYQjUbl6DN6n9MXgiAgGo1iaWkJo6OjmohISZLw4osv4pZbbsH73vc+3HPPPTCbzYjH47hw4QJeffVV+UsURTz00EN473vfW/brpFCuBhW5FBW7FbnLy8uYm5vDwYMHi3hV20cP4hZ4O6vTZDLB5XIVzaRBkqSCrFMSHK+sjO3VTeZWkSQJCwsLiEQicsteuU2TKG+zPqIrmUwinU7DYDCA4zh0dXVhYGCgLPEYlK2jzLz1+Xy0urMBV2rhL4fwzWQy8Pv9MBqN8Hq9dARDh6ytrWFsbEw+DNei+p9Op3Hvvffi+eefx2OPPYbrrrvuin8/mUzCYDDQbgCKLqEil1JAPp/f8WvX1tYQjUZx9OjRIl7R1tGLuM1kMgiHw8jlcnC73WXJ6lRmnRLxuz7yxW63UxH3fySTSQSDQdTV1cHtdlOXSB1CZgbtdjuam5uRTqflTgaLxaJa1zvNpqbsnHJm3lYjmwlfpfvtboWvKIrymAxxtqafE30hCAIikQji8ThGR0c16VKRJAn/+7//i7/+67/G+9//ftx99930IIRS8VCRSymAZVnsdFmQDLcTJ04U+aquDBG3ZP5WK3FL4mYWFxcxMjKCrq4uTTcUPM+rNlHJZFLlfOtwOGC1WnU1L1ZqWJZFJBJBIpGA2+2uqEznvUI2m0UoFALLsvB6vQVVAtLJoFzXuVxObuFXZlPTDX1pSKfT8Pv9qK2t1SzzthoppvAl7eN2ux0ul4vGAumQeDwOv9+Prq4uDA0NaXJIlEqlcPfdd+M3v/kNHn/8cZw8ebLs10ChlAIqcikF7Ebk5vN5nD9/Htdff32Rr2pjlKZSWopbYrYyOTmJ3t5eXcfNKDdRiURCNgBa7+hcbeKAVDSmp6evaPxF0Q5BEDA5OYnZ2dltz0aLolggfNe38BPhS9k5ysxbt9uN9vZ2rS+p6tmu8OV5HuPj41hZWYHP5ytLJxFle/A8j3A4jEQigf3792vS7itJEl544QXceuut+OAHP4gvfvGL9P5IqSqoyKUUwHGc3O67XURRxAsvvIB3vetdRb6qQvTQmixJEpaXlxEOh9HU1ISRkZGKe0gQAyDlfG86nYbZbFZVfCu5HXRpaQnhcBgtLS0YHh6ms8o6hLxHra2tGBkZKUpbvSiKSKVSqhZ+nudV4sBut9P1sEWWlpYQCoUqLvO2GtlM+JJIuvb2drjdblq91SEkO5rkr2tVvf3iF7+IF198EWfOnMHx48fLfg0USqmhIpdSwG5ELgA899xzePe7313EK1KjB3ELXA5oD4VCAAC3211VxguSJCGTyagqvqQdVFnx1fvMTjqdRjAYhCRJVfceVQuZTAbBYBCCIMDr9ZY8T1UQBJXzLZldXy98qTh4m1wuh2AwCJZlqybzttpgWRZjY2PIZDJoaWlBLpcryYwvZedwHIdQKIR0Oo3R0VFNPkeSJOHXv/41br31VnzoQx/CXXfdVXEH8xTKVqEil1IAz/MQBGHHr3/uuedwww03FF146kXc5vN5RCIRJJNJOJ1OtLW1VWyFczuQdlBlxZfjOHkDRcSvHsQBx3GIRqNYXl6Gy+VCe3v7nniPKgllbJPT6URnZ6dm7xHP8wXCF0CB8N1rpm2iKGJ6ehrT09M0WkunSJKE2dlZTExMyGMYyveoHOZWlKuzuLiIUCiE/v5+DAwMaHYwf9ddd+HcuXM4c+aMZgahFEq5oCKXUsBuRe4LL7yA6667rmgbQr2YSpF5wZmZGQwODqK3t3fPz3RuVBWTJAk2m01V8S3XBkqSJMzMzCAWi6G3txcDAwN086YzJEmSW5M7Ojp0G9vEcVzB2laatlW7OFhbW5OdrZ1OJ23p1iHE/Kuurg4ej2fLnTVU+JYPlmURCATAsixGR0c1cfGXJAnPP/88Pv3pT+OjH/0oPv/5z9PPM2VPQEUupYDditwXX3wRhw8f3rXbpl5MpSRJwtzcHKLRKDo7OzE4OKiLaqVe4TiuYANlNBoLHJ2LfUAQj8cRCoVgtVrhdDp130q9F1G2j3u9XjQ2Nmp9SduCZdkC4UuyTpWmbZUsDjiOkw1xaOatPhFFUT5wdbvd6Ojo2PW/SYVvcVFmsG9UYS8XyWQSd911Fy5cuIAzZ87g8OHDZb8GCkUrqMilFCAIAnie3/Hrz507B4/Hs6v5R720JhPhZLFY4HK5aEzGDsnn8wWOzg0NDapqb2Nj447e42w2K2cSezweTTIGKVdG6cjrdDqrKqtTubaTyaTsVr5e+Oq960N5mEczb/VLIpHA2NgYmpub4XQ6S9oFQYXvzsjn8/D7/RBFET6fT5N9gyRJ+O//OBKM2wAAIABJREFU/m/cdttt+LM/+zPceeedtHpL2XNQkUspYLci97XXXsPAwABaWlq2/Vq9iNt0Oo1wOAyWZeF2u2k1o8hIkoRcLqdyvc1kMrBYLKr5XpPJtOn7T4TT/Pw8nRfUKZIkYXFxEeFwWM6BrPYNMXErXy98GxoaVMK3sbFRNyIylUohEAhsu+2VUj54nkckEsHq6qqmFXYqfDdHeVA0NDSEnp4eTZ5JiUQCX/jCF/DGG2/gzJkzOHToUNmvgfDDH/4Qn/jEJ/D000/j/e9/v2bXQdmbUJFLKUAURXAct+PXX7x4Ee3t7dtqodKLuFUaFo2MjGhqhrPXkCRJlXOaSCSQz+dhtVpVFd/6+nrMz89jfHwcXV1dGBwc1OVM514nlUohGAyipqYGHo9Hk1k0vaA81Nkspstut8NisZT1fiMIAqLRKBYXF2nmrY4h0U3d3d0YHBzUzeEIYb3wTaVSMBqNe0r4ZrNZ+P1+GAwG+Hw+TQ6KJEnCf/3Xf+H222/Hxz/+cXz2s5/VdLQqFovhox/9KCRJwmc/+1kqcillh+4MKUWntrZ2yyJZL6ZSxEV0amoKfX19OHXqVFU/kPWIwWCA1WqF1WpFT08PgLdzThOJBBYXFxEMBpHL5VBfX4+uri60tLSAntPpC57nEY1GsbS0BLfbvWfcx6+EwWCA2WyG2WxGZ2cngMv3vmw2KwuDmZkZVTcD+SpVPrUy85be7/RJPp9HMBhEPp/H4cOHdTvDXl9fj7a2NrS1tcl/phS+sVisaoWv0uxwZGQEXV1dmtzv1tbW8PnPfx4XL17E008/jYMHD5b9GpSIooi/+Iu/wIMPPojbb79d02uh7F2oyKUUnbq6uqu2O29kKqXF6TRxeo1EImhubsbJkyfp3IqOIG62DQ0NSCaTMBqNOHToEGpra5FMJnHp0iUwDAODwbBnXG/1iiRJcoW9u7ubCqerYDAYYLFYYLFY0NXVBUDdzbC2toapqSk5n1q5vq/Uxn81SOYtx3E4dOgQzbzVIUrhRJz8K+2gaC8I30wmg7GxMdTX1+PEiROa7B0kScJ//Md/4DOf+Qz+/M//HI8//rgujDHvu+8+vOMd78CxY8e0vhTKHoaKXEoBu32YXq2Sq5fW5GQyiWAwCKPRiGuuuYZu9nSIKIqYmprC9PQ0BgcH4fP55MOQ5uZm+e8RR+dEIoFYLAaGYVTmPw6HQ1czkNUGmemsra3FsWPHqEHbDtmsm4EI33g8jlgsJrfxrxe+V4J8li5dukRn2HVMOp3G2NgYGhoacO2116KhoUHrSyoa1SJ8JUmSO79cLpfcnVFuVldXceeddyIUCuGf//mfsX//fk2uYz1vvfUWfvazn+HXv/611pdC2ePQmVxKAZIkgWXZHb9+bm4OiUQCXq+34N/Vg7jN5XKIRCJgGAYul0v1wKXoA2WFvaWlBSMjI9s+nVbOQCYSCaTTaZhMJtV8b7lnIKsNMsO+srIityZTSg9p41fOQXIcJwtfssZJZWltbQ1+vx8OhwMul0sXlR6KGlEUEYvFMDc3t+fnozea8dVLRnU6ncbFixdhsVjgdrs1q97+27/9G+644w588pOfxO23364rX4pHHnkE9957r3xAMz8/D7vdjnvuuQc33nijxldH2UtQkUvZkHw+v+PXLi0tYWFhAQcOHACgH3HL8zwmJycxNzeHwcFB9PT00MqeDiGGRQDg8XiKVmEnM5DEzTmZTCKbzcqtoEQYNDQ0UOF7FZQuor29vdi3bx/9LGmMIAgFwpeMjYiiKN/zqMDVH+QQohyxQJWK1sJXmU3s8Xg0O4SIx+P47Gc/i2g0ijNnzmB0dFST69gON9xwAz71qU9R4ylK2aF3UsqGGAyGHRv6kHZlvZhKSZKE2dlZTExMoKurC6dOnaKbCB3CcRzGx8cRj8flCnsx14tyBrK7uxuAuhV0eXkZ0WhUroitd3SmXIZhGAQCAdTX19PWZB1hNBrhcDjgcDjkQ4jx8XG0t7fDZDLJM+ySJKmEgd1up/dDjeA4DpFIBIlEAqOjozTj+wpstdW5FMKXYRiMjY3BZrPh5MmTmhwUSZKEf/3Xf8Wdd96JG2+8EU8++ST93FIoV4FWcikbwrLsjkUuwzDw+/04evSopuIWAFZWVhAOh9HY2Ain00k35DpEFEXZZKW/vx8DAwOaVgVJRUxZ8RVFcc8LA7IhX11dhcfjQWtrq9aXRNmAVCoFv9+P+vr6DTNveZ5XVcSSyWSBcZvdbtfVDGQ1sri4iFAoRDshikwxK76iKMpZ7F6vV7N73srKCu644w5MTU3hzJkzBaNgFAplY6jIpWzITkUumec9e/YsAMhtoA6HA1artWwP8nQ6jVAoBJ7n4Xa76Qm5TonH4wgGg7Db7XA6nbo1WdlIGNTU1KiqvTabrSo3qkqn176+Ps0PISgbs5vMW2LcRr4YhoHRaFQJA6vVSoVvESDu1jzPw+v16jYWqJrYifBNJpMYGxtDU1OTZi3kkiThl7/8JT73uc/hlltuwa233ko/gxTKNqAil7IhHMfJM7RbYaO5W47j5GpYIpFAKpVSGf84HI6iZ0CyLCsb4TidTnR0dND5Sh2SyWQQDoeRz+fh8Xgq8hCCZVlVtTeVSqG+vr7A0bmS118ikUAwGITZbIbL5bqqgy9FG0jmbWdnJ4aGhoqyEV4vDNY7lhPhSw88toYkSbh06RImJyepu7UOUK5vhmHAMAxqampgs9nAsiwymQx8Pp9mZnrLy8v4zGc+g7m5OTzxxBPweDyaXAeFUslQkUvZkK2K3O2YSq03/kkkEsjlcipHUIfDsaP5R2XUjB5aXikbw/M8JiYmsLCwgJGREXR1dVXNRk+SJJWjczKZRDqdhtlsVlV8i32wUwpYlpVnBT0eD1paWrS+JMoGZLNZuSro8/lKXhVcv75TqRQaGhpUwpdGdRVCWshNJhM8Hg+d8dcpS0tL8Pv9MJvNqKur08TVWZIk/OIXv8AXvvAF3Hrrrbjlllto9ZZC2SFU5FI2hOd5CIKw6X8vlqmUMgqDiF9BEFTVsCvNh0mShMXFRUQiEbS2tmJ4eJhuIHSI0o23u7sbg4ODe+LBLUkSMpmMquKrPNgha1wvbdrKatPAwAD6+vqoYNEhysxbLQ+LNjvYMZlMBcJX7wc7pUA50+nxeGjElk4RBAGRSATxeLzAAGyzim8phO/S0hJuv/12LC0t4YknnoDL5dr1v0mh7GWoyKVsyGYil4haInBLYSqlnH8k4qC2tlbV5tzY2AiGYRAKhVBbWwu3201nm3QKaXk1mUxwuVx73vxrfcZpIpEAz/MFxj/ldvBcW1tDIBCA1WqFy+XSjfCmqCFxM2RWUG+RQKRjRyl8M5kMzGazan1Xe0b16uoq/H4/Wltb4XQ698ShXiUSj8cRCATQ0dGB4eHhLR3qFVv4SpKEn//85/jiF7+IT3/60zh9+jRdLxRKEaAil7IhgiDIGYsELfNu8/m8LHhXV1dlR9C2tjZ0dHTA4XDAZDJV9aap0sjlcohEIkilUvB4PGhubtb6knSLIAhgGEZV8QWgqvaWqk2OZVmEw2EwDAOv14umpqaifw/K7lG+Tz6fr6Lm2ElHg1L4KjOqyVc13MM5jkM4HEYymcTo6CjsdrvWl0TZAJ7nEQ6HkUgksH//fthstl39e1sRvlartcDAanFxEbfddhvi8TieeOIJOJ3OXV0HhUJ5GypyKRuiFLlailslynnOwcFBNDU1qaph+XweNptN1eZMW5fLjyAImJqawszMDAYHB9Hb21vxG1ctWO94SzoalOt7N8Y/oiji0qVLmJqawr59+9DX10ffJx2izPmuphZyURQLhO/6Vn673Y6GhoaKWJdkdCYcDlMXcp2zvLyMYDCInp6eksY3rRe+X//61/Hmm29i//79OHToEIxGI5588knccccduPHGG+l6oVCKDBW5lA0RBEE2n9Ja3IqiiNnZWcRiMXR3d2Pfvn0b2vmLogiGYVRtzpIkqURBqU0j9jKSJGFpaQnhcBhtbW0YHh7WXStlpZPP51XrmziWKyu+W2kDXV1dRSAQgMPhgNPppIdBOoUYFjU0NMDtdle9u/X6Vv5kMgmO4zYUvnoil8vB7/dDFEX4fD5YLBatL4myARzHIRQKIZ1OY3R0FFartezXMDMzg//8z//ET3/6U0SjUXmPcvz4cRw7dgzHjh3D4cOH6RqiUIoAFbmUDfnVr34FjuNw5MgRNDc3a3bCuLKyglAoBJvNBqfTue1NnrIalkgk5BiM9fO9lVAp0DNkPtpgMMDj8dD56DKxfv4xkUggm83CYrGoHJ1JG2gul0M4HEYmk4HX662olte9hDLzdq8bFgmCUCB818+w22w2TQ5qJEnC9PQ0pqamqs4tvtpYXFxEKBSS0xe0OrD/6U9/invvvRd33HEH/uqv/go1NTVYXFzEq6++inPnzuH8+fN4/fXXYbFY8KMf/QjHjx8v+3VSKNUCFbmUDXnqqafw9NNP4/z586ipqZFPGK+99locPHiw5CfpqVQKoVAIoijC7XYXba5JkiTVfG8ikUAmk1GJAuJ2SzcrV4dlWYyPj2N1dRUulwvt7e1aX9KeR5IkpNNpVcU3n8/DaDSCZVl0d3djaGhId9UwymVIy2sxM2+rDTLDrhS+oigWCN9SdpIwDAO/3w+LxQK32027IXQKy7IIBoPI5XIYHR3V7AB2fn4en/rUp5DJZPD4449jaGjoin9/cXERjY2N9MCYQtkFVORSrogkSVheXsbZs2fx8ssv45VXXsGbb76Jnp4elfAdGRkpSrVXKZqcTifa29tLLjbXi4JEIgGO42Cz2VTVMNp6+zZknpNEzfT399N5Ip1C3EMbGxvhcDiQTqeRSCQgimLBGt9oDIBSHkjmrSAI8Hq9dHO7TXieV5m3MQwDAAXCd7drXBAE2RvC6/WitbW1GJdPKTKSJGFhYQGRSERTzwFRFPHUU0/hK1/5Cu6880785V/+JX1WUihlgopcyrYRRRHRaBQvvfQSzp49i1deeQVTU1MYHR2VRe+xY8e2JVCJWdGlS5fkB5KWDwJlpYBsmgwGQ8F87158WJEWcjrPqW9yuRxCoRByuRy8Xm9BN8R6UZBMJlVuoA6HA1arlVYSS4xeMm+rkfXmbbuNeiEHRu3t7RgeHqafDZ2Sz+cRCATA8zxGR0c1i62bm5vDrbfeCpZl8fjjj2Pfvn2aXAeFslehIpdSFFiWxRtvvCEL33PnziGXy+Ho0aOy8D18+DDMZrNqAyeKIs6cOYPe3l6MjIzo2qxI6ZRI5nsbGhpUbc7VnP2YyWQQCoXAcRw8Hg+NxtApoihicnISMzMzGB4eRnd395bX5Po1nkqlUFdXpzrcaWxs3JOHO6WAGIDpNfO2GlGucSJ8iWu5Uvgq1zgxLEqlUvD5fPTep1MkScLc3Byi0SiGhobQ09OjWfX2H//xH/H1r38dX/jCF/CJT3yC3jMpFA2gIpdSEiRJQiKRwLlz5/DSSy/hlVdewWuvvYaWlha5zdloNOJ73/se2tvb8cADD1RcPpwkScjlcqr5XpL9uH6+t5JRRjc5nU50dnZWrZCvdJaXlxEKhdDS0oKRkZFdiyYyw67saEin0zCbzaqK7/rDK8qVqeTM22qErHGl8K2vr5fF7PLyMgYGBmgskI7J5XIYGxuDwWCAz+fTzIl8dnYWt9xyCwDgscceQ39/vybXQaFQqMillBHiRPnLX/4SDz74IJaXl9HX1weHwyHb5584cWJblSe9IYqiPPNIhAFxAq202UdlPmd3dzcGBwdpe55OIfOcHMfB6/XCZrOV7HtJkqTKN00kEsjlcqrDHeLoTFGzPvO2v7+/Yu911Qw5pPX7/RAEAQ0NDchms6q4LtLVQN8/bZEkCTMzM4jFYpq2+4uiiH/4h3/AN7/5TfzN3/wNPv7xj9MDEQpFY6jIpZSNRCKBr33ta/j5z3+OL33pS/joRz8KURQxNjaGl19+GS+//DLOnTuHtbU1HDp0CMeOHcPx48dx9OhR2Gy2it1MCIKgqoSR2Udltddqterqgbi2toZgMAiLxQKXy0UFi04RBAGTk5OYnZ3VfIOnPNwh+aY2m011wLOX23EZhkEgENgzmbeViiRJmJqawvT0tKpzZX1cVzKZRCaTUXU12O32qh5Z0RuZTAZ+vx+1tbXwer2adU3NzMzg5ptvhtFoxGOPPYa+vj5NroNCoaihIpdSFp555hncdttt+MQnPoHbbrtt06Bz4nR8/vx52c351VdfRUNDg1ztPX78OA4cOFDRG2aWZVXV3lQqBZPJpBK+WrSAkhzVdDoNj8eD5ubmsn5/ytZZWlpCKBSSTXD01h2wUcyLJEkFjs7V3h3A8zyi0SiWl5fh8XioG6+OYRgGY2NjsFqtcLvdV33GrO9qSCaTck618nCH5FRTioMyn9jlcqGzs1OT6xBFET/+8Y/xrW99C1/60pfwsY99TFeH1RTKXoeKXEpZ8Pv9aGpqQnd397ZfS6IAzp49K8/3jo2NYWBgQCV8BwcHK/YBQ6oESuGby+VgtVpVwrdUTsbKiqCWhh2Uq5PJZBAMBiGKIjweD6xWq9aXtGU4jiuIeTEajVc0/alUJEmSDyJou7++EQQB0WgUS0tL8Hq9aGlp2fG/pYykI1/kXq5c5zSLfWek02mMjY3BZDLB4/Fo5u4/PT2N06dPw2w249FHH0Vvb68m10GhUDaHilxKRSKKIkKhkKrNeXZ2FgcOHMDx48flr+bm5ordSIiiiFQqpRK+oigWzPfuZuMsSRIWFxcRiUR0WxGkXIbkc87Pz8PlcqGjo6Ni17aS9aY/qVQK9fX1qjVeabOP2WwWgUAAoijSzFuds7KygkAggM7OTgwNDZXkIIK08yvHVjiO21D4UjZGGbXl8XjQ3t6u2XX86Ec/wne+8x3ce++9+JM/+ZOqOJSjUKoRKnIpVQFxOn7ttddw9uxZOcZIFEUcPXpUFr2HDh2q6BN0nucL5ntra2sL5nu38vORGcHa2lq43W66EdcppCIYDofR0dGBoaGhqj6IIJ9l5TrPZDJyCyhZ53psAVXGN9HMW33DsixCoRAymQx8Pl9Jzdo2QhTFgnZ+nuflOXbyRXPIgVQqhYsXL265jbxUTE1N4fTp07BarXjkkUfQ09NT9mt473vfi/n5edTU1MBms+GBBx7AkSNHyn4dFEolQEUupWqRJAnxeByvvPIKXn75ZZw9exZvvPEGOjo65Bbn48ePw+VyVXQbIREERBSQiBeHw7HhTBjLsohEIkgkEnC5XGhra9P4J6BsRjqdRjAYBAB4PJ49exBxpRZQZcVXy0oYybxtbm4uSnwTpTRIkoT5+XmMj4/rzuF6ozl2URQLhO9eWVuiKCIWi2Fubg5er1ezeXZRFPGDH/wA3/3ud/GVr3wFH/nIRzSr3q6traGpqQkA8PTTT+Puu+/G66+/rsm1UCh6h4pcyp6CPDSJ6D179ixisRg8Hg+OHTuGa6+9FsePH6/oLFhihqJsc2ZZFlarFZIkIZlMYt++fdi3bx9ts9IpJJt4cXERLpcL7e3tFbseS8X6dv5kMglBEMouCEhFMJ1Ow+v10sxbHZPJZBAIBDTPUt0OPM8XCF8AKudym81Wdd0dyWQSY2NjaGpqgtPp1Ozni8ViuPnmm9HU1ISHH34YXV1dmlzHRvzoRz/C/fffj9dee03rS6FQdAkVuZQ9D8dxePPNN1Xzvel0GkeOHJErvkeOHKm4uUAli4uLCAaDMJlMaGhoQCqVgiRJqvlem81W0RXtaoCYrEUiEWpWtANIXNd6QaCs9hZrnSvzOfVWEaSoUc5zVsM8OzFwU67zmpqaAgO3Srx3iKKIaDSKxcVF+Hw+zRz+BUHAmTNn8MADD+CrX/0qPvzhD+tmzXzsYx/Dc889BwB49tlncfDgQY2viELRJ1TkUijrkCQJDMPg3LlzcsX3tddeg81mU7U5+3w+3Z+ep9NphEIhCIIAj8ejmjvjOE7V5swwDOrq6lRtzpUs7CuNVCqFYDCImpoaeDyeTWO2KNtjs3WunO9tbGzcVlcDwzDw+/2ywys1DNIvpCJot9vhcrmqttWXZdkC5/La2tqKci5PJBIYGxtDa2srRkZGNBPp0WgUN998M9ra2vDQQw9pFlF0NZ588kk89dRTePbZZ7W+FApFl1CRS6FsAVK1UbY5h0IhDA8Pq4RvX1+fLjYRHMfJ2ZxOp3NLlQtJkpDP51VtzsTwZ/18L6V48DyP8fFxLC8vw+12a+YaupdQzrETR2eTyaTqbLBYLAWfGfJerays0MxbnSMIAiKRCFZWVjStCGrJRs7lygMeu90Oq9Wq+TNLEAT5c+Xz+eSZUy2u47HHHsNDDz2Er3/96/jjP/5j3R/yms1mXLp0id6LKJQNoCKXQtkhgiDA7/fj5ZdfxiuvvIKzZ89ieXkZ11xzjTzfe/ToUTgcjrI9KJUtlL29vRgYGNh1xFA6nUYikVBFX9hsNlULaLVWR0qJ0gCnp6cH+/btq8j2wmqA5FQrHZ2z2SwaGxvlNc6yLGKxGHp6emgbuc5ZXl5GMBhEV1cXfa8UkIPMzQ54tIjsWl1dhd/vR0dHB4aHhzUT3JFIBKdPn0ZPTw8efPBBdHR0aHIdV2JtbQ2ZTEZ2dX7mmWdw8803Y3p6WvdinELRAipyKZQiQTbK58+fl6u958+fR21tLY4dOyYL3wMHDpSkvXF1dRXBYPD/t3fv0VHWd/7A34SQZHKZkAQIIQmEZJJMEi5hJkm71LUeu8eertujXXXrsceW03V1DQqsl4O3tWiroCJFVgURjtWj1u3qlq1r3d2DrrqeLZkMBAXmkkkCuUBCyGUmM5n7PN/fH/7m2XmM3EKSZ2byfp3DH70QvgMTmPfzuXyRnZ0NnU43bRXX6AbQ2IpvdB4sdr5X7epAPIte35SWloaqqipoNBq1j0RfE73bdGhoCH19fQiFQpg7d66izZlXvMSXYDAIu90Ov9+PmpoaZGdnq32kuBd7ZVf0R3RDf2zw/abOhisRDofR0dEBp9OJ2tpaaLXaKfvalyMSiWDPnj3YvXs3nnnmGdx8881xGxi7u7txyy23wOfzISUlBQsXLsT27dtRX1+v9tGI4hJDLtE0EkJgaGhIXmplMplw4sQJFBcXK4LvlTzB9vl8cDgc8Pl8qK6uVqXVKxgMKqpgbrf7kto/Z5tQKITOzk6MjIygqqqK1zfFsdg7b3U6HQoLC+WNzrHvdUmSFGFAq9XG/ax+shFCoL+/H11dXVi2bBlKSkpm/d81VyK6oT82+Pp8PsVd1VqtFhqNZlK/z8PDw7DZbPJyPbUeiDocDqxfvx6lpaXYtWsXR0WIkgxDLk05h8OBn/3sZxgaGkJubi5+85vfoK6uTu1jxQ1JktDZ2YlDhw7BZDKhtbUVfX19qK2tVcz3Lliw4IIfIEKhEHp6etDf34/y8nIUFRXFzQe7aHUgts052v4ZDb25ubmzZmFP7Ifw4uJiXt8U50ZGRmC32y/pzttwODxhozM7G2aO1+uF1WpFamoqqquruTNgmpzvrurYlv6v38n+daFQCO3t7fB4PKirq1Ot0h6JRPDyyy9j7969ePbZZ/HXf/3XcfNvJxFNHYZcmnLXXnstfvrTn2LdunV499138cwzz6C1tVXtY8W1YDCIL774Qg6+ZrMZwWAQBoNBrvauXr0aGo0GQgjs27cPL7zwAt566y2sWLEiISpH0fbP2Dbn6L2msfO9ifBaLsfY2BhsNhsyMjJQVVXFD+FxLPbO25qamkm3UH69s8Hj8SAtLW3CRmd+sJ682Ep7VVVVXM5QJrvo3+mxwTcQCCA7O1vxXk9PT8e5c+dgt9tRUlKCpUuXqvbQx263o7m5GRUVFdi5cye7aYiSGEMuTanBwUHodDqMjIwgNTUVQggUFRXh888/h06nU/t4CUMIAafTCbPZjEOHDqG1tRVHjx6FRqNBOBxGQUEBNm/ejOuuuy6hl6qEw2HFfO/Y2Jg89xgNvvGw/XMyQqGQPHNWXV2N/Px8tY9E5xG7sG062l2/vrn863OP0ff6ZNs/ZxuXywWr1Yrc3FzodDouvosjsS39sVv6U1JSUFRUhAULFqgyyx4Oh/HSSy9h3759eP7553HDDTfwe40oyTHk0pQ6fPgwbrvtNtjtdvm/a2pqwrZt23DttdeqeLLENjAwgEceeQR/+tOfcNNNN8Hv96O1tRUOhwNVVVVoaGiA0WhEU1MTFi9enND/eEe3f8ZWwRIpDMQGptLSUpSWliZkSJ8tonfeajQaVFVVzVgLfezcY/S97vf7v7EKRl+JLisaHR1V9aoZujRnz56Fw+FASUkJ5s+fD7fbLb/fJUlCTk6OotV5uh5W2Gw2NDc3o7KyEjt37uR1O0SzRHL1BRIlmWAwiF27duGll17Cgw8+iL179yraecPhME6cOIGWlhYcPHgQ27Ztg8vlwurVq+XZXoPBgOzs7LgNhV+Xnp6OhQsXyktAYsOA0+lET0+PHAZi53vjYcuty+WCzWZDVlYWGhsbGVDimNp33s6ZMwdZWVnIyspCUVERAGVL/9DQEDo7OxEOh3llFyC3uy5ZsgTf+ta3+OAojgUCAdhsNoTDYRiNRnl7fOxDiWgXz9jYGM6cOQObzQYhxJQucQuHw/inf/onvPbaa9ixYwd++MMfJsy/g0R05VjJpSnFduWp9eCDD8Lv9+OJJ564pHZXIQQ8Hg8OHz4s39975MgRaDQaxVKrurq6hP6gHG2Ji53vjW65zc3NRW5uLnJycmaslTsYDKKjowNjY2Oorq5GXl7ejPy6dPmEEBgcHITD4ZDvvI3nwBS9siu24gtAUe2dyff6TAsEArDb7QgEAqitrUVWVpbaR6LziL37u6ysDMXFxZcVKkOhkPxe//oSt+iPS32UijncAAAgAElEQVSvWywWNDc3o6amBr/+9a85LkI0CzHk0pS75pprsG7dOnnx1LZt22A2m9U+VkISQlzxk+foBw+TySTP91qtVixbtkxuc25oaEj4jb/RLbexc4/z5s2bMN871bOWfX196O7uxtKlS1FSUpLQv4fJzuv1wmazAQD0ej0yMzNVPtHkhEIhRRBwu91JM8seFdv2P5nARDPL7/fDarUCAGpqaqZswd6F3utarRYnT56E0WiUH36EQiHs2rULr7/+Onbu3Inrr7+e7xuiWYohl6ac3W7HunXrMDw8DK1Wi9deew0rV65U+1gUIxKJoL29Xb6/12w2Y2BgACtWrJCrvUajEXl5eQn9AcHv9yuCb3TZT7Tae7ErLy7E6XTCZrMhJycHOp2OrclxTJIknDp1CmfOnEFlZSUWLVqU0O/rb/JNs+zRu6qj4TdR7qoeHx+H1WpFWloaqqur+b0Vx2IfRszUVXbR9/q5c+fwD//wD2hvb4dWq0VlZSU6Ojqg1+vx6quvorCwcFrPQUTxjSGXiOR7bdva2mAymeRrjADAYDDIwXfVqlVIT09PiA/K3yQ63xt7f28wGJTne6PB90Kt3IFAAA6HAx6PB3q9nstv4tzIyAhsNhsKCgpQUVGRdFdUnU/sXdXRKpjX60VmZqZivneyD3mmQ+zDiOrqankun+KTz+eDxWJBamoq9Hq9ag8jQqEQnnrqKXz66acoLy+Hy+XCsWPHUFRUJP/b1djYiJqamlnz/U9EDLlEdB5CCAwPD6O1tVVucz527BgKCwsV872VlZUJ3RYZiUQmzPcCUMz3Rtuce3t70dvbOy3XzNDUij6MuNI7b5OJEEK+1/TrD3liK75qLHFzOp2wWq3Iy8uDTqdjGIljQgj09vaip6dH9c6I48eP4+6778aaNWuwfft2+aFj9Iytra0wm80wm81wOBxob2+PiyWFRDT9GHKJ6JJJkoSTJ0+ipaVFrvh2d3dDr9fDaDSisbERDQ0NCd8OGp0Di1Z8XS4XIpEINBoNSkpKkJ+fj6ysrIR+jckqOicdneXkw4gLkyRpwrKfSCQyYaPzdIXOcDgMh8MBp9OJ2tpa5ObmTsuvQ1NjfHwcFosFGRkZqK6uVi0wBoNB7NixA7/97W/x4osv4rrrrrvo9/lU7LggosTBkEtEVyQYDOLYsWOK+V6v1wuDwSBXfNesWZMw84Cx/H4/HA4HvF4vli9fDiGEXAHzer3IyspSLPuZqmUrNDljY2Ow2WzIzMxEZWUlZzknKfZ6l+j7fbJbbi9kcHAQ7e3tKC4uTvjFd8lOCIHu7m709fWhqqoKixYtUu0sX375JZqbm9HY2Ihnn32WD0aI6Bsx5BLRlBJCYGxsDGazWa74Hj16FLm5uTAajXLFV6/Xx21LoiRJ6OnpQV9fH5YvX44lS5ZMCOjR1s/Y+d5QKKRo+5zOChj9n9g7b/V6Pa8LmQbBYHDCltuvby/Pysq6pKDq9/tht9sRCoVQU1PDa4HinMfjgcViQVZWFqqqqlS7fi4YDGL79u343e9+h5dffhnf+973Eu7BKRHNHIZcIpp20RbS2Dbn9vZ26HQ6xXxvcXGx6tWc4eFh2O125Ofno6Ki4rI+0EXvNI0NvtEKWOx8r9qvMVkIIXD27Fl0dHQkxJ23ySa6vTxa8Y1uL4+t+MZ2cMReuXW+h0cUP6KLwPr7+6HX61FQUKDaWY4ePYr169fjW9/6Fp599lnO2BPRRTHkEpEqIpEILBaLHHpNJhNGRkawatUqudprMBig1Wpn5IOwz+dDe3s7AoEAampqkJOTMyVfN1oBi4Zet9stX+0SrYAlYiu32pLlzttkEt1eHlvx9fl8yMrKgkajwejoKLKyslBTU8NW8jjndrtx4sQJ5ObmorKyUrWOlEAggGeffRbvvfcedu/ejWuvvZZ/VxLRJWHIJaK4EP2AfPjwYTn0HjlyBPPmzVO0Oa9YsWJKl51IkoTu7m6cPn16Ru55FELA5/Mpgq/P55M33EaDL0PAN4suP+vv71d9sytdXDgcRnt7O86dO4ecnBwEg0GEQiHk5OQoWvvVaoElJUmS0NXVhcHBQdVb/9va2tDc3IyrrroK27Ztm7IHj0Q0OzDkElHcEkLg3Llz8lIrk8mEEydOoKSkBA0NDXLwXb58+aTaVIeGhtDe3o6CggKUl5er9kFbkqQJ872RSEQRAnJycmb9fG+0lXy23XmbqEZHR2G1Wif8eUXb+mMrvpIkTZhnv9LFVnR5XC4XLBYL8vPzodPpVPv9DwQC2LZtGw4cOIA9e/bgmmuu4YMsIrpsDLlEcWDDhg34wx/+gO7ubrS1taG+vl7tI8UtSZLQ0dGBQ4cOwWQyobW1FadPn0ZdXZ1ivregoOC8H4xOnToFp9OJcDiM6urquKwQhMNhxbyj2+3G3LlzFfO9l7roJ9EFAgG0t7fD5/NNaSs5TY9QKASHw4GxsTHU1NRc0vbbC73fYzc6z4b3+0yLRCLy4raamhr5rlk1HD58GOvXr8d3v/tdbNu2jUvJiGjSGHKJ4sBnn32G8vJyXHXVVThw4ABD7mXy+/04evSoHHpbW1sRDocV1xjV19cjHA5jy5Yt+Ld/+zccOHAAdXV1CVUhCAQCijZnj8cjL/qJBt+MjIyEek0XEnvn7fLly1FcXJw0ry0ZCSEwODgIh8OBkpISLF269IpCaTAYlN/r0fd7WlrahI3OfE9MXrTavmjRIixfvly16q3f78fWrVvx7//+79izZw+uvvpq/rkS0RVhyCWKI2VlZQy5U0AIAafTCZPJJLc5t7S0IBKJYPXq1bjxxhtx1VVXoaqqKqFbImMX/UTDgN/vl+cdo0FgKmeYZ8rY2BisVqt8bUkivobZxO/3w2azIRKJoKamZloWgQkhJmx09nq9yMzMVLQ6J9ODnukSDofR0dEBp9OJ2tpaVbcVm81mrF+/Ht/73vfw1FNPsXpLRFOCIZcojjDkTj2Hw4GNGzciGAzioYcewtDQEFpbW2EymdDZ2Ynq6mp5vrepqQmFhYUJ/QFZkiR53jEafCVJkgNvdL43XsN9KBRCZ2cnRkdHUV1dzTtv45wQAr29vejp6ZmRxW3f9Ot7vV5Fxdfv93OR2wUMDw/DZrNh8eLFk95nMBV8Ph+efvppfPjhh9izZw/+/M//fMb/7vX7/bj11lthsVig0WiwaNEi7N69GzqdbkbPQURTjyGXKI4w5E6d8fFxPP300/jd736HrVu34qabbprwASoUCuHEiROK+V632436+np5tnfNmjXIzs5O6OAbCoUU9/e63W7Mmzdvwnyvmq8x9s7b4uJiLFu2jPOXcc7tdsNqtSIzMzOuqu2SJMHj8Sge9EQiEcVGZ61WO+s2Okdnpd1uN2pra1WdbW9pacE999yD73//+/jVr36l2hVgfr8fH3/8MX7wgx9gzpw5ePHFF/Huu+/ik08+UeU8RDR1GHKJ4ghD7tR58803YbVa8cgjj1xy+5sQAh6PB4cPH8ahQ4fQ2tqKI0eOICsrS7HUqra2NuE/IEfbPqMhYHx8HJmZmYqKb3p6+owE3/HxcdhsNqSkpKC6upp33sa5SCSCkydP4uzZs9Dr9SgoKFD7SBcV3egcW/EFoKj2xnOHw5U6d+4c7Hb7lMxKXwmfz4df/epX+K//+i+88sor+M53vhNXDxDNZjNuvvlmnDp1Su2jENEVYsgliiMMufFHCIH+/n6YTCY5+NpsNpSVlSmCr5ofHKeCEALj4+Ny8HW5XIr7TKNBYCrDfSQSwalTp3jnbQIZGRmBzWbDggULUFFRkdChMBQKTdjonJqaqnjQk+gbzIPBoLyZvLa2VrV5VyGEXL29/vrr8eSTT0Kj0ahylgu5/fbbkZ+fjxdeeEHtoxDRFWLIJYoDd911Fz744AMMDAygoKAAOTk56OjoUPtYdB6RSAR2u12+v9dsNuPs2bNYuXKlHHqNRiPmz5+f0KEt9j7TaAUMwIT53smEAN55m1hCoRDa29vh8XhQU1Oj6qKi6RQIBCZsdM7IyFA86MnMzEyI7+uzZ8/C4XBg6dKlKC0tVe3MXq8Xv/zlL/HRRx9h7969WLt2rSrnuJinn34a77//Pj766CN2kxAlAYZcIqIrJISAz+dDW1sbWlpa0NraCrPZjDlz5iiqvatWrUJaWlpCfEA+n2j1K3a+Nz09XRF8LxQCAoEA7HY7/H4/77xNALGz0qWlpSgtLU3oyublin5vxz7o8fl8yMrKUmx0nqnW/ksRCARgs9kQCoVQW1urWmATQuBPf/oT7r33Xvzwhz/EE088EZfVWwDYvn073nnnHRw8eFDVe4KJaOow5BIRTQMhBIaHhxVtzseOHUNRUZEi+Op0uoQODbHXukSDb2wIiC62SktLk7fwlpWV8c7bBODz+WCz2SCEQE1NTdwGlJkWbe2PrfgGg8EJG51nehGXEAIDAwPo7OxU/XtsfHwcTzzxBD799FO8+uqr+Pa3v63KOS7Fjh078NZbb+HgwYPIy8tT+zhENEUYcomIZogkSejq6lK0OXd3d6OmpgZGoxGNjY1oaGjAwoULEzoASpKkmO8dHR2Fz+dDeno6ioqKkJ+fD61WyxblOBV7LVBFRQUWL16c0O/HmXC+q7titzlP53ve7/fDarWq/kBCCIHPP/8cGzduxI9+9CP84he/QEZGhipnuRR9fX0oLS1FeXm53FWSnp6OlpYWlU9GRFeKIZeISEXBYBBffvmlIvj6/X6sWbNGrvbW19cnzBxgrNg7bysrKzF37lxFCEhJSVG0OWdnZyd0VTsZuN1uWCwWZGdno7KyMm6uBUpE4XBYrvRGf6SkpEzY6Hwl73khBM6cOYOuri5UVFTM+D3FsTweD7Zs2YLPP/8c+/fvR2NjoyrnICICGHKJiOKKEAIulwtmsxktLS0wmUw4evQo8vLyYDQa5YpvdXV13FZCY9smL3TnbTAYlAOvy+WSl/zEBl+NRpNw4T4RRSIRdHV14dy5c9Dr9cjPz1f7SEkpGAwqNjp7PB7MmzdPfs9rtdpLvpfb5/PBYrFg7ty5qKmpQXp6+gy8gomEEPif//kfbNy4ETfffDMef/xx1c5CRBTFkEtEFOei7aPR0GsymeBwOFBZWakIvvEw5xp7561er7+stsnokp/Y4Ov3+xWzjtH5Xpo60U3XCxcuRHl5eUJfC5RohBATNjqPj49Do9EoKr6xD3uEEOjr60N3dzd0Oh0KCwtV+753u914/PHH0dLSgn379qGhoUGVcxARfR1DLhFRAgqHw7BYLDCZTPJG59HRUaxevVoOvWvWrIFWq52RD8Cxd95WVVVN2VyxJEnweDyKNudIJKLYbKvVahnMJiF6h6rX6+Wm6zgihIDX61VUfKMPezQaDUZHR6HRaFBXV6faAx8hBD799FNs2rQJt956Kx599FFWb4korjDkEhElgejG18OHD8vV3iNHjiAtLU2+t7exsXFaPhhHK4ELFixAeXn5tLdRx846RoNvamqqos05KyuL873nEdtOrvYdqnRpIpEIOjo60N/fj5ycHIRCIYRCIeTk5ChanefNmzftZ3G73XjsscdgNpuxf/9+GAyGaf81iYguF0MuEVGSit5xGq32mkwmWCwWlJaWKoJvWVnZpAKh3+9He3t7XNx5G9vy6XK55JbP2OCbkZEx68Ocz+eD1WrFnDlzLrudnNTh8XhgsViQlZWFqqoqOchGIhF5o3P0hxBiwkbnqepyEELgk08+waZNm/CTn/wEjzzyCEcHiChuMeQSUULz+/249dZbYbFYoNFosGjRIuzevRs6nU7to8UlSZLQ3t4uh97W1lacOXMGdXV18jbnhoYG5OfnnzcQhsNhOBwODA8PY/ny5ViyZEnchcdoy2ds8A0EAsjJyVH1LlO1SJKEnp4e9PX1qT7HSZdGkiR0d3fj9OnT0Ov1WLBgwUV/TigUUoRet9uNuXPnKt7zk9liPjY2hsceewxtbW3Yv38/6uvrJ/uyiIhmBEMuESU0v9+Pjz/+GD/4wQ8wZ84cvPjii3j33XfxySefqH20hOH3+9HW1iaH3tbWVkiSBIPBAKPRiIaGBqxevRoZGRn47LPPsGnTJvz4xz/Gfffdl1Ah8ZvuMo1WvmKvdEm2+d6xsTFYLBZotVpUVlbOSEsrXRm3240TJ04gNzcXlZWVVzQCEAgEJmx0zsjIUFR7s7KyvvGhhxACH3/8Me677z7cfvvteOihhxLqe56IZi+GXCJKKmazGTfffDNOnTql9lESlhACo6OjiqVWbW1tcvi77bbbcMstt6CqqirhA2Fs5cvlcsHtdiuudInO9yZi1TMSiaCzsxNDQ0O8FihBSJKErq4unD17FjU1NdPyZyaEgN/vVzzs8Xq9+PDDD+F0OtHU1IS1a9di0aJFeOyxx3D8+HHs378fq1atmvKzEBFNF4ZcIkoqt99+O/Lz8/HCCy+ofZSkIITA22+/jccffxy33HIL6urq5KpvV1cX9Hq9XO1tbGxM+DbYr1/p4nK54PV6kZmZqQi+6enpcf06h4aGYLfbUVhYiOXLlyf8w4jZwOVywWKxID8/Hzqdbkb/zIQQOHHiBD755BOYzWYcPXoU/f39WLJkCW655RZ8+9vflr+/iYgSAUMuESWNp59+Gu+//z4++ugjZGZmqn2chGe329Hc3Izs7Gzs2rULy5YtU/zvoVAIx48fx6FDh+RW5/HxcdTX18uLrQwGQ8JWQqOim6ujodflcqm22fZigsEg7HY7fD4famtrkZ2drfaR6CJiK+61tbWYP3++amdxOp14+OGHYbVasWfPHkiSJI8wtLa2wuPxwGAwoKmpCX/5l3+JlStXqnZWIqILYcgloqSwfft2vPPOOzh48KCqHxKThd/vx9VXX41HH30UN9xwwyX9HCEE3G43Dh8+jEOHDsltztnZ2XK1t6GhAbW1tdN+zdB0i91sG636AlBUe3NycmbsGiMhBPr7+9HV1YVly5ahpKQkoR8szBajo6OwWq1YuHAhysvLVau4CyHwn//5n3jwwQdxxx134IEHHvjGhzYejwdtbW1obW1FdXU1rr/+ehVOS0R0cQy5RJTwduzYgbfeegsHDx5EXl6e2sdJGkKIKw5KQgicPn1asc3Zbrdj+fLliuBbWlqa8PfaBoPBCfO96enpiuCbmZk55eHT6/XCarVi7ty50Ov1yMjImNKvT1MvHA6jo6MDo6OjqK2tRW5urmpnGR0dxUMPPQSHw4H9+/ejrq5OtbMQEU0VhlwiSmh9fX0oLS1FeXm5fE9reno6WlpaVD4ZnU8kEoHNZpOrva2trTh37hxWrlwp391rMBgwf/78hK5GRhf8xM73+nw+ZGVlTZjvnYzYK2YqKys5L5kghoeHYbPZsHjxYixfvly1hztCCHz44YfYvHkz7rzzTtx///0J32FBRBTFkEtERKoSQsDn8+HIkSPyNmez2Yy5c+cqqr0rV66cdCCMF5IkYXx8XBF8w+Gw4hojrVZ70bDhcrlgtVqRm5sLnU4XF/PAdGGhUAgOhwNjY2Ooq6uTH8qpYWRkBJs3b0ZXVxf279+P2tpa1c5CRDQdGHKJiCjuCCEwNDQEk8kkV3yPHz+OJUuWKIJvRUVFwrc5RyIRxWzv2NgYUlJSFNXe7OxspKSkIBwOo7OzEyMjI6ipqeH8eYI4d+4c7HY7iouLsWzZMlWrtx988AEeeughNDc3Y9OmTazeElFSYsglIqKEIEkSOjs70dLSgpaWFpjNZvT09KC2tlZuczYajVi4cGFCtzkDX833xlZ7PR4PUlNTEQgEkJ+fj4qKioTfWj0bhEIh2O12eL1e1bddDw8P48EHH0Rvby/2798PvV6v2lmIiKYbQy4RESWsYDCIL774QhF8A4EADAaDHHzr6+uh0WgSNhAGAgHYbDb4fD4UFhbKAdjv9yM7O1tR8U1LS1P7uPT/DQ4Oor29HaWlpVi6dKlq7z8hBN5//308/PDDuPfee7Fx40bem0xESY8hl4iIkoYQAk6nE2azWd7ofPToURQUFMBoNMrBt7q6Ou4/6AshcObMGZw8eRJlZWUoLi5WBCVJkuDxeBQVX0mSJsz3xvvrTDbBYBA2mw3BYBC1tbWq3tk9NDSEBx54AP39/di3bx+qq6tVOwsR0UxiyCUioqQmhEBPT4/iGiOHw4HKyko0NDTAaDSiqakJRUVFcVPtHR8fh9Vqxbx586DX6y954VY4HJ4w35uamjphvjdeXmcyEUJgYGAAnZ2dqt9VLITAgQMH8Nhjj2Hjxo249957+bCDiGYVhlwiIpp1wuEwTpw4IS+2MpvNcDqdqK+vlxdbGQwG5OTkzGhQkSQJp06dwpkzZ1BVVYVFixZd8df0+/2K+3vHx8eh0WiQm5srh9+MjAwG3yvg9/ths9kgSRJqamqg0WhUO8vg4CDuv/9+DA0NYd++faisrFTtLEREamHIJSKiWU8IgfHxcZjNZphMJphMJhw5cgQZGRlytbehoQErVqyYtut6nE4nrFYr8vLyoNPppm3rrRACXq9X0eYcCASQk5OjqPjyWqKLi7aUd3V1oaKiQtVuACEE/vVf/xWPP/447rvvPjQ3N7N6S0SzFkMuERHRN4i2n5pMJrnV2WKxYNmyZYrgW1ZWdkVXwoTDYXR0dGB0dFS1a4EkSYLb7Va0OQshFPO9OTk5DE0xfD4frFYrUlJSoNfrkZGRodpZzp49i/vvvx8jIyPYv38/KioqVDnHhg0b8Ic//AHd3d1oa2tDfX29KucgImLIJSIiXHfddRgYGEBKSgpycnKwa9curFmzRu1jxR1JkmC32xXzvf39/VixYoV8d29DQwPy8vIuqaIX3cCr9v2p3yQUCinme91uN+bNm6doc56N1xgJIdDX14fu7m7odDoUFhaq9nsgSRLee+89bNmyBQ888ADuvvtuVd9Dn332GcrLy3HVVVfhwIEDDLlEpBqGXCIigtPplCuIv//977FlyxZ88cUXKp8q/gkh4Pf70dbWJrc5m81mCCFgMBjk0Lt69Wqkp6fLYai7uxubNm3CnXfeiauvvhpZWVkqv5KLE0IgEAgo2py9Xi8yMzMnzPcmK6/XC4vFgrS0NOj1elWvbBoYGMB9992HsbEx7Nu3D+Xl5aqd5evKysoYcolIVdMz8ENERAkltkXW5XLNuurcZM2ZMwcajQZr167F2rVrAXwVBkdGRuQ25+eeew5ffvklCgsLYTQaEQwG8R//8R/YsGEDvv/978dV9fZC5syZg4yMDGRkZKCwsBDA/80yu1wuDA0NoaurC6FQSDHfq9VqE36+N7qhu7e3d8oWgk2WJEn4l3/5Fzz55JPYvHkz7rzzzoR5DxERzRRWcomICADw05/+FP/93/8NAPjjH/+IlStXqnyi5CFJEg4ePIgNGzYgJSUFBQUF6OzshF6vV7Q5q9n6OlUikYhivtflciElJWXCfG+iBLPx8XGcOHECmZmZqK6uVjWwDwwMYNOmTfD5fNi7dy+WL1+u2lkuhJVcIlIbQy4RESm8/vrr+Od//mf88Y9/VPsoSSEQCGDbtm1466238Otf/xrXX389gK9mXo8dO4ZDhw7J871erxdr1qyRF1utWbMmKeZeg8HghPnejIwMRfDNzMyMq9cpSRK6u7tx+vRp6PV6LFiwQNWzvPPOO3jqqafw8MMP44477ojrhwQMuUSkNoZcIiKaQKPRoK+vDwUFBWofJaF1dnbixhtvxF/8xV/gl7/8JbKzs8/7/xVCYGxsDGazGS0tLWhtbUVbWxu0Wq28ybmhoQE1NTXTdr3QTInOMrtcLjn4+nw+ZGVlKa4xSk9PV+V8brcbFosFOTk5qKqqUvX3u7+/Hxs2bEA4HMarr76KpUuXqnaWS8WQS0RqY8glIprlnE4nvF4vlixZAgA4cOAA7rnnHvT29sZVZS0R+Xw+WCwWGI3GSf386Cbf6DZnk8mE9vZ2VFRUKIJvSUlJXFf2LoUkSfJ8b7TqG4lEJsz3TmfglCQJJ0+exMDAAPR6vaoPeSRJwttvv42tW7fi0Ucfxc9//vO4/zO+66678MEHH2BgYAAFBQXIyclBR0eH2sciolmIIZeIaJbr7u7GLbfcAp/Ph5SUFCxcuBDbt29nFSZORSIRWK1WxTVGQ0NDWLVqFYxGIxobG2EwGJCbm5vwDynC4fCE+3vnzp2raHPOzs6ekvDncrlgsViQl5cHnU6navX2zJkzuPfeewEAe/fuRWlpqWpnISJKRAy5RERECUwIAa/XiyNHjshtzocPH0ZqaiqMRqMcfFesWKFa++9UCgQCivlej8cDjUajCL4ajeaSA34kEkFXVxfOnTuHmpoa5OXlTfMrOD9JkvDmm2/imWeewT/+4z9i3bp1cV+9JSKKRwy5RERESUYIgXPnzsFkMuHQoUNobW3F8ePHUVJSogi+5eXlCR+ioiE/Nvj6/X5kZ2cr5nu/6U5bp9MJi8WChQsXory8HHPnzlXhFXylr68P99xzD+bNm4dXXnkFJSUlqp2FiCjRMeQSERHNApIkoaOjAy0tLWhpaYHZbEZvby/q6uoU870LFixI+DZnSZLg8XgU872SJMmBNzs7G4ODg3A6naitrUVubq6qZ33jjTfw3HPPYcuWLbj99tsT/sEDEZHaGHKJiIhmqUAggC+++EIx3xsKhWAwGORq7+rVqy+r/TdehUIhuN1uDAwMYGBgAHPmzEFGRgZyc3MV870z+Tp7e3uxfv16aDQavPLKK/LyNyIiujIMuURERATgq9Zfp9OJ1tZWuc35iy++QEFBgaLaW11drWpr72SEw2E4HA64XC7U1dUhJycHfr9f0eY8Pj4OjUajCL4ZGRlTHnwlScJvfvMbPP/883jyySfxk5/8hNVbIqIpxJBLRERE5yVJEnp6ehTV3o6ODlRXV8vzvU1NTQmNX/AAAAgzSURBVFi8eHHcVnuHhoZgs9lQXFyMZcuWnTdQCiEwPj6uCL7BYFCe740G33nz5k36LD09PWhuboZWq8Xu3btRVFQ06a9FRETfjCGXiIiILks4HMbx48flxVZmsxkulwv19fVytddgMMx4++/XhUIhtLe3Y3x8HLW1tcjOzr7srxGJRCbM9wKQ53ujM74Xq2xLkoT9+/dj586deOqpp3DrrbeyektENE0YcomIiOiKCCHg8Xhw+PBhueLb1tYGjUaDhoYGudW5rq7uiqqgl2NwcBDt7e0oLS3F0qVLpzRsh0IhOfC6XC54PB6kpaVBq9XC6XQiPT0dq1evloPvqVOnsH79euTl5eHll1/G4sWLp+wsREQ0EUMuERERTTkhBPr7+2EymeTga7VaUVZWpgi+F2ofnoxgMAibzYZAIIDa2lpkZWVN2dc+HyGEPN974MABvPHGG+jt7UVZWRkKCwthNpvxi1/8AnfffXfctnQTESUThlwiIiKaEZFIBHa7XTHfOzAwgJUrV8ptzkajEXl5eZcdBoUQOHv2LDo6OrBs2TKUlJSoGijb29vxwAMPIBKJYOnSpTh27BhGRkZgMBjQ1NSEpqYmNDQ0QKvVqnZGIqJkxZBLREQ0hV577TX8/Oc/x+9//3vceOONah8nrkUroEeOHIHJZILJZILZbMacOXNgMBjk4Ltq1Sqkp6efN7QODAygv78fkiShtrYWGo1mhl/J/4lEIti7dy9eeuklbN26FX/zN38jn9vr9eLo0aOK19rY2Ii33npLtfMSESUjhlwiIqIpcurUKdx2220QQmDz5s0MuZMghMDw8LCizfnYsWNYvHix4hqjyspKAMDu3buxY8cOvP3222hqalK1etvR0YH169ejuLgYu3btwqJFiy76c/x+PzIyMmbgdEREswdDLhER0RSQJAnXXXcdnnnmGdx///3YtGkTQ+4UkSQJJ0+elO/uNZlM6OzshEajQV5eHv7+7/8e1113HRYtWqRKyI1EItizZw/27NmDbdu24eabb+bsLRGRilLVPgAREVEy2LFjB77zne/AaDSqfZSkk5KSgoqKClRUVOC2227Dq6++iq1bt+Jv//ZvMX/+fPzv//4vXnjhBfh8PhgMBrniu2bNGmRmZk5r4HQ4HGhubsayZctw6NAhLFy4cNp+LSIiujQMuURERFfo+PHjeO+99/DZZ5+pfZSk1tXVhb/7u79DQUEBWlpaFO3AQgiMjY2htbUVLS0tePnll9HW1ob58+fDaDTCaDSisbERer0eqalX/vEnHA7j5ZdfxquvvornnnsOP/rRj1i9JSKKE2xXJiIiukK7d+/Gk08+ifT0dABfLULSarV44okncPfdd6t8uuQwPDyMP/uzP8PWrVtx0003XdLPEUKgt7dXnu01mUxwOBzQ6XSK+d7L3cRst9vR3NyMiooK7Ny5EwsWLJjsyyIiomnAkEtERDTFrrnmGs7kToNAICA/SJiscDgMq9WqCL4jIyNYvXq1XO01GAzQarUTgm84HMZLL72Effv24fnnn8cNN9zA6i0RURxiuzIRERElhCsNuACQmpqKlStXYuXKlbjjjjsghIDX68Xhw4fR0tKC119/HRs2bMC8efPke3sbGxuRlpaGDRs2oLKyEiaTCQUFBVPwioiIaDqwkktEREQUQwiBwcFBmEwmHDp0SP7xzjvv4K/+6q9YvSUiinMMuUREREQXEYlEMHfuXLWPQUREl4Ahl4iIiIiIiJJGitoHICIiIiIlh8OBtWvXoqqqCo2NjThx4oTaRyIiShgMuURERERx5q677sKdd96J9vZ2bN68GevWrVP7SERECYPtykRERERxZHBwEDqdDiMjI0hNTYUQAkVFRfj888+h0+nUPh4RUdxjJZeIiIgojvT29qKoqAipqV/d9DhnzhwsXboUPT09Kp+MiCgxMOQSERERERFR0mDIJSIiIoojpaWl6O/vRzgcBvDVvb09PT1YunSpyicjIkoMDLlEREREcWTRokUwGAx48803AQDvvfceSkpKOI9LRHSJuHiKiIiI4kpZWRnS09Oh0WgAAA8//DB+/OMfq3yqmWW327Fu3ToMDw9Dq9Xitddew8qVK9U+FhFRQmDIJSIiorhSVlaGAwcOoL6+Xu2jEBFRAmK7MhERERERESUNVnKJiIgorpSVlUGr1UIIgaamJmzbtg0LFy5U+1hERJQgWMklIiKiuPLZZ5/hyy+/xJEjR7BgwQL87Gc/U/tIRESUQFjJJSIiorjV39+PqqoquN1utY9CREQJgpVcIiIiihvj4+NwOp3yf/7tb3+LNWvWqHgiIiJKNKlqH4CIiIgo6uzZs7jpppsQiUQghEB5eTneeOMNtY9FREQJhO3KRERERERElDTYrkxERERERERJgyGXiIiIiIiIkgZDLhERERERESUNhlwiIiIiIiJKGgy5RERERERElDQYcomIiIiIiChpMOQSERERERFR0mDIJSIiIiIioqTBkEtERERERERJgyGXiIiIiIiIkgZDLhERERERESUNhlwiIiIiIiJKGgy5RERERERElDQYcomIiIiIiChpMOQSERERERFR0mDIJSIiIiIioqTBkEtERERERERJgyGXiIiIiIiIkgZDLhERERERESUNhlwiIiIiIiJKGgy5RERERERElDQYcomIiIiIiChpMOQSERERERFR0mDIJSIiIiIioqTBkEtERERERERJgyGXiIiIiIiIkgZDLhERERERESUNhlwiIiIiIiJKGgy5RERERERElDQYcomIiIiIiChp/D/tC1WKL5oRNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#figure(num=None, figsize=(10, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "fig = plt.figure(figsize=(15, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "t = trials_3.trials\n",
    "\n",
    "y = []\n",
    "x = []\n",
    "z = []\n",
    "\n",
    "for tr in t: \n",
    "    z.append((tr['result']['loss']))\n",
    "    x.append(tr['misc']['vals']['l1'])\n",
    "    y.append(tr['misc']['vals']['l2'])\n",
    "    \n",
    "\n",
    "ax.scatter(x, y, z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure(num=None, figsize=(10, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "t = trials_2.trials\n",
    "\n",
    "x_axis = np.arange(0, 5)\n",
    "y = []\n",
    "x = []\n",
    "for tr in t: \n",
    "    y.append((tr['result']['loss']))\n",
    "    x.append(tr['misc']['vals']['l1'])\n",
    "\n",
    "t_1 = trials_3.trials\n",
    "\n",
    "y_1 = []\n",
    "x_1 = []\n",
    "\n",
    "for tr in t_1: \n",
    "    y_1.append((tr['result']['loss']))\n",
    "    x_1.append(tr['misc']['vals']['l2'])\n",
    "\n",
    "\n",
    "plt.scatter(x, y, c=\"blue\")\n",
    "plt.scatter(x_1, y_1, c=\"red\")\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135,\n",
       " -0.1135]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
